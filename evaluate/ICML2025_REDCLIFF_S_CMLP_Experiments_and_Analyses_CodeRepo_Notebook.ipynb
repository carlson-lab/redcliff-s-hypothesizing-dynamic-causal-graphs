{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "C6eO24GyfK9N",
        "JOvt1GWiIwtV",
        "clMIE14EIspc",
        "WPaa_NZjqq3w",
        "8Kxo1bJgqmWZ",
        "6bebtnI0Rh4i",
        "_6Pxnur7Rsdq",
        "Wjf9cHHKR8Xi",
        "mcp1c9-VR8Qj",
        "JfteyH-2R71a",
        "RspPZ1mdR7s7",
        "FxLeXol2SFND",
        "9Duv9ChcrNQR",
        "bhq9iiizqcZS",
        "Rdb8r_Ns9nmM",
        "CnHpQ37jqVMm",
        "iN_zOB5oieor",
        "jvjBftnjfvkY",
        "7J6dYXlRdsSu",
        "Sf32Hzekd_el",
        "1LYTbkR0qx6H",
        "SRFpj-ZfcmVC",
        "IQ-UEyxacZWj",
        "2lKNFVNfMUX1"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install gadjid"
      ],
      "metadata": {
        "id": "iD5ttjsI5IDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -V"
      ],
      "metadata": {
        "id": "ow4NpBOk5YP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Social Preference Sandbox and Analyses"
      ],
      "metadata": {
        "id": "C6eO24GyfK9N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing Social Preference Model v03/31/2025"
      ],
      "metadata": {
        "id": "JOvt1GWiIwtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torcheeg"
      ],
      "metadata": {
        "id": "lY6WgyelIweT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch_scatter"
      ],
      "metadata": {
        "id": "FOvNnb9KI1ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------------------------------------------------------------------------\n",
        "# FILE DESCRIPTION\n",
        "# ----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# File:  plot.py\n",
        "# Author:  anonymous\n",
        "# Date written:  01-18-2022\n",
        "# Last modified:  10-25-2023\n",
        "\n",
        "r\"\"\"\n",
        "Description:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------------------------------------------------------\n",
        "# IMPORT STATEMENTS\n",
        "# ----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# Import statements\n",
        "import numpy as np\n",
        "#from scipy.stats import pearsonr\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import to_rgba, LinearSegmentedColormap\n",
        "from matplotlib.patches import Polygon\n",
        "import seaborn as sns\n",
        "\n",
        "# Constants\n",
        "R1 = 1.0  # inner radius of power plots\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------------------------------------------------------\n",
        "# FUNCTION DEFINITIONS\n",
        "# ----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# Chord plot\n",
        "def chord_plot(\n",
        "    x,\n",
        "    rois=None,\n",
        "    freqs=None,\n",
        "    freq_ticks=None,\n",
        "    max_alpha=0.7,\n",
        "    buffer_percent=1.0,\n",
        "    outer_radius=1.2,\n",
        "    min_max_quantiles=(0.5, 0.9),\n",
        "    color=None,\n",
        "    cmap=None,\n",
        "    roi_fontsize=13,\n",
        "    roi_extent=0.28,\n",
        "    tick_extent=0.03,\n",
        "    tick_label_extent=0.11,\n",
        "    tick_label_fontsize=10.0,\n",
        "    fontfamily='sans-serif',\n",
        "    figsize=(7, 7)):\n",
        "    r\"\"\"\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    \"\"\"\n",
        "\n",
        "    # Check arguments\n",
        "    assert x.ndim == 3\n",
        "    assert x.shape[0] == x.shape[1]\n",
        "    assert max_alpha >= 0.0 and max_alpha <= 1.0, f\"{max_alpha}\"\n",
        "    n_roi, n_freq = x.shape[1:]\n",
        "    assert freqs is None or len(freqs) == n_freq, f\"{len(freqs)} != {n_freq}\"\n",
        "\n",
        "    # Replace ROI underscores with spaces\n",
        "    if rois is not None:\n",
        "        assert len(rois) == n_roi, f\"{len(rois)} != {n_roi}\"\n",
        "        pretty_rois = [roi.replace(\"_\", \" \") for roi in rois]\n",
        "\n",
        "    # Default color\n",
        "    if color is None and cmap is None:\n",
        "        color = 'tab:blue'\n",
        "\n",
        "    # Set color to None if color map is provided\n",
        "    if cmap is not None:\n",
        "        color = None\n",
        "\n",
        "    #  variables\n",
        "    r2 = outer_radius\n",
        "    center_angles = np.linspace(0, 2 * np.pi, n_roi + 1)\n",
        "    buffer = buffer_percent / 100.0 * 2.0 * np.pi\n",
        "    start_angles = center_angles[:-1] + buffer\n",
        "    stop_angles = center_angles[1:] - buffer\n",
        "    freq_diff = (stop_angles[0] - start_angles[0]) / (n_freq + 1)\n",
        "    min_val, max_val = np.quantile(x, min_max_quantiles)\n",
        "    x = max_alpha * np.clip((x - min_val) / (max_val - min_val), 0.0, 1.0)\n",
        "\n",
        "    # Set up axes and labels and ticks\n",
        "    _, ax = _set_up_chord_plot(\n",
        "        start_angles=start_angles,\n",
        "        stop_angles=stop_angles,\n",
        "        r1=R1,\n",
        "        r2=r2,\n",
        "        pretty_rois=pretty_rois,\n",
        "        freqs=freqs,\n",
        "        freq_ticks=freq_ticks,\n",
        "        tick_extent=tick_extent,\n",
        "        tick_label_extent=tick_label_extent,\n",
        "        tick_label_fontsize=tick_label_fontsize,\n",
        "        roi_fontsize=roi_fontsize,\n",
        "        roi_extent=roi_extent,\n",
        "        fontfamily=fontfamily,\n",
        "        figsize=figsize)\n",
        "\n",
        "    # Add the power and chord plots\n",
        "    _update_chord_plot(\n",
        "        x=x,\n",
        "        ax=ax,\n",
        "        start_angles=start_angles,\n",
        "        stop_angles=stop_angles,\n",
        "        freq_diff=freq_diff,\n",
        "        outer_radius=outer_radius,\n",
        "        color=color,\n",
        "        cmap=cmap)\n",
        "\n",
        "    # Return plot axis\n",
        "    return ax\n",
        "\n",
        "\n",
        "# Update chord plot\n",
        "def _update_chord_plot(\n",
        "    x,\n",
        "    ax,\n",
        "    start_angles,\n",
        "    stop_angles,\n",
        "    freq_diff,\n",
        "    outer_radius,\n",
        "    color,\n",
        "    cmap=None):\n",
        "    r\"\"\"\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize variables\n",
        "    r2 = outer_radius\n",
        "    handles = []\n",
        "    n_roi, n_freq = x.shape[1:]\n",
        "\n",
        "    # Create colormap array for different frequencies\n",
        "    if cmap is not None:\n",
        "        if isinstance(cmap, str):\n",
        "            cmap_idx = np.linspace(0, 1, n_freq)\n",
        "            # cmap_color_arr = mpl.colormaps[cmap](cmap_idx)[:, :3]\n",
        "            cmap_color_arr = mpl.cm.get_cmap(cmap)(cmap_idx)[:, :3]\n",
        "        elif isinstance(cmap, LinearSegmentedColormap):\n",
        "            cmap_idx = np.linspace(0, 1, n_freq)\n",
        "            cmap_color_arr = cmap(cmap_idx)[:, :3]\n",
        "        else:\n",
        "            cmap_color_arr = None\n",
        "            color = 'b'\n",
        "    else:\n",
        "        cmap_color_arr = None\n",
        "\n",
        "    # Draw the power plots\n",
        "    for i, (c1, c2) in enumerate(zip(start_angles, stop_angles)):\n",
        "        # Iterate over frequencies\n",
        "        for j in range(n_freq):\n",
        "            # Retrieve colormap color for corresponding frequency value\n",
        "            if cmap_color_arr is not None:\n",
        "                color = cmap_color_arr[j]\n",
        "\n",
        "            # Generate arc power patch\n",
        "            if x[i, i, j] > 0:\n",
        "                # Arc power patch rotation\n",
        "                diff1 = j * (c2 - c1) / n_freq\n",
        "                diff2 = (j + 1) * (c2 - c1) / n_freq\n",
        "\n",
        "                # Transparency value\n",
        "                alpha = x[i, i, j]\n",
        "\n",
        "                # Append arc power patch to handles\n",
        "                h = _arc_patch(\n",
        "                    r1=R1,\n",
        "                    r2=r2,\n",
        "                    theta1=c1 + diff1,\n",
        "                    theta2=c1 + diff2,\n",
        "                    ax=ax,\n",
        "                    color=color,\n",
        "                    cmap=cmap,\n",
        "                    n=5,\n",
        "                    alpha=alpha)\n",
        "                handles.append(h)\n",
        "\n",
        "    # Draw the chords to represent cross-power\n",
        "    print(\"WARNING - CROSS-POWER PLOT HAS BEEN OVER-WRITTEN TO REPRESENT DIRECTIONAL ADJACENCY MATRICES!!!\")\n",
        "    for i in range(n_roi):# - 1):\n",
        "        for j in range(n_roi):#i + 1, n_roi):\n",
        "            # Iterate over frequency values\n",
        "            for k in range(n_freq):\n",
        "                # Frequency-specific color map color\n",
        "                if cmap_color_arr is not None:\n",
        "                    color = cmap_color_arr[k]\n",
        "                if i >= j:\n",
        "                    color = 'b'\n",
        "                else:\n",
        "                    color = 'r'\n",
        "\n",
        "                # Generate chord connection\n",
        "                if x[i, j, k] > 0.0:\n",
        "                    # Chord connection rotation\n",
        "                    theta1 = start_angles[i] + freq_diff * k\n",
        "                    theta2 = start_angles[j] + freq_diff * k\n",
        "\n",
        "                    # Transparency value\n",
        "                    alpha = x[i, j, k]\n",
        "\n",
        "                    # Append chord connection polygon to handles\n",
        "                    h = _plot_poly_chord(\n",
        "                        theta1=theta1,\n",
        "                        theta2=theta2,\n",
        "                        diff=freq_diff,\n",
        "                        ax=ax,\n",
        "                        color=color,\n",
        "                        alpha=alpha)\n",
        "                    handles.append(h)\n",
        "\n",
        "    # Return collection of power arc and chord connection handles\n",
        "    return handles\n",
        "\n",
        "\n",
        "# Set up chord plot\n",
        "def _set_up_chord_plot(\n",
        "    start_angles,\n",
        "    stop_angles,\n",
        "    r1,\n",
        "    r2,\n",
        "    pretty_rois,\n",
        "    freqs,\n",
        "    freq_ticks,\n",
        "    tick_extent,\n",
        "    tick_label_extent,\n",
        "    tick_label_fontsize,\n",
        "    roi_fontsize,\n",
        "    roi_extent,\n",
        "    fontfamily,\n",
        "    figsize):\n",
        "    r\"\"\"\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize figure\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    ax = plt.gca()\n",
        "\n",
        "    # Set up axes and draw power plots\n",
        "    for i, (c1, c2) in enumerate(zip(start_angles, stop_angles)):\n",
        "        # Draw power axis\n",
        "        _draw_power_axis(\n",
        "            r1=r1,\n",
        "            r2=r2,\n",
        "            theta1=c1,\n",
        "            theta2=c2,\n",
        "            ax=ax)\n",
        "\n",
        "        # Plot ticks\n",
        "        if freqs is not None and freq_ticks is not None:\n",
        "            _plot_ticks(\n",
        "                r=r2,\n",
        "                theta1=c1,\n",
        "                theta2=c2,\n",
        "                ax=ax,\n",
        "                freqs=freqs,\n",
        "                freq_ticks=freq_ticks,\n",
        "                tick_extent=tick_extent,\n",
        "                tick_label_extent=tick_label_extent,\n",
        "                tick_label_fontsize=tick_label_fontsize,\n",
        "                fontfamily=fontfamily)\n",
        "\n",
        "        # Annotate ROIs\n",
        "        if pretty_rois is not None:\n",
        "            _plot_roi_name(\n",
        "                r=r2,\n",
        "                theta=0.5 * (c1 + c2),\n",
        "                ax=ax,\n",
        "                roi=pretty_rois[i],\n",
        "                extent=roi_extent,\n",
        "                fontsize=roi_fontsize,\n",
        "                fontfamily=fontfamily)\n",
        "\n",
        "    # Axis limits\n",
        "    ax.set_ylim(-1.5, 1.5)\n",
        "    ax.set_xlim(-1.5, 1.5)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    # Return figure and axis variables\n",
        "    return fig, ax\n",
        "\n",
        "\n",
        "# Plot poly chord\n",
        "def _plot_poly_chord(\n",
        "    theta1,\n",
        "    theta2,\n",
        "    diff,\n",
        "    ax,\n",
        "    color,\n",
        "    n=50,\n",
        "    alpha=0.5):\n",
        "    r\"\"\"\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    \"\"\"\n",
        "\n",
        "    # Chord chonnection points\n",
        "    points1 = _chord_helper(theta1, theta2, n=n)\n",
        "    rot_mat = np.array([[np.cos(diff), -np.sin(diff)], [np.sin(diff), np.cos(diff)]])\n",
        "    points2 = rot_mat @ points1\n",
        "    points = np.concatenate([points1, points2[:, ::-1]], axis=1).T\n",
        "\n",
        "    # Chord connection polygon\n",
        "    poly = Polygon(points, closed=True, fc=to_rgba(c=color, alpha=alpha))\n",
        "    ax.add_patch(poly)\n",
        "\n",
        "    # Return chord connection polygon\n",
        "    return poly\n",
        "\n",
        "\n",
        "# Chord helper\n",
        "def _chord_helper(theta1, theta2, n=50):\n",
        "    r\"\"\"\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    \"\"\"\n",
        "\n",
        "    # Chord helper coordinates calculations\n",
        "    a1, a2 = np.cos(theta1), np.sin(theta1)\n",
        "    b1, b2 = np.cos(theta2), np.sin(theta2)\n",
        "    denom = a1 * b2 - a2 * b1\n",
        "    if np.abs(denom) < 1e-5:\n",
        "        xs = np.linspace(a1, b1, n)\n",
        "        ys = np.linspace(a2, b2, n)\n",
        "\n",
        "        return np.vstack([xs, ys])\n",
        "    v, w = 2.0 * (a2 - b2) / denom, 2.0 * (b1 - a1) / denom\n",
        "    center = (-v / 2.0, -w / 2.0)\n",
        "    radius = np.sqrt(((v ** 2.0 + w ** 2.0) / 4.0) - 1.0)\n",
        "    angle1 = np.arctan2(a2 - center[1], a1 - center[0])\n",
        "    angle2 = np.arctan2(b2 - center[1], b1 - center[0])\n",
        "    angle1, angle2 = min(angle1, angle2), max(angle1, angle2)\n",
        "    if angle2 - angle1 > np.pi:\n",
        "        angle1, angle2 = angle2, angle1 + 2 * np.pi\n",
        "    theta = np.linspace(angle1, angle2, n)\n",
        "    xs = radius * np.cos(theta) + center[0]\n",
        "    ys = radius * np.sin(theta) + center[1]\n",
        "\n",
        "    # Return coordinates\n",
        "    return np.vstack([xs, ys])\n",
        "\n",
        "\n",
        "# Arc patch\n",
        "def _arc_patch(\n",
        "    r1,\n",
        "    r2,\n",
        "    theta1,\n",
        "    theta2,\n",
        "    ax,\n",
        "    color,\n",
        "    cmap=None,\n",
        "    n=50,\n",
        "    alpha=1.0,\n",
        "    **kwargs):\n",
        "    r\"\"\"\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    \"\"\"\n",
        "\n",
        "    # Power arc points\n",
        "    thetas = np.linspace(theta1, theta2, n)\n",
        "    sin_thetas, cos_thetas = np.sin(thetas), np.cos(thetas)\n",
        "    points = np.vstack([cos_thetas, sin_thetas]).T\n",
        "    points = np.concatenate([r1 * points, r2 * points[::-1]], axis=0)\n",
        "\n",
        "    # Power arc polygon\n",
        "    poly = Polygon(\n",
        "        points,\n",
        "        closed=True,\n",
        "        fc=to_rgba(color, alpha=alpha),\n",
        "        **kwargs)\n",
        "    ax.add_patch(poly)\n",
        "\n",
        "    # Return power arc polygon\n",
        "    return poly\n",
        "\n",
        "\n",
        "# Draw power axis\n",
        "def _draw_power_axis(\n",
        "    r1,\n",
        "    r2,\n",
        "    theta1,\n",
        "    theta2,\n",
        "    ax,\n",
        "    n=50,\n",
        "    **kwargs):\n",
        "    r\"\"\"\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    \"\"\"\n",
        "\n",
        "    # Power axis points\n",
        "    thetas = np.linspace(theta1, theta2, n)\n",
        "    sin_thetas, cos_thetas = np.sin(thetas), np.cos(thetas)\n",
        "    points = np.vstack([cos_thetas, sin_thetas]).T\n",
        "    points = np.concatenate([r1 * points, r2 * points[::-1]], axis=0)\n",
        "    points = np.concatenate([points, points[:1]], axis=0)\n",
        "\n",
        "    # Power axis handle\n",
        "    handle = ax.plot(points[:, 0], points[:, 1], c='k', **kwargs)\n",
        "\n",
        "    # Return handle\n",
        "    return handle\n",
        "\n",
        "\n",
        "# Plot ticks\n",
        "def _plot_ticks(\n",
        "    r,\n",
        "    theta1,\n",
        "    theta2,\n",
        "    ax,\n",
        "    freqs,\n",
        "    freq_ticks,\n",
        "    tick_extent=0.03,\n",
        "    tick_label_extent=0.11,\n",
        "    tick_label_fontsize=10.0,\n",
        "    n=5,\n",
        "    fontfamily='sans-serif',\n",
        "    **kwargs):\n",
        "    r\"\"\"\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    \"\"\"\n",
        "\n",
        "    # Tick offset\n",
        "    offset = 0.0 if np.cos((theta1 + theta2) / 2.0) > 0.0 else 180.0\n",
        "\n",
        "    # Iterate over frequency tick values\n",
        "    for freq in freq_ticks:\n",
        "        # Tick location and rotation\n",
        "        theta = theta1 + (theta2 - theta1) * (freq - freqs[0]) / (freqs[-1] - freqs[0])\n",
        "        x = [r * np.cos(theta), (r + tick_extent) * np.cos(theta)]\n",
        "        y = [r * np.sin(theta), (r + tick_extent) * np.sin(theta)]\n",
        "\n",
        "        # Plot tick\n",
        "        ax.plot(x, y, c=\"k\", **kwargs)\n",
        "\n",
        "        # Tick label location and rotation\n",
        "        x = (r + tick_label_extent) * np.cos(theta)\n",
        "        y = (r + tick_label_extent) * np.sin(theta)\n",
        "        rotation = (theta * 180.0 / np.pi) + offset\n",
        "\n",
        "        # Tick text / label\n",
        "        ax.text(\n",
        "            x=x,\n",
        "            y=y,\n",
        "            s=str(freq),\n",
        "            rotation=rotation,\n",
        "            fontfamily=fontfamily,\n",
        "            fontsize=tick_label_fontsize,\n",
        "            ha='center',\n",
        "            va='center')\n",
        "\n",
        "\n",
        "# Plot ROI name\n",
        "def _plot_roi_name(\n",
        "    r,\n",
        "    theta,\n",
        "    ax,\n",
        "    roi,\n",
        "    extent=0.3,\n",
        "    fontsize=13,\n",
        "    fontfamily='sans-serif'):\n",
        "    r\"\"\"\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    \"\"\"\n",
        "\n",
        "    # ROI location and rotation\n",
        "    x, y = (r + extent) * np.cos(theta), (r + extent) * np.sin(theta)\n",
        "    rotation = (theta * 180.0 / np.pi) - 90.0\n",
        "\n",
        "    # Offset rotation\n",
        "    if np.sin(theta) < 0.0:\n",
        "        rotation += 180.0\n",
        "\n",
        "    # ROI text\n",
        "    ax.text(\n",
        "        x=x,\n",
        "        y=y,\n",
        "        s=roi,\n",
        "        rotation=rotation,\n",
        "        ha='center',\n",
        "        va='center',\n",
        "        fontfamily=fontfamily,\n",
        "        fontsize=fontsize)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0TdLjU_RI8YM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle as pkl\n",
        "\n",
        "from general_utils.misc import get_topk_graph_mask\n",
        "\n",
        "FONT_SMALL_SIZE = 18\n",
        "FONT_MEDIUM_SIZE = 20\n",
        "FONT_BIGGER_SIZE = 22\n",
        "\n",
        "plt.rc('font', size=FONT_SMALL_SIZE)          # controls default text sizes\n",
        "plt.rc('axes', titlesize=FONT_BIGGER_SIZE)     # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=FONT_MEDIUM_SIZE)    # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=FONT_SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=FONT_SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=FONT_SMALL_SIZE)    # legend fontsize\n",
        "plt.rc('figure', titlesize=FONT_BIGGER_SIZE)  # fontsize of the figure title\n",
        "\n",
        "\n",
        "factor_names = [\"Social Preference (SP)\", \"Object Preference (OP)\",\n",
        "                \"UNKNOWN 1 (U1)\", \"UNKNOWN 2 (U2)\", \"UNKNOWN 3 (U3)\",\n",
        "                \"UNKNOWN 4 (U4)\", \"UNKNOWN 5 (U5)\", \"UNKNOWN 6 (U6)\",\n",
        "                \"UNKNOWN 7 (U7)\", \"UNKNOWN 8 (U8)\", \"UNKNOWN 9 (U9)\",\n",
        "                \"UNKNOWN 10 (U10)\", \"UNKNOWN 11 (U11)\", \"UNKNOWN 12 (U12)\",\n",
        "                \"UNKNOWN 13 (U13)\", \"UNKNOWN 14 (U14)\", \"UNKNOWN 15 (U15)\",\n",
        "                \"UNKNOWN 16 (U16)\", ]\n",
        "channel_names = ['Amy_BLA', 'Amy_CeA', 'Cg_Cx_R', 'Hipp', 'NAc_Core', 'NAc_Shell', 'PrL_Cx_R', 'VTA_L', 'VTA_R']\n",
        "model0 = torch.load(\"final_best_model_FOLD0.bin\", map_location=torch.device('cpu'), weights_only=False)\n",
        "model1 = torch.load(\"final_best_model_FOLD1.bin\", map_location=torch.device('cpu'), weights_only=False)\n",
        "model2 = torch.load(\"final_best_model_FOLD2.bin\", map_location=torch.device('cpu'), weights_only=False)\n",
        "model3 = torch.load(\"final_best_model_FOLD3.bin\", map_location=torch.device('cpu'), weights_only=False)\n",
        "model4 = torch.load(\"final_best_model_FOLD4.bin\", map_location=torch.device('cpu'), weights_only=False)\n",
        "curr_gc_factor_ests0 = [x.detach().numpy() for x in model0.GC(\"fixed_factor_exclusive\", X=None, threshold=False, ignore_lag=False, combine_wavelet_representations=True, rank_wavelets=False)[0]]\n",
        "curr_gc_factor_ests0 = [x/np.max(x) for x in curr_gc_factor_ests0]\n",
        "curr_gc_factor_ests1 = [x.detach().numpy() for x in model1.GC(\"fixed_factor_exclusive\", X=None, threshold=False, ignore_lag=False, combine_wavelet_representations=True, rank_wavelets=False)[0]]\n",
        "curr_gc_factor_ests1 = [x/np.max(x) for x in curr_gc_factor_ests1]\n",
        "curr_gc_factor_ests2 = [x.detach().numpy() for x in model2.GC(\"fixed_factor_exclusive\", X=None, threshold=False, ignore_lag=False, combine_wavelet_representations=True, rank_wavelets=False)[0]]\n",
        "curr_gc_factor_ests2 = [x/np.max(x) for x in curr_gc_factor_ests2]\n",
        "curr_gc_factor_ests3 = [x.detach().numpy() for x in model3.GC(\"fixed_factor_exclusive\", X=None, threshold=False, ignore_lag=False, combine_wavelet_representations=True, rank_wavelets=False)[0]]\n",
        "curr_gc_factor_ests3 = [x/np.max(x) for x in curr_gc_factor_ests3]\n",
        "curr_gc_factor_ests4 = [x.detach().numpy() for x in model4.GC(\"fixed_factor_exclusive\", X=None, threshold=False, ignore_lag=False, combine_wavelet_representations=True, rank_wavelets=False)[0]]\n",
        "curr_gc_factor_ests4 = [x/np.max(x) for x in curr_gc_factor_ests4]\n",
        "\n",
        "\n",
        "curr_gc_factor_ests = [x0+x1+x2+x3+x4 for (x0,x1,x2,x3,x4) in zip(curr_gc_factor_ests0, curr_gc_factor_ests1, curr_gc_factor_ests2, curr_gc_factor_ests3, curr_gc_factor_ests4)]\n",
        "curr_gc_factor_ests = [x/5. for x in curr_gc_factor_ests]\n",
        "\n",
        "\n",
        "for i in range(len(curr_gc_factor_ests)):\n",
        "    fig, ax = plt.subplots()\n",
        "    fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "    im = ax.imshow(curr_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r')\n",
        "    fig.colorbar(im, orientation='vertical')\n",
        "    plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "    plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "    plt.xlabel(\"Driving Channels\")\n",
        "    plt.ylabel(\"Receiving Channels\")\n",
        "    plt.title(\"Est. Causality: \"+factor_names[i]+\"\\n\")\n",
        "    plt.show()\n",
        "\n",
        "print(\"DIFFERENCE BETWEEN FACTOR 1 AND FACTOR 2 ------------------------\")\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(i,3):\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_gc_factor_ests[j][:,:,:].sum(axis=2) - curr_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[j]+\" - \"+factor_names[i])\n",
        "        plt.show()\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_gc_factor_ests[i][:,:,:].sum(axis=2) - curr_gc_factor_ests[j][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[i]+\" - \"+factor_names[j])\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n\\n\\n # OFF-DIAGONAL VISUALIZATIONS ##########################################################################################################\")\n",
        "\n",
        "curr_offDiag_gc_factor_ests = [x - x*np.expand_dims(np.eye(x.shape[0]), axis=2) for x in curr_gc_factor_ests]\n",
        "curr_offDiag_gc_factor_ests = [x/np.max(x) for x in curr_offDiag_gc_factor_ests]\n",
        "\n",
        "for i in range(len(curr_offDiag_gc_factor_ests)):\n",
        "    fig, ax = plt.subplots()\n",
        "    fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "    im = ax.imshow(curr_offDiag_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r')\n",
        "    fig.colorbar(im, orientation='vertical')\n",
        "    plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "    plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "    plt.xlabel(\"Driving Channels\")\n",
        "    plt.ylabel(\"Receiving Channels\")\n",
        "    plt.title(\"Est. Causality: \"+factor_names[i]+\"\\n\")\n",
        "    plt.show()\n",
        "\n",
        "print(\"DIFFERENCE BETWEEN FACTOR 1 AND FACTOR 2 ------------------------\")\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(i,3):\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_offDiag_gc_factor_ests[j][:,:,:].sum(axis=2) - curr_offDiag_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[j]+\" - \"+factor_names[i])\n",
        "        plt.show()\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_offDiag_gc_factor_ests[i][:,:,:].sum(axis=2) - curr_offDiag_gc_factor_ests[j][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[i]+\" - \"+factor_names[j])\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "R7R34QeQJTmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Identifying Social Preference Model"
      ],
      "metadata": {
        "id": "clMIE14EIspc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "#2-factor\n",
        "nk2_perfs = [4.001132041613262,\n",
        "3.4969392490386957,\n",
        "3.559678573608399,\n",
        "3.870644167264303,\n",
        "3.327145659128825, ]\n",
        "\n",
        "#4-factor\n",
        "nk4_perfs = [3.6608014297485347,\n",
        "3.8341940339406326,\n",
        "3.976153351465861,\n",
        "3.234516398111979,\n",
        "3.4700066741307576, ]\n",
        "\n",
        "#6-factor\n",
        "nk6_perfs = [8.950920476913453,\n",
        "10.350576349894206,\n",
        "10.162520256042482,\n",
        "9.243894300460816,\n",
        "10.51370607058207, ]\n",
        "\n",
        "#9-factor\n",
        "nk9_perfs = [3.516380707422892,\n",
        "3.3691013908386225,\n",
        "4.0688151931762695,\n",
        "3.250964085261027,\n",
        "3.072849206924438, ]\n",
        "\n",
        "#18-factor\n",
        "nk18_perfs = [3.4153781859079997,\n",
        "3.2008409102757773,\n",
        "2.9720478153228758,\n",
        "3.280436124801636,\n",
        "3.933880195617675, ]\n",
        "\n",
        "#36-factor\n",
        "nk36_perfs = [3.753356472651164,\n",
        "4.154083093007405,\n",
        "3.461827759742737,\n",
        "3.7385053253173837,\n",
        "3.3300649420420334, ]\n",
        "\n",
        "\n",
        "num_factors_tested = [2, 4, 6, 9, 18, 36]\n",
        "means_perf = [np.mean(x) for x in [nk2_perfs, nk4_perfs, nk6_perfs, nk9_perfs, nk18_perfs, nk36_perfs]]\n",
        "plt.plot(num_factors_tested, means_perf)\n",
        "plt.scatter(num_factors_tested, means_perf)\n",
        "plt.xlabel(\"Number of Factors Tested\")\n",
        "plt.ylabel(\"Mean Performance\")\n",
        "plt.title(\"Social Preference Factor Selection\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "num_factors_tested = [2, 4, 9, 18, 36]\n",
        "means_perf = [np.mean(x) for x in [nk2_perfs, nk4_perfs, nk9_perfs, nk18_perfs, nk36_perfs]]\n",
        "plt.plot(num_factors_tested, means_perf)\n",
        "plt.scatter(num_factors_tested, means_perf)\n",
        "plt.xlabel(\"Number of Factors Tested\")\n",
        "plt.ylabel(\"Mean Performance\")\n",
        "plt.title(\"Social Preference Factor Selection\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "apEdbBXpHR-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "naive_adjacency_tensor = np.array([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]])\n",
        "print(naive_adjacency_tensor.shape)\n",
        "\n",
        "print(naive_adjacency_tensor[:9,:9,:])"
      ],
      "metadata": {
        "id": "iflERkH2MIzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "unique_mice_names = [\n",
        "    'Mouse8881', 'Mouse6991', 'Mouse5333', 'Mouse699L', 'Mouse6664', 'Mouse8884',\n",
        "    'Mouse8893', 'Mouse6990', 'Mouse0641', 'Mouse6992', 'Mouse8891', 'Mouse0642',\n",
        "    'Mouse0643', 'Mouse533L', 'Mouse0631', 'Mouse0632', 'Mouse0640', 'Mouse6662',\n",
        "    'Mouse0644', 'Mouse0633', 'Mouse6674', 'Mouse0630', 'Mouse8882', 'Mouse8894',\n",
        "    'Mouse5321', 'Mouse0634', 'Mouse5331', 'Mouse5332',\n",
        "]\n",
        "keys_of_interest = [\n",
        "    'Amy_BLA_03', 'Amy_CeA_01', 'Amy_CeA_02', 'Cg_Cx_R_01', 'Hipp_01', 'NAc_Core_01',\n",
        "    'NAc_Core_02', 'NAc_Shell_01', 'NAc_Shell_02', 'NAc_Shell_03', 'NAc_Shell_04',\n",
        "    'PrL_Cx_R_01', 'VTA_L_01', 'VTA_L_02', 'VTA_R_01', 'VTA_R_02'\n",
        "]\n",
        "print(\"len(unique_mice_names) == \", len(unique_mice_names))\n",
        "print(\"len(keys_of_interest) == \", len(keys_of_interest))\n",
        "\n",
        "NUM_HOLDOUT_MICE = 8\n",
        "NUM_TRAIN_MICE = 16\n",
        "NUM_VAL_MICE = 4\n",
        "NUM_CV_FOLDS = 5\n",
        "\n",
        "print(\"unique_mice_names == \", unique_mice_names)\n",
        "random.shuffle(unique_mice_names)\n",
        "print(\"post-shuffle unique_mice_names == \", unique_mice_names)\n",
        "\n",
        "holdout_mice = unique_mice_names[-1*NUM_HOLDOUT_MICE:]\n",
        "mice_for_cv_exps = unique_mice_names[:-1*NUM_HOLDOUT_MICE]\n",
        "print(\"holdout_mice == \", holdout_mice)\n",
        "print(\"mice_for_cv_exps == \", mice_for_cv_exps)\n",
        "\n",
        "for i in range(NUM_CV_FOLDS):\n",
        "    print(\"i == \", i)\n",
        "    val_mice = mice_for_cv_exps[i*NUM_VAL_MICE:(i+1)*NUM_VAL_MICE]\n",
        "    train_mice = [mouse for mouse in mice_for_cv_exps if mouse not in val_mice]\n",
        "    print(\"\\t val_mice == \", val_mice)\n",
        "    print(\"\\t train_mice == \", train_mice)"
      ],
      "metadata": {
        "id": "ziNLK40TDSwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proper_s_label_files = [\n",
        "    'Mouse8881_100617_SocialPreference_Class.mat', 'Mouse699L_061616_SocialPreference_Class.mat', 'Mouse6992_061416_SocialPreference_Class.mat', 'Mouse6662_032618_SocialPreference_Class.mat', 'Mouse8894_100517_SocialPreference_Class.mat', 'Mouse8881_092917_SocialPreference_Class.mat', 'Mouse8893_090917_SocialPreference_Class.mat', 'Mouse8884_100617_SocialPreference_Class.mat', 'Mouse6992_060916_SocialPreference_Class.mat', 'Mouse5321_052616_SocialPreference_Class.mat', 'Mouse6662_040218_SocialPreference_Class.mat', 'Mouse0632_092517_SocialPreference_Class.mat', 'Mouse8882_092217_SocialPreference_Class.mat', 'Mouse6674_041118_SocialPreference_Class.mat', 'Mouse0634_092017_SocialPreference_Class.mat', 'Mouse8882_100217_SocialPreference_Class.mat', 'Mouse8894_091417_SocialPreference_Class.mat', 'Mouse0633_100417_SocialPreference_Class.mat', 'Mouse0631_100617_SocialPreference_Class.mat', 'Mouse0643_091917_SocialPreference_Class.mat', 'Mouse0632_091817_SocialPreference_Class.mat', 'Mouse0634_100917_SocialPreference_Class.mat', 'Mouse533L_070716_SocialPreference_Class.mat', 'Mouse6662_040418_SocialPreference_Class.mat', 'Mouse5333_060916_SocialPreference_Class.mat', 'Mouse6992_052416_SocialPreference_Class.mat', 'Mouse5331_070716_SocialPreference_Class.mat', 'Mouse6662_040918_SocialPreference_Class.mat', 'Mouse5333_061416_SocialPreference_Class.mat', 'Mouse6664_040218_SocialPreference_Class.mat', 'Mouse0634_092917_SocialPreference_Class.mat', 'Mouse6991_060216_SocialPreference_Class.mat', 'Mouse8893_091417_SocialPreference_Class.mat', 'Mouse0640_100517_SocialPreference_Class.mat', 'Mouse5321_060716_SocialPreference_Class.mat', 'Mouse0644_101017_SocialPreference_Class.mat', 'Mouse0631_092017_SocialPreference_Class.mat', 'Mouse8893_091617_SocialPreference_Class.mat', 'Mouse6664_040618_SocialPreference_Class.mat', 'Mouse0632_092917_SocialPreference_Class.mat', 'Mouse533L_052616_SocialPreference_Class.mat', 'Mouse8884_100417_SocialPreference_Class.mat', 'Mouse0631_092217_SocialPreference_Class.mat', 'Mouse5321_060216_SocialPreference_Class.mat', 'Mouse0643_091417_SocialPreference_Class.mat', 'Mouse8882_091117_SocialPreference_Class.mat', 'Mouse8893_092617_SocialPreference_Class.mat', 'Mouse8884_092917_SocialPreference_Class.mat', 'Mouse6662_033018_SocialPreference_Class.mat', 'Mouse0632_100617_SocialPreference_Class.mat', 'Mouse8891_100317_SocialPreference_Class.mat', 'Mouse5321_060916_SocialPreference_Class.mat', 'Mouse6674_041618_SocialPreference_Class.mat', 'Mouse6662_041118_SocialPreference_Class.mat', 'Mouse0641_091917_SocialPreference_Class.mat', 'Mouse533L_060216_SocialPreference_Class.mat', 'Mouse6664_032618_SocialPreference_Class.mat', 'Mouse0642_091617_SocialPreference_Class.mat', 'Mouse8893_093017_SocialPreference_Class.mat', 'Mouse6992_060716_SocialPreference_Class.mat', 'Mouse6991_070716_SocialPreference_Class.mat', 'Mouse8884_091117_SocialPreference_Class.mat', 'Mouse0644_093017_SocialPreference_Class.mat', 'Mouse0640_100717_SocialPreference_Class.mat', 'Mouse8891_090917_SocialPreference_Class.mat', 'Mouse5332_060216_SocialPreference_Class.mat', 'Mouse0642_093017_SocialPreference_Class.mat', 'Mouse0634_091817_SocialPreference_Class.mat', 'Mouse6990_060916_SocialPreference_Class.mat', 'Mouse0634_092517_SocialPreference_Class.mat', 'Mouse0644_100517_SocialPreference_Class.mat', 'Mouse6992_053116_SocialPreference_Class.mat', 'Mouse8891_091617_SocialPreference_Class.mat', 'Mouse8884_092217_SocialPreference_Class.mat', 'Mouse5321_061416_SocialPreference_Class.mat', 'Mouse8881_092217_SocialPreference_Class.mat', 'Mouse0633_092017_SocialPreference_Class.mat', 'Mouse0633_092917_SocialPreference_Class.mat', 'Mouse0640_092617_SocialPreference_Class.mat', 'Mouse0632_100417_SocialPreference_Class.mat', 'Mouse8891_092617_SocialPreference_Class.mat', 'Mouse533L_061416_SocialPreference_Class.mat', 'Mouse0633_092217_SocialPreference_Class.mat', 'Mouse6674_040418_SocialPreference_Class.mat', 'Mouse0631_100217_SocialPreference_Class.mat', 'Mouse0632_091517_SocialPreference_Class.mat', 'Mouse0631_100417_SocialPreference_Class.mat', 'Mouse6674_040618_SocialPreference_Class.mat', 'Mouse0633_091517_SocialPreference_Class.mat', 'Mouse6990_060716_SocialPreference_Class.mat', 'Mouse8881_091117_SocialPreference_Class.mat', 'Mouse0631_091817_SocialPreference_Class.mat', 'Mouse0642_092117_SocialPreference_Class.mat', 'Mouse6674_040218_SocialPreference_Class.mat', 'Mouse5321_061616_SocialPreference_Class.mat', 'Mouse8893_091217_SocialPreference_Class.mat', 'Mouse0634_092217_SocialPreference_Class.mat', 'Mouse8882_092517_SocialPreference_Class.mat', 'Mouse5331_070516_SocialPreference_Class.mat', 'Mouse6990_061416_SocialPreference_Class.mat', 'Mouse8882_092917_SocialPreference_Class.mat', 'Mouse0640_091417_SocialPreference_Class.mat', 'Mouse0642_100717_SocialPreference_Class.mat', 'Mouse5331_060716_SocialPreference_Class.mat', 'Mouse6990_052616_SocialPreference_Class.mat', 'Mouse6991_052416_SocialPreference_Class.mat', 'Mouse0644_092317_SocialPreference_Class.mat', 'Mouse6674_032618_SocialPreference_Class.mat', 'Mouse6662_041618_SocialPreference_Class.mat', 'Mouse8884_091517_SocialPreference_Class.mat', 'Mouse8891_093017_SocialPreference_Class.mat', 'Mouse0633_100917_SocialPreference_Class.mat', 'Mouse0643_092617_SocialPreference_Class.mat', 'Mouse8894_091617_SocialPreference_Class.mat', 'Mouse0630_091517_SocialPreference_Class.mat', 'Mouse8893_092317_SocialPreference_Class.mat', 'Mouse8882_100417_SocialPreference_Class.mat', 'Mouse0630_100217_SocialPreference_Class.mat', 'Mouse0640_092317_SocialPreference_Class.mat', 'Mouse6990_061616_SocialPreference_Class.mat', 'Mouse8882_091317_SocialPreference_Class.mat', 'Mouse0632_100217_SocialPreference_Class.mat', 'Mouse0630_092217_SocialPreference_Class.mat', 'Mouse0642_091917_SocialPreference_Class.mat', 'Mouse8884_100217_SocialPreference_Class.mat', 'Mouse6992_061616_SocialPreference_Class.mat', 'Mouse0644_100717_SocialPreference_Class.mat', 'Mouse0642_091417_SocialPreference_Class.mat', 'Mouse0641_100517_SocialPreference_Class.mat', 'Mouse0632_092017_SocialPreference_Class.mat', 'Mouse0631_092517_SocialPreference_Class.mat', 'Mouse8894_093017_SocialPreference_Class.mat', 'Mouse0631_092917_SocialPreference_Class.mat', 'Mouse699L_060216_SocialPreference_Class.mat', 'Mouse6991_060716_SocialPreference_Class.mat', 'Mouse0633_100217_SocialPreference_Class.mat', 'Mouse8884_092517_SocialPreference_Class.mat', 'Mouse0633_100617_SocialPreference_Class.mat', 'Mouse6674_041318_SocialPreference_Class.mat', 'Mouse5332_052616_SocialPreference_Class.mat', 'Mouse8891_091417_SocialPreference_Class.mat', 'Mouse6664_040918_SocialPreference_Class.mat', 'Mouse699L_061416_SocialPreference_Class.mat', 'Mouse8891_100517_SocialPreference_Class.mat', 'Mouse0641_100317_SocialPreference_Class.mat', 'Mouse0634_091517_SocialPreference_Class.mat', 'Mouse6662_040618_SocialPreference_Class.mat', 'Mouse0630_100617_SocialPreference_Class.mat', 'Mouse8894_092617_SocialPreference_Class.mat', 'Mouse8894_092317_SocialPreference_Class.mat', 'Mouse6992_052616_SocialPreference_Class.mat', 'Mouse8882_090817_SocialPreference_Class.mat', 'Mouse8893_100517_SocialPreference_Class.mat', 'Mouse5333_060716_SocialPreference_Class.mat', 'Mouse533L_070516_SocialPreference_Class.mat', 'Mouse8884_090817_SocialPreference_Class.mat', 'Mouse8882_100617_SocialPreference_Class.mat', 'Mouse0634_100617_SocialPreference_Class.mat', 'Mouse0630_092517_SocialPreference_Class.mat', 'Mouse0632_092217_SocialPreference_Class.mat', 'Mouse0642_100317_SocialPreference_Class.mat', 'Mouse5333_070516_SocialPreference_Class.mat', 'Mouse699L_053116_SocialPreference_Class.mat', 'Mouse8894_100717_SocialPreference_Class.mat', 'Mouse8881_100217_SocialPreference_Class.mat', 'Mouse0641_091417_SocialPreference_Class.mat', 'Mouse0630_091817_SocialPreference_Class.mat', 'Mouse6991_052616_SocialPreference_Class.mat', 'Mouse0633_091817_SocialPreference_Class.mat', 'Mouse0642_101017_SocialPreference_Class.mat', 'Mouse0641_092117_SocialPreference_Class.mat', 'Mouse0641_092617_SocialPreference_Class.mat', 'Mouse5332_061416_SocialPreference_Class.mat', 'Mouse699L_070516_SocialPreference_Class.mat', 'Mouse0641_100717_SocialPreference_Class.mat', 'Mouse0632_100917_SocialPreference_Class.mat', 'Mouse0640_091617_SocialPreference_Class.mat', 'Mouse5333_060216_SocialPreference_Class.mat', 'Mouse699L_052616_SocialPreference_Class.mat', 'Mouse5332_052416_SocialPreference_Class.mat', 'Mouse6664_040418_SocialPreference_Class.mat', 'Mouse0641_091617_SocialPreference_Class.mat', 'Mouse8881_091317_SocialPreference_Class.mat', 'Mouse0643_092317_SocialPreference_Class.mat', 'Mouse5332_070716_SocialPreference_Class.mat', 'Mouse6992_060216_SocialPreference_Class.mat', 'Mouse0633_092517_SocialPreference_Class.mat', 'Mouse6674_040918_SocialPreference_Class.mat', 'Mouse6662_041318_SocialPreference_Class.mat', 'Mouse6991_070516_SocialPreference_Class.mat', 'Mouse0634_100417_SocialPreference_Class.mat', 'Mouse533L_060716_SocialPreference_Class.mat', 'Mouse8891_092317_SocialPreference_Class.mat', 'Mouse5321_053116_SocialPreference_Class.mat', 'Mouse0643_092117_SocialPreference_Class.mat', 'Mouse0633_091417_SocialPreference_Class.mat', 'Mouse8881_090817_SocialPreference_Class.mat', 'Mouse8893_100317_SocialPreference_Class.mat', 'Mouse0644_091617_SocialPreference_Class.mat', 'Mouse5331_061616_SocialPreference_Class.mat', 'Mouse0632_091417_SocialPreference_Class.mat', 'Mouse0642_092317_SocialPreference_Class.mat', 'Mouse0631_091417_SocialPreference_Class.mat', 'Mouse0642_100517_SocialPreference_Class.mat', 'Mouse0634_100217_SocialPreference_Class.mat', 'Mouse0630_100917_SocialPreference_Class.mat', 'Mouse0643_100317_SocialPreference_Class.mat', 'Mouse0630_091417_SocialPreference_Class.mat', 'Mouse0643_100717_SocialPreference_Class.mat', 'Mouse5333_061616_SocialPreference_Class.mat', 'Mouse0643_093017_SocialPreference_Class.mat', 'Mouse0644_092117_SocialPreference_Class.mat', 'Mouse6992_070716_SocialPreference_Class.mat', 'Mouse5333_070716_SocialPreference_Class.mat', 'Mouse0630_100417_SocialPreference_Class.mat', 'Mouse6664_041118_SocialPreference_Class.mat', 'Mouse8884_091317_SocialPreference_Class.mat', 'Mouse0634_091417_SocialPreference_Class.mat', 'Mouse0641_101017_SocialPreference_Class.mat', 'Mouse0644_100317_SocialPreference_Class.mat', 'Mouse8894_100317_SocialPreference_Class.mat', 'Mouse533L_053116_SocialPreference_Class.mat', 'Mouse0644_091917_SocialPreference_Class.mat', 'Mouse5331_061416_SocialPreference_Class.mat', 'Mouse5332_061616_SocialPreference_Class.mat', 'Mouse8894_090917_SocialPreference_Class.mat', 'Mouse5332_053116_SocialPreference_Class.mat', 'Mouse8893_100717_SocialPreference_Class.mat', 'Mouse6991_061616_SocialPreference_Class.mat', 'Mouse0630_092017_SocialPreference_Class.mat', 'Mouse8891_091217_SocialPreference_Class.mat', 'Mouse8881_091517_SocialPreference_Class.mat', 'Mouse5331_052416_SocialPreference_Class.mat', 'Mouse0640_092117_SocialPreference_Class.mat', 'Mouse699L_052416_SocialPreference_Class.mat', 'Mouse5331_053116_SocialPreference_Class.mat', 'Mouse8882_091517_SocialPreference_Class.mat', 'Mouse0640_093017_SocialPreference_Class.mat', 'Mouse8891_100717_SocialPreference_Class.mat', 'Mouse0631_100917_SocialPreference_Class.mat', 'Mouse0640_101017_SocialPreference_Class.mat', 'Mouse0640_100317_SocialPreference_Class.mat', 'Mouse0641_092317_SocialPreference_Class.mat', 'Mouse0641_093017_SocialPreference_Class.mat', 'Mouse6664_041318_SocialPreference_Class.mat', 'Mouse6664_041618_SocialPreference_Class.mat', 'Mouse8894_091217_SocialPreference_Class.mat', 'Mouse8881_092517_SocialPreference_Class.mat', 'Mouse5333_052616_SocialPreference_Class.mat', 'Mouse0640_091917_SocialPreference_Class.mat', 'Mouse5333_052416_SocialPreference_Class.mat', 'Mouse6991_061416_SocialPreference_Class.mat', 'Mouse6991_060916_SocialPreference_Class.mat', 'Mouse5332_070516_SocialPreference_Class.mat', 'Mouse0644_092617_SocialPreference_Class.mat', 'Mouse8881_100417_SocialPreference_Class.mat', 'Mouse0631_091517_SocialPreference_Class.mat', 'Mouse0644_091417_SocialPreference_Class.mat', 'Mouse5332_060716_SocialPreference_Class.mat', 'Mouse0630_092917_SocialPreference_Class.mat', 'Mouse6991_053116_SocialPreference_Class.mat', 'Mouse0643_100517_SocialPreference_Class.mat', 'Mouse0643_091617_SocialPreference_Class.mat', 'Mouse0642_092617_SocialPreference_Class.mat', 'Mouse6992_070516_SocialPreference_Class.mat', 'Mouse0643_101017_SocialPreference_Class.mat', 'Mouse699L_070716_SocialPreference_Class.mat'\n",
        "]\n",
        "proper_o_label_files = [\n",
        "    'Mouse8881_100617_SocialPreference_Class.mat', 'Mouse699L_061616_SocialPreference_Class.mat', 'Mouse6992_061416_SocialPreference_Class.mat', 'Mouse6662_032618_SocialPreference_Class.mat', 'Mouse8894_100517_SocialPreference_Class.mat', 'Mouse8881_092917_SocialPreference_Class.mat', 'Mouse8893_090917_SocialPreference_Class.mat', 'Mouse8884_100617_SocialPreference_Class.mat', 'Mouse6992_060916_SocialPreference_Class.mat', 'Mouse5321_052616_SocialPreference_Class.mat', 'Mouse6662_040218_SocialPreference_Class.mat', 'Mouse0632_092517_SocialPreference_Class.mat', 'Mouse8882_092217_SocialPreference_Class.mat', 'Mouse6674_041118_SocialPreference_Class.mat', 'Mouse0634_092017_SocialPreference_Class.mat', 'Mouse8882_100217_SocialPreference_Class.mat', 'Mouse8894_091417_SocialPreference_Class.mat', 'Mouse0633_100417_SocialPreference_Class.mat', 'Mouse0631_100617_SocialPreference_Class.mat', 'Mouse0643_091917_SocialPreference_Class.mat', 'Mouse0632_091817_SocialPreference_Class.mat', 'Mouse0634_100917_SocialPreference_Class.mat', 'Mouse533L_070716_SocialPreference_Class.mat', 'Mouse6662_040418_SocialPreference_Class.mat', 'Mouse5333_060916_SocialPreference_Class.mat', 'Mouse6992_052416_SocialPreference_Class.mat', 'Mouse5331_070716_SocialPreference_Class.mat', 'Mouse6662_040918_SocialPreference_Class.mat', 'Mouse5333_061416_SocialPreference_Class.mat', 'Mouse6664_040218_SocialPreference_Class.mat', 'Mouse0634_092917_SocialPreference_Class.mat', 'Mouse6991_060216_SocialPreference_Class.mat', 'Mouse8893_091417_SocialPreference_Class.mat', 'Mouse0640_100517_SocialPreference_Class.mat', 'Mouse5321_060716_SocialPreference_Class.mat', 'Mouse0644_101017_SocialPreference_Class.mat', 'Mouse0631_092017_SocialPreference_Class.mat', 'Mouse8893_091617_SocialPreference_Class.mat', 'Mouse6664_040618_SocialPreference_Class.mat', 'Mouse0632_092917_SocialPreference_Class.mat', 'Mouse533L_052616_SocialPreference_Class.mat', 'Mouse8884_100417_SocialPreference_Class.mat', 'Mouse0631_092217_SocialPreference_Class.mat', 'Mouse5321_060216_SocialPreference_Class.mat', 'Mouse0643_091417_SocialPreference_Class.mat', 'Mouse8882_091117_SocialPreference_Class.mat', 'Mouse8893_092617_SocialPreference_Class.mat', 'Mouse8884_092917_SocialPreference_Class.mat', 'Mouse6662_033018_SocialPreference_Class.mat', 'Mouse0632_100617_SocialPreference_Class.mat', 'Mouse8891_100317_SocialPreference_Class.mat', 'Mouse5321_060916_SocialPreference_Class.mat', 'Mouse6674_041618_SocialPreference_Class.mat', 'Mouse6662_041118_SocialPreference_Class.mat', 'Mouse0641_091917_SocialPreference_Class.mat', 'Mouse533L_060216_SocialPreference_Class.mat', 'Mouse6664_032618_SocialPreference_Class.mat', 'Mouse0642_091617_SocialPreference_Class.mat', 'Mouse8893_093017_SocialPreference_Class.mat', 'Mouse6992_060716_SocialPreference_Class.mat', 'Mouse6991_070716_SocialPreference_Class.mat', 'Mouse8884_091117_SocialPreference_Class.mat', 'Mouse0644_093017_SocialPreference_Class.mat', 'Mouse0640_100717_SocialPreference_Class.mat', 'Mouse8891_090917_SocialPreference_Class.mat', 'Mouse5332_060216_SocialPreference_Class.mat', 'Mouse0642_093017_SocialPreference_Class.mat', 'Mouse0634_091817_SocialPreference_Class.mat', 'Mouse6990_060916_SocialPreference_Class.mat', 'Mouse0634_092517_SocialPreference_Class.mat', 'Mouse0644_100517_SocialPreference_Class.mat', 'Mouse6992_053116_SocialPreference_Class.mat', 'Mouse8891_091617_SocialPreference_Class.mat', 'Mouse8884_092217_SocialPreference_Class.mat', 'Mouse5321_061416_SocialPreference_Class.mat', 'Mouse8881_092217_SocialPreference_Class.mat', 'Mouse0633_092017_SocialPreference_Class.mat', 'Mouse0633_092917_SocialPreference_Class.mat', 'Mouse0640_092617_SocialPreference_Class.mat', 'Mouse0632_100417_SocialPreference_Class.mat', 'Mouse8891_092617_SocialPreference_Class.mat', 'Mouse533L_061416_SocialPreference_Class.mat', 'Mouse0633_092217_SocialPreference_Class.mat', 'Mouse6674_040418_SocialPreference_Class.mat', 'Mouse0631_100217_SocialPreference_Class.mat', 'Mouse0632_091517_SocialPreference_Class.mat', 'Mouse0631_100417_SocialPreference_Class.mat', 'Mouse6674_040618_SocialPreference_Class.mat', 'Mouse0633_091517_SocialPreference_Class.mat', 'Mouse6990_060716_SocialPreference_Class.mat', 'Mouse8881_091117_SocialPreference_Class.mat', 'Mouse0631_091817_SocialPreference_Class.mat', 'Mouse0642_092117_SocialPreference_Class.mat', 'Mouse6674_040218_SocialPreference_Class.mat', 'Mouse5321_061616_SocialPreference_Class.mat', 'Mouse8893_091217_SocialPreference_Class.mat', 'Mouse0634_092217_SocialPreference_Class.mat', 'Mouse8882_092517_SocialPreference_Class.mat', 'Mouse5331_070516_SocialPreference_Class.mat', 'Mouse6990_061416_SocialPreference_Class.mat', 'Mouse8882_092917_SocialPreference_Class.mat', 'Mouse0640_091417_SocialPreference_Class.mat', 'Mouse0642_100717_SocialPreference_Class.mat', 'Mouse5331_060716_SocialPreference_Class.mat', 'Mouse6990_052616_SocialPreference_Class.mat', 'Mouse6991_052416_SocialPreference_Class.mat', 'Mouse0644_092317_SocialPreference_Class.mat', 'Mouse6674_032618_SocialPreference_Class.mat', 'Mouse6662_041618_SocialPreference_Class.mat', 'Mouse8884_091517_SocialPreference_Class.mat', 'Mouse8891_093017_SocialPreference_Class.mat', 'Mouse0633_100917_SocialPreference_Class.mat', 'Mouse0643_092617_SocialPreference_Class.mat', 'Mouse8894_091617_SocialPreference_Class.mat', 'Mouse0630_091517_SocialPreference_Class.mat', 'Mouse8893_092317_SocialPreference_Class.mat', 'Mouse8882_100417_SocialPreference_Class.mat', 'Mouse0630_100217_SocialPreference_Class.mat', 'Mouse0640_092317_SocialPreference_Class.mat', 'Mouse6990_061616_SocialPreference_Class.mat', 'Mouse8882_091317_SocialPreference_Class.mat', 'Mouse0632_100217_SocialPreference_Class.mat', 'Mouse0630_092217_SocialPreference_Class.mat', 'Mouse0642_091917_SocialPreference_Class.mat', 'Mouse8884_100217_SocialPreference_Class.mat', 'Mouse6992_061616_SocialPreference_Class.mat', 'Mouse0644_100717_SocialPreference_Class.mat', 'Mouse0642_091417_SocialPreference_Class.mat', 'Mouse0641_100517_SocialPreference_Class.mat', 'Mouse0632_092017_SocialPreference_Class.mat', 'Mouse0631_092517_SocialPreference_Class.mat', 'Mouse8894_093017_SocialPreference_Class.mat', 'Mouse0631_092917_SocialPreference_Class.mat', 'Mouse699L_060216_SocialPreference_Class.mat', 'Mouse6991_060716_SocialPreference_Class.mat', 'Mouse0633_100217_SocialPreference_Class.mat', 'Mouse8884_092517_SocialPreference_Class.mat', 'Mouse0633_100617_SocialPreference_Class.mat', 'Mouse6674_041318_SocialPreference_Class.mat', 'Mouse5332_052616_SocialPreference_Class.mat', 'Mouse8891_091417_SocialPreference_Class.mat', 'Mouse6664_040918_SocialPreference_Class.mat', 'Mouse699L_061416_SocialPreference_Class.mat', 'Mouse8891_100517_SocialPreference_Class.mat', 'Mouse0641_100317_SocialPreference_Class.mat', 'Mouse0634_091517_SocialPreference_Class.mat', 'Mouse6662_040618_SocialPreference_Class.mat', 'Mouse0630_100617_SocialPreference_Class.mat', 'Mouse8894_092617_SocialPreference_Class.mat', 'Mouse8894_092317_SocialPreference_Class.mat', 'Mouse6992_052616_SocialPreference_Class.mat', 'Mouse8882_090817_SocialPreference_Class.mat', 'Mouse8893_100517_SocialPreference_Class.mat', 'Mouse5333_060716_SocialPreference_Class.mat', 'Mouse533L_070516_SocialPreference_Class.mat', 'Mouse8884_090817_SocialPreference_Class.mat', 'Mouse8882_100617_SocialPreference_Class.mat', 'Mouse0634_100617_SocialPreference_Class.mat', 'Mouse0630_092517_SocialPreference_Class.mat', 'Mouse0632_092217_SocialPreference_Class.mat', 'Mouse0642_100317_SocialPreference_Class.mat', 'Mouse5333_070516_SocialPreference_Class.mat', 'Mouse699L_053116_SocialPreference_Class.mat', 'Mouse8894_100717_SocialPreference_Class.mat', 'Mouse8881_100217_SocialPreference_Class.mat', 'Mouse0641_091417_SocialPreference_Class.mat', 'Mouse0630_091817_SocialPreference_Class.mat', 'Mouse6991_052616_SocialPreference_Class.mat', 'Mouse0633_091817_SocialPreference_Class.mat', 'Mouse0642_101017_SocialPreference_Class.mat', 'Mouse0641_092117_SocialPreference_Class.mat', 'Mouse0641_092617_SocialPreference_Class.mat', 'Mouse5332_061416_SocialPreference_Class.mat', 'Mouse699L_070516_SocialPreference_Class.mat', 'Mouse0641_100717_SocialPreference_Class.mat', 'Mouse0632_100917_SocialPreference_Class.mat', 'Mouse0640_091617_SocialPreference_Class.mat', 'Mouse5333_060216_SocialPreference_Class.mat', 'Mouse699L_052616_SocialPreference_Class.mat', 'Mouse5332_052416_SocialPreference_Class.mat', 'Mouse6664_040418_SocialPreference_Class.mat', 'Mouse0641_091617_SocialPreference_Class.mat', 'Mouse8881_091317_SocialPreference_Class.mat', 'Mouse0643_092317_SocialPreference_Class.mat', 'Mouse5332_070716_SocialPreference_Class.mat', 'Mouse6992_060216_SocialPreference_Class.mat', 'Mouse0633_092517_SocialPreference_Class.mat', 'Mouse6674_040918_SocialPreference_Class.mat', 'Mouse6662_041318_SocialPreference_Class.mat', 'Mouse6991_070516_SocialPreference_Class.mat', 'Mouse0634_100417_SocialPreference_Class.mat', 'Mouse533L_060716_SocialPreference_Class.mat', 'Mouse8891_092317_SocialPreference_Class.mat', 'Mouse5321_053116_SocialPreference_Class.mat', 'Mouse0643_092117_SocialPreference_Class.mat', 'Mouse0633_091417_SocialPreference_Class.mat', 'Mouse8881_090817_SocialPreference_Class.mat', 'Mouse8893_100317_SocialPreference_Class.mat', 'Mouse0644_091617_SocialPreference_Class.mat', 'Mouse5331_061616_SocialPreference_Class.mat', 'Mouse0632_091417_SocialPreference_Class.mat', 'Mouse0642_092317_SocialPreference_Class.mat', 'Mouse0631_091417_SocialPreference_Class.mat', 'Mouse0642_100517_SocialPreference_Class.mat', 'Mouse0634_100217_SocialPreference_Class.mat', 'Mouse0630_100917_SocialPreference_Class.mat', 'Mouse0643_100317_SocialPreference_Class.mat', 'Mouse0630_091417_SocialPreference_Class.mat', 'Mouse0643_100717_SocialPreference_Class.mat', 'Mouse5333_061616_SocialPreference_Class.mat', 'Mouse0643_093017_SocialPreference_Class.mat', 'Mouse0644_092117_SocialPreference_Class.mat', 'Mouse6992_070716_SocialPreference_Class.mat', 'Mouse5333_070716_SocialPreference_Class.mat', 'Mouse0630_100417_SocialPreference_Class.mat', 'Mouse6664_041118_SocialPreference_Class.mat', 'Mouse8884_091317_SocialPreference_Class.mat', 'Mouse0634_091417_SocialPreference_Class.mat', 'Mouse0641_101017_SocialPreference_Class.mat', 'Mouse0644_100317_SocialPreference_Class.mat', 'Mouse8894_100317_SocialPreference_Class.mat', 'Mouse533L_053116_SocialPreference_Class.mat', 'Mouse0644_091917_SocialPreference_Class.mat', 'Mouse5331_061416_SocialPreference_Class.mat', 'Mouse5332_061616_SocialPreference_Class.mat', 'Mouse8894_090917_SocialPreference_Class.mat', 'Mouse5332_053116_SocialPreference_Class.mat', 'Mouse8893_100717_SocialPreference_Class.mat', 'Mouse6991_061616_SocialPreference_Class.mat', 'Mouse0630_092017_SocialPreference_Class.mat', 'Mouse8891_091217_SocialPreference_Class.mat', 'Mouse8881_091517_SocialPreference_Class.mat', 'Mouse5331_052416_SocialPreference_Class.mat', 'Mouse0640_092117_SocialPreference_Class.mat', 'Mouse699L_052416_SocialPreference_Class.mat', 'Mouse5331_053116_SocialPreference_Class.mat', 'Mouse8882_091517_SocialPreference_Class.mat', 'Mouse0640_093017_SocialPreference_Class.mat', 'Mouse8891_100717_SocialPreference_Class.mat', 'Mouse0631_100917_SocialPreference_Class.mat', 'Mouse0640_101017_SocialPreference_Class.mat', 'Mouse0640_100317_SocialPreference_Class.mat', 'Mouse0641_092317_SocialPreference_Class.mat', 'Mouse0641_093017_SocialPreference_Class.mat', 'Mouse6664_041318_SocialPreference_Class.mat', 'Mouse6664_041618_SocialPreference_Class.mat', 'Mouse8894_091217_SocialPreference_Class.mat', 'Mouse8881_092517_SocialPreference_Class.mat', 'Mouse5333_052616_SocialPreference_Class.mat', 'Mouse0640_091917_SocialPreference_Class.mat', 'Mouse5333_052416_SocialPreference_Class.mat', 'Mouse6991_061416_SocialPreference_Class.mat', 'Mouse6991_060916_SocialPreference_Class.mat', 'Mouse5332_070516_SocialPreference_Class.mat', 'Mouse0644_092617_SocialPreference_Class.mat', 'Mouse8881_100417_SocialPreference_Class.mat', 'Mouse0631_091517_SocialPreference_Class.mat', 'Mouse0644_091417_SocialPreference_Class.mat', 'Mouse5332_060716_SocialPreference_Class.mat', 'Mouse0630_092917_SocialPreference_Class.mat', 'Mouse0643_100517_SocialPreference_Class.mat', 'Mouse0643_091617_SocialPreference_Class.mat', 'Mouse0642_092617_SocialPreference_Class.mat', 'Mouse6992_070516_SocialPreference_Class.mat', 'Mouse0643_101017_SocialPreference_Class.mat', 'Mouse699L_070716_SocialPreference_Class.mat'\n",
        "]\n",
        "\n",
        "proper_label_files = list(set([x for x in proper_s_label_files+proper_o_label_files if x in proper_s_label_files and x in proper_o_label_files]))\n",
        "print(len(proper_label_files))"
      ],
      "metadata": {
        "id": "lxPt8PHGfKiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# TST Experiment Analyses"
      ],
      "metadata": {
        "id": "WPaa_NZjqq3w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing TST REDCLIFF-S GC Models"
      ],
      "metadata": {
        "id": "8Kxo1bJgqmWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torcheeg"
      ],
      "metadata": {
        "id": "qmsAGiBYqxYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch_scatter"
      ],
      "metadata": {
        "id": "NKNDy0V1viIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------------------------------------------------------------------------\n",
        "# FILE DESCRIPTION\n",
        "# ----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# File:  plot.py\n",
        "# Author:  anonymous\n",
        "# Date written:  01-18-2022\n",
        "# Last modified:  10-25-2023\n",
        "\n",
        "r\"\"\"\n",
        "Description:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------------------------------------------------------\n",
        "# IMPORT STATEMENTS\n",
        "# ----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# Import statements\n",
        "import numpy as np\n",
        "from scipy.stats import pearsonr\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import to_rgba, LinearSegmentedColormap\n",
        "from matplotlib.patches import Polygon\n",
        "import seaborn as sns\n",
        "\n",
        "# Constants\n",
        "R1 = 1.0  # inner radius of power plots\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------------------------------------------------------\n",
        "# FUNCTION DEFINITIONS\n",
        "# ----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# Chord plot\n",
        "def chord_plot(\n",
        "    x,\n",
        "    rois=None,\n",
        "    freqs=None,\n",
        "    freq_ticks=None,\n",
        "    max_alpha=0.7,\n",
        "    buffer_percent=1.0,\n",
        "    outer_radius=1.2,\n",
        "    min_max_quantiles=(0.5, 0.9),\n",
        "    color=None,\n",
        "    cmap=None,\n",
        "    roi_fontsize=13,\n",
        "    roi_extent=0.28,\n",
        "    tick_extent=0.03,\n",
        "    tick_label_extent=0.11,\n",
        "    tick_label_fontsize=10.0,\n",
        "    fontfamily='sans-serif',\n",
        "    figsize=(7, 7)):\n",
        "    r\"\"\"\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    \"\"\"\n",
        "\n",
        "    # Check arguments\n",
        "    assert x.ndim == 3\n",
        "    assert x.shape[0] == x.shape[1]\n",
        "    assert max_alpha >= 0.0 and max_alpha <= 1.0, f\"{max_alpha}\"\n",
        "    n_roi, n_freq = x.shape[1:]\n",
        "    assert freqs is None or len(freqs) == n_freq, f\"{len(freqs)} != {n_freq}\"\n",
        "\n",
        "    # Replace ROI underscores with spaces\n",
        "    if rois is not None:\n",
        "        assert len(rois) == n_roi, f\"{len(rois)} != {n_roi}\"\n",
        "        pretty_rois = [roi.replace(\"_\", \" \") for roi in rois]\n",
        "\n",
        "    # Default color\n",
        "    if color is None and cmap is None:\n",
        "        color = 'tab:blue'\n",
        "\n",
        "    # Set color to None if color map is provided\n",
        "    if cmap is not None:\n",
        "        color = None\n",
        "\n",
        "    #  variables\n",
        "    r2 = outer_radius\n",
        "    center_angles = np.linspace(0, 2 * np.pi, n_roi + 1)\n",
        "    buffer = buffer_percent / 100.0 * 2.0 * np.pi\n",
        "    start_angles = center_angles[:-1] + buffer\n",
        "    stop_angles = center_angles[1:] - buffer\n",
        "    freq_diff = (stop_angles[0] - start_angles[0]) / (n_freq + 1)\n",
        "    min_val, max_val = np.quantile(x, min_max_quantiles)\n",
        "    x = max_alpha * np.clip((x - min_val) / (max_val - min_val), 0.0, 1.0)\n",
        "\n",
        "    # Set up axes and labels and ticks\n",
        "    _, ax = _set_up_chord_plot(\n",
        "        start_angles=start_angles,\n",
        "        stop_angles=stop_angles,\n",
        "        r1=R1,\n",
        "        r2=r2,\n",
        "        pretty_rois=pretty_rois,\n",
        "        freqs=freqs,\n",
        "        freq_ticks=freq_ticks,\n",
        "        tick_extent=tick_extent,\n",
        "        tick_label_extent=tick_label_extent,\n",
        "        tick_label_fontsize=tick_label_fontsize,\n",
        "        roi_fontsize=roi_fontsize,\n",
        "        roi_extent=roi_extent,\n",
        "        fontfamily=fontfamily,\n",
        "        figsize=figsize)\n",
        "\n",
        "    # Add the power and chord plots\n",
        "    _update_chord_plot(\n",
        "        x=x,\n",
        "        ax=ax,\n",
        "        start_angles=start_angles,\n",
        "        stop_angles=stop_angles,\n",
        "        freq_diff=freq_diff,\n",
        "        outer_radius=outer_radius,\n",
        "        color=color,\n",
        "        cmap=cmap)\n",
        "\n",
        "    # Return plot axis\n",
        "    return ax\n",
        "\n",
        "\n",
        "# Update chord plot\n",
        "def _update_chord_plot(\n",
        "    x,\n",
        "    ax,\n",
        "    start_angles,\n",
        "    stop_angles,\n",
        "    freq_diff,\n",
        "    outer_radius,\n",
        "    color,\n",
        "    cmap=None):\n",
        "    r\"\"\"\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize variables\n",
        "    r2 = outer_radius\n",
        "    handles = []\n",
        "    n_roi, n_freq = x.shape[1:]\n",
        "\n",
        "    # Create colormap array for different frequencies\n",
        "    if cmap is not None:\n",
        "        if isinstance(cmap, str):\n",
        "            cmap_idx = np.linspace(0, 1, n_freq)\n",
        "            # cmap_color_arr = mpl.colormaps[cmap](cmap_idx)[:, :3]\n",
        "            cmap_color_arr = mpl.cm.get_cmap(cmap)(cmap_idx)[:, :3]\n",
        "        elif isinstance(cmap, LinearSegmentedColormap):\n",
        "            cmap_idx = np.linspace(0, 1, n_freq)\n",
        "            cmap_color_arr = cmap(cmap_idx)[:, :3]\n",
        "        else:\n",
        "            cmap_color_arr = None\n",
        "            color = 'b'\n",
        "    else:\n",
        "        cmap_color_arr = None\n",
        "\n",
        "    # Draw the power plots\n",
        "    for i, (c1, c2) in enumerate(zip(start_angles, stop_angles)):\n",
        "        # Iterate over frequencies\n",
        "        for j in range(n_freq):\n",
        "            # Retrieve colormap color for corresponding frequency value\n",
        "            if cmap_color_arr is not None:\n",
        "                color = cmap_color_arr[j]\n",
        "\n",
        "            # Generate arc power patch\n",
        "            if x[i, i, j] > 0:\n",
        "                # Arc power patch rotation\n",
        "                diff1 = j * (c2 - c1) / n_freq\n",
        "                diff2 = (j + 1) * (c2 - c1) / n_freq\n",
        "\n",
        "                # Transparency value\n",
        "                alpha = x[i, i, j]\n",
        "\n",
        "                # Append arc power patch to handles\n",
        "                h = _arc_patch(\n",
        "                    r1=R1,\n",
        "                    r2=r2,\n",
        "                    theta1=c1 + diff1,\n",
        "                    theta2=c1 + diff2,\n",
        "                    ax=ax,\n",
        "                    color=color,\n",
        "                    cmap=cmap,\n",
        "                    n=5,\n",
        "                    alpha=alpha)\n",
        "                handles.append(h)\n",
        "\n",
        "    # Draw the chords to represent cross-power\n",
        "    print(\"WARNING - CROSS-POWER PLOT HAS BEEN OVER-WRITTEN TO REPRESENT DIRECTIONAL ADJACENCY MATRICES!!!\")\n",
        "    for i in range(n_roi):# - 1):\n",
        "        for j in range(n_roi):#i + 1, n_roi):\n",
        "            # Iterate over frequency values\n",
        "            for k in range(n_freq):\n",
        "                # Frequency-specific color map color\n",
        "                if cmap_color_arr is not None:\n",
        "                    color = cmap_color_arr[k]\n",
        "                if i >= j:\n",
        "                    color = 'b'\n",
        "                else:\n",
        "                    color = 'r'\n",
        "\n",
        "                # Generate chord connection\n",
        "                if x[i, j, k] > 0.0:\n",
        "                    # Chord connection rotation\n",
        "                    theta1 = start_angles[i] + freq_diff * k\n",
        "                    theta2 = start_angles[j] + freq_diff * k\n",
        "\n",
        "                    # Transparency value\n",
        "                    alpha = x[i, j, k]\n",
        "\n",
        "                    # Append chord connection polygon to handles\n",
        "                    h = _plot_poly_chord(\n",
        "                        theta1=theta1,\n",
        "                        theta2=theta2,\n",
        "                        diff=freq_diff,\n",
        "                        ax=ax,\n",
        "                        color=color,\n",
        "                        alpha=alpha)\n",
        "                    handles.append(h)\n",
        "\n",
        "    # Return collection of power arc and chord connection handles\n",
        "    return handles\n",
        "\n",
        "\n",
        "# Set up chord plot\n",
        "def _set_up_chord_plot(\n",
        "    start_angles,\n",
        "    stop_angles,\n",
        "    r1,\n",
        "    r2,\n",
        "    pretty_rois,\n",
        "    freqs,\n",
        "    freq_ticks,\n",
        "    tick_extent,\n",
        "    tick_label_extent,\n",
        "    tick_label_fontsize,\n",
        "    roi_fontsize,\n",
        "    roi_extent,\n",
        "    fontfamily,\n",
        "    figsize):\n",
        "    r\"\"\"\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize figure\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    ax = plt.gca()\n",
        "\n",
        "    # Set up axes and draw power plots\n",
        "    for i, (c1, c2) in enumerate(zip(start_angles, stop_angles)):\n",
        "        # Draw power axis\n",
        "        _draw_power_axis(\n",
        "            r1=r1,\n",
        "            r2=r2,\n",
        "            theta1=c1,\n",
        "            theta2=c2,\n",
        "            ax=ax)\n",
        "\n",
        "        # Plot ticks\n",
        "        if freqs is not None and freq_ticks is not None:\n",
        "            _plot_ticks(\n",
        "                r=r2,\n",
        "                theta1=c1,\n",
        "                theta2=c2,\n",
        "                ax=ax,\n",
        "                freqs=freqs,\n",
        "                freq_ticks=freq_ticks,\n",
        "                tick_extent=tick_extent,\n",
        "                tick_label_extent=tick_label_extent,\n",
        "                tick_label_fontsize=tick_label_fontsize,\n",
        "                fontfamily=fontfamily)\n",
        "\n",
        "        # Annotate ROIs\n",
        "        if pretty_rois is not None:\n",
        "            _plot_roi_name(\n",
        "                r=r2,\n",
        "                theta=0.5 * (c1 + c2),\n",
        "                ax=ax,\n",
        "                roi=pretty_rois[i],\n",
        "                extent=roi_extent,\n",
        "                fontsize=roi_fontsize,\n",
        "                fontfamily=fontfamily)\n",
        "\n",
        "    # Axis limits\n",
        "    ax.set_ylim(-1.5, 1.5)\n",
        "    ax.set_xlim(-1.5, 1.5)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    # Return figure and axis variables\n",
        "    return fig, ax\n",
        "\n",
        "\n",
        "# Plot poly chord\n",
        "def _plot_poly_chord(\n",
        "    theta1,\n",
        "    theta2,\n",
        "    diff,\n",
        "    ax,\n",
        "    color,\n",
        "    n=50,\n",
        "    alpha=0.5):\n",
        "    r\"\"\"\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    \"\"\"\n",
        "\n",
        "    # Chord chonnection points\n",
        "    points1 = _chord_helper(theta1, theta2, n=n)\n",
        "    rot_mat = np.array([[np.cos(diff), -np.sin(diff)], [np.sin(diff), np.cos(diff)]])\n",
        "    points2 = rot_mat @ points1\n",
        "    points = np.concatenate([points1, points2[:, ::-1]], axis=1).T\n",
        "\n",
        "    # Chord connection polygon\n",
        "    poly = Polygon(points, closed=True, fc=to_rgba(c=color, alpha=alpha))\n",
        "    ax.add_patch(poly)\n",
        "\n",
        "    # Return chord connection polygon\n",
        "    return poly\n",
        "\n",
        "\n",
        "# Chord helper\n",
        "def _chord_helper(theta1, theta2, n=50):\n",
        "    r\"\"\"\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    \"\"\"\n",
        "\n",
        "    # Chord helper coordinates calculations\n",
        "    a1, a2 = np.cos(theta1), np.sin(theta1)\n",
        "    b1, b2 = np.cos(theta2), np.sin(theta2)\n",
        "    denom = a1 * b2 - a2 * b1\n",
        "    if np.abs(denom) < 1e-5:\n",
        "        xs = np.linspace(a1, b1, n)\n",
        "        ys = np.linspace(a2, b2, n)\n",
        "\n",
        "        return np.vstack([xs, ys])\n",
        "    v, w = 2.0 * (a2 - b2) / denom, 2.0 * (b1 - a1) / denom\n",
        "    center = (-v / 2.0, -w / 2.0)\n",
        "    radius = np.sqrt(((v ** 2.0 + w ** 2.0) / 4.0) - 1.0)\n",
        "    angle1 = np.arctan2(a2 - center[1], a1 - center[0])\n",
        "    angle2 = np.arctan2(b2 - center[1], b1 - center[0])\n",
        "    angle1, angle2 = min(angle1, angle2), max(angle1, angle2)\n",
        "    if angle2 - angle1 > np.pi:\n",
        "        angle1, angle2 = angle2, angle1 + 2 * np.pi\n",
        "    theta = np.linspace(angle1, angle2, n)\n",
        "    xs = radius * np.cos(theta) + center[0]\n",
        "    ys = radius * np.sin(theta) + center[1]\n",
        "\n",
        "    # Return coordinates\n",
        "    return np.vstack([xs, ys])\n",
        "\n",
        "\n",
        "# Arc patch\n",
        "def _arc_patch(\n",
        "    r1,\n",
        "    r2,\n",
        "    theta1,\n",
        "    theta2,\n",
        "    ax,\n",
        "    color,\n",
        "    cmap=None,\n",
        "    n=50,\n",
        "    alpha=1.0,\n",
        "    **kwargs):\n",
        "    r\"\"\"\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    \"\"\"\n",
        "\n",
        "    # Power arc points\n",
        "    thetas = np.linspace(theta1, theta2, n)\n",
        "    sin_thetas, cos_thetas = np.sin(thetas), np.cos(thetas)\n",
        "    points = np.vstack([cos_thetas, sin_thetas]).T\n",
        "    points = np.concatenate([r1 * points, r2 * points[::-1]], axis=0)\n",
        "\n",
        "    # Power arc polygon\n",
        "    poly = Polygon(\n",
        "        points,\n",
        "        closed=True,\n",
        "        fc=to_rgba(color, alpha=alpha),\n",
        "        **kwargs)\n",
        "    ax.add_patch(poly)\n",
        "\n",
        "    # Return power arc polygon\n",
        "    return poly\n",
        "\n",
        "\n",
        "# Draw power axis\n",
        "def _draw_power_axis(\n",
        "    r1,\n",
        "    r2,\n",
        "    theta1,\n",
        "    theta2,\n",
        "    ax,\n",
        "    n=50,\n",
        "    **kwargs):\n",
        "    r\"\"\"\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    \"\"\"\n",
        "\n",
        "    # Power axis points\n",
        "    thetas = np.linspace(theta1, theta2, n)\n",
        "    sin_thetas, cos_thetas = np.sin(thetas), np.cos(thetas)\n",
        "    points = np.vstack([cos_thetas, sin_thetas]).T\n",
        "    points = np.concatenate([r1 * points, r2 * points[::-1]], axis=0)\n",
        "    points = np.concatenate([points, points[:1]], axis=0)\n",
        "\n",
        "    # Power axis handle\n",
        "    handle = ax.plot(points[:, 0], points[:, 1], c='k', **kwargs)\n",
        "\n",
        "    # Return handle\n",
        "    return handle\n",
        "\n",
        "\n",
        "# Plot ticks\n",
        "def _plot_ticks(\n",
        "    r,\n",
        "    theta1,\n",
        "    theta2,\n",
        "    ax,\n",
        "    freqs,\n",
        "    freq_ticks,\n",
        "    tick_extent=0.03,\n",
        "    tick_label_extent=0.11,\n",
        "    tick_label_fontsize=10.0,\n",
        "    n=5,\n",
        "    fontfamily='sans-serif',\n",
        "    **kwargs):\n",
        "    r\"\"\"\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    \"\"\"\n",
        "\n",
        "    # Tick offset\n",
        "    offset = 0.0 if np.cos((theta1 + theta2) / 2.0) > 0.0 else 180.0\n",
        "\n",
        "    # Iterate over frequency tick values\n",
        "    for freq in freq_ticks:\n",
        "        # Tick location and rotation\n",
        "        theta = theta1 + (theta2 - theta1) * (freq - freqs[0]) / (freqs[-1] - freqs[0])\n",
        "        x = [r * np.cos(theta), (r + tick_extent) * np.cos(theta)]\n",
        "        y = [r * np.sin(theta), (r + tick_extent) * np.sin(theta)]\n",
        "\n",
        "        # Plot tick\n",
        "        ax.plot(x, y, c=\"k\", **kwargs)\n",
        "\n",
        "        # Tick label location and rotation\n",
        "        x = (r + tick_label_extent) * np.cos(theta)\n",
        "        y = (r + tick_label_extent) * np.sin(theta)\n",
        "        rotation = (theta * 180.0 / np.pi) + offset\n",
        "\n",
        "        # Tick text / label\n",
        "        ax.text(\n",
        "            x=x,\n",
        "            y=y,\n",
        "            s=str(freq),\n",
        "            rotation=rotation,\n",
        "            fontfamily=fontfamily,\n",
        "            fontsize=tick_label_fontsize,\n",
        "            ha='center',\n",
        "            va='center')\n",
        "\n",
        "\n",
        "# Plot ROI name\n",
        "def _plot_roi_name(\n",
        "    r,\n",
        "    theta,\n",
        "    ax,\n",
        "    roi,\n",
        "    extent=0.3,\n",
        "    fontsize=13,\n",
        "    fontfamily='sans-serif'):\n",
        "    r\"\"\"\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    \"\"\"\n",
        "\n",
        "    # ROI location and rotation\n",
        "    x, y = (r + extent) * np.cos(theta), (r + extent) * np.sin(theta)\n",
        "    rotation = (theta * 180.0 / np.pi) - 90.0\n",
        "\n",
        "    # Offset rotation\n",
        "    if np.sin(theta) < 0.0:\n",
        "        rotation += 180.0\n",
        "\n",
        "    # ROI text\n",
        "    ax.text(\n",
        "        x=x,\n",
        "        y=y,\n",
        "        s=roi,\n",
        "        rotation=rotation,\n",
        "        ha='center',\n",
        "        va='center',\n",
        "        fontfamily=fontfamily,\n",
        "        fontsize=fontsize)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9Z485BSsqxQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization of All Folds of TST 9-factor REDCLIFF-S Models, 01/15/2025"
      ],
      "metadata": {
        "id": "6bebtnI0Rh4i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fold 0"
      ],
      "metadata": {
        "id": "_6Pxnur7Rsdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle as pkl\n",
        "\n",
        "from general_utils.misc import get_topk_graph_mask\n",
        "\n",
        "FONT_SMALL_SIZE = 18\n",
        "FONT_MEDIUM_SIZE = 20\n",
        "FONT_BIGGER_SIZE = 22\n",
        "\n",
        "plt.rc('font', size=FONT_SMALL_SIZE)          # controls default text sizes\n",
        "plt.rc('axes', titlesize=FONT_BIGGER_SIZE)     # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=FONT_MEDIUM_SIZE)    # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=FONT_SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=FONT_SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=FONT_SMALL_SIZE)    # legend fontsize\n",
        "plt.rc('figure', titlesize=FONT_BIGGER_SIZE)  # fontsize of the figure title\n",
        "\n",
        "\n",
        "factor_names = [\"Home Cage (HC)\", \"Open Field (OF)\", \"Tail Suspended (TS)\",\n",
        "                \"UNKNOWN 1 (U1)\", \"UNKNOWN 2 (U2)\", \"UNKNOWN 3 (U3)\",\n",
        "                \"UNKNOWN 4 (U4)\", \"UNKNOWN 5 (U5)\", \"UNKNOWN 6 (U6)\", ]\n",
        "channel_names = [\n",
        "    'Acb_Core', 'Acb_Sh', 'IL_Cx', 'L_VTA', 'Md_Thal', 'PrL_Cx', 'R_VTA', 'aILH_Hab', 'IDHip', 'lSNC', 'mDHip', 'mSNC'\n",
        "]\n",
        "model = torch.load(\"final_best_model_FOLD0.bin\", map_location=torch.device('cpu'))\n",
        "curr_gc_factor_ests = [x.detach().numpy() for x in model.GC(\"fixed_factor_exclusive\", X=None, threshold=False, ignore_lag=False, combine_wavelet_representations=True, rank_wavelets=False)[0]]\n",
        "\n",
        "\n",
        "curr_gc_factor_ests = [x/np.max(x) for x in curr_gc_factor_ests]\n",
        "\n",
        "\n",
        "for i in range(len(curr_gc_factor_ests)):\n",
        "    fig, ax = plt.subplots()\n",
        "    fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "    im = ax.imshow(curr_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r')\n",
        "    fig.colorbar(im, orientation='vertical')\n",
        "    plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "    plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "    plt.xlabel(\"Driving Channels\")\n",
        "    plt.ylabel(\"Receiving Channels\")\n",
        "    plt.title(\"Est. Causality: \"+factor_names[i]+\"\\n\")\n",
        "    plt.show()\n",
        "\n",
        "print(\"DIFFERENCE BETWEEN FACTOR 1 AND FACTOR 2 ------------------------\")\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(i,3):\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_gc_factor_ests[j][:,:,:].sum(axis=2) - curr_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[j]+\" - \"+factor_names[i])\n",
        "        plt.show()\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_gc_factor_ests[i][:,:,:].sum(axis=2) - curr_gc_factor_ests[j][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[i]+\" - \"+factor_names[j])\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n\\n\\n # OFF-DIAGONAL VISUALIZATIONS ##########################################################################################################\")\n",
        "\n",
        "curr_offDiag_gc_factor_ests = [x.detach().numpy() for x in model.GC(\"fixed_factor_exclusive\", X=None, threshold=False, ignore_lag=False, combine_wavelet_representations=True, rank_wavelets=False)[0]]\n",
        "curr_offDiag_gc_factor_ests = [x - x*np.expand_dims(np.eye(x.shape[0]), axis=2) for x in curr_offDiag_gc_factor_ests]\n",
        "curr_offDiag_gc_factor_ests = [x/np.max(x) for x in curr_offDiag_gc_factor_ests]\n",
        "\n",
        "for i in range(len(curr_offDiag_gc_factor_ests)):\n",
        "    fig, ax = plt.subplots()\n",
        "    fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "    im = ax.imshow(curr_offDiag_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r')\n",
        "    fig.colorbar(im, orientation='vertical')\n",
        "    plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "    plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "    plt.xlabel(\"Driving Channels\")\n",
        "    plt.ylabel(\"Receiving Channels\")\n",
        "    plt.title(\"Est. Causality: \"+factor_names[i]+\"\\n\")\n",
        "    plt.show()\n",
        "\n",
        "print(\"DIFFERENCE BETWEEN FACTOR 1 AND FACTOR 2 ------------------------\")\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(i,3):\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_offDiag_gc_factor_ests[j][:,:,:].sum(axis=2) - curr_offDiag_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[j]+\" - \"+factor_names[i])\n",
        "        plt.show()\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_offDiag_gc_factor_ests[i][:,:,:].sum(axis=2) - curr_offDiag_gc_factor_ests[j][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[i]+\" - \"+factor_names[j])\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "utYCGqtXRq-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fold 1"
      ],
      "metadata": {
        "id": "Wjf9cHHKR8Xi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle as pkl\n",
        "\n",
        "from general_utils.misc import get_topk_graph_mask\n",
        "\n",
        "FONT_SMALL_SIZE = 18\n",
        "FONT_MEDIUM_SIZE = 20\n",
        "FONT_BIGGER_SIZE = 22\n",
        "\n",
        "plt.rc('font', size=FONT_SMALL_SIZE)          # controls default text sizes\n",
        "plt.rc('axes', titlesize=FONT_BIGGER_SIZE)     # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=FONT_MEDIUM_SIZE)    # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=FONT_SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=FONT_SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=FONT_SMALL_SIZE)    # legend fontsize\n",
        "plt.rc('figure', titlesize=FONT_BIGGER_SIZE)  # fontsize of the figure title\n",
        "\n",
        "\n",
        "factor_names = [\"Home Cage (HC)\", \"Open Field (OF)\", \"Tail Suspended (TS)\",\n",
        "                \"UNKNOWN 1 (U1)\", \"UNKNOWN 2 (U2)\", \"UNKNOWN 3 (U3)\",\n",
        "                \"UNKNOWN 4 (U4)\", \"UNKNOWN 5 (U5)\", \"UNKNOWN 6 (U6)\", ]\n",
        "channel_names = [\n",
        "    'Acb_Core', 'Acb_Sh', 'IL_Cx', 'L_VTA', 'Md_Thal', 'PrL_Cx', 'R_VTA', 'aILH_Hab', 'IDHip', 'lSNC', 'mDHip', 'mSNC'\n",
        "]\n",
        "model = torch.load(\"final_best_model_FOLD1.bin\", map_location=torch.device('cpu'))\n",
        "curr_gc_factor_ests = [x.detach().numpy() for x in model.GC(\"fixed_factor_exclusive\", X=None, threshold=False, ignore_lag=False, combine_wavelet_representations=True, rank_wavelets=False)[0]]\n",
        "\n",
        "\n",
        "curr_gc_factor_ests = [x/np.max(x) for x in curr_gc_factor_ests]\n",
        "\n",
        "\n",
        "for i in range(len(curr_gc_factor_ests)):\n",
        "    fig, ax = plt.subplots()\n",
        "    fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "    im = ax.imshow(curr_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r')\n",
        "    fig.colorbar(im, orientation='vertical')\n",
        "    plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "    plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "    plt.xlabel(\"Driving Channels\")\n",
        "    plt.ylabel(\"Receiving Channels\")\n",
        "    plt.title(\"Est. Causality: \"+factor_names[i]+\"\\n\")\n",
        "    plt.show()\n",
        "\n",
        "print(\"DIFFERENCE BETWEEN FACTOR 1 AND FACTOR 2 ------------------------\")\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(i,3):\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_gc_factor_ests[j][:,:,:].sum(axis=2) - curr_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[j]+\" - \"+factor_names[i])\n",
        "        plt.show()\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_gc_factor_ests[i][:,:,:].sum(axis=2) - curr_gc_factor_ests[j][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[i]+\" - \"+factor_names[j])\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n\\n\\n # OFF-DIAGONAL VISUALIZATIONS ##########################################################################################################\")\n",
        "\n",
        "curr_offDiag_gc_factor_ests = [x.detach().numpy() for x in model.GC(\"fixed_factor_exclusive\", X=None, threshold=False, ignore_lag=False, combine_wavelet_representations=True, rank_wavelets=False)[0]]\n",
        "curr_offDiag_gc_factor_ests = [x - x*np.expand_dims(np.eye(x.shape[0]), axis=2) for x in curr_offDiag_gc_factor_ests]\n",
        "curr_offDiag_gc_factor_ests = [x/np.max(x) for x in curr_offDiag_gc_factor_ests]\n",
        "\n",
        "for i in range(len(curr_offDiag_gc_factor_ests)):\n",
        "    fig, ax = plt.subplots()\n",
        "    fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "    im = ax.imshow(curr_offDiag_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r')\n",
        "    fig.colorbar(im, orientation='vertical')\n",
        "    plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "    plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "    plt.xlabel(\"Driving Channels\")\n",
        "    plt.ylabel(\"Receiving Channels\")\n",
        "    plt.title(\"Est. Causality: \"+factor_names[i]+\"\\n\")\n",
        "    plt.show()\n",
        "\n",
        "print(\"DIFFERENCE BETWEEN FACTOR 1 AND FACTOR 2 ------------------------\")\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(i,3):\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_offDiag_gc_factor_ests[j][:,:,:].sum(axis=2) - curr_offDiag_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[j]+\" - \"+factor_names[i])\n",
        "        plt.show()\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_offDiag_gc_factor_ests[i][:,:,:].sum(axis=2) - curr_offDiag_gc_factor_ests[j][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[i]+\" - \"+factor_names[j])\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "9nTlUy4-SBz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fold 2"
      ],
      "metadata": {
        "id": "mcp1c9-VR8Qj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle as pkl\n",
        "\n",
        "from general_utils.misc import get_topk_graph_mask\n",
        "\n",
        "FONT_SMALL_SIZE = 18\n",
        "FONT_MEDIUM_SIZE = 20\n",
        "FONT_BIGGER_SIZE = 22\n",
        "\n",
        "plt.rc('font', size=FONT_SMALL_SIZE)          # controls default text sizes\n",
        "plt.rc('axes', titlesize=FONT_BIGGER_SIZE)     # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=FONT_MEDIUM_SIZE)    # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=FONT_SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=FONT_SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=FONT_SMALL_SIZE)    # legend fontsize\n",
        "plt.rc('figure', titlesize=FONT_BIGGER_SIZE)  # fontsize of the figure title\n",
        "\n",
        "\n",
        "factor_names = [\"Home Cage (HC)\", \"Open Field (OF)\", \"Tail Suspended (TS)\",\n",
        "                \"UNKNOWN 1 (U1)\", \"UNKNOWN 2 (U2)\", \"UNKNOWN 3 (U3)\",\n",
        "                \"UNKNOWN 4 (U4)\", \"UNKNOWN 5 (U5)\", \"UNKNOWN 6 (U6)\", ]\n",
        "channel_names = [\n",
        "    'Acb_Core', 'Acb_Sh', 'IL_Cx', 'L_VTA', 'Md_Thal', 'PrL_Cx', 'R_VTA', 'aILH_Hab', 'IDHip', 'lSNC', 'mDHip', 'mSNC'\n",
        "]\n",
        "model = torch.load(\"final_best_model_FOLD2.bin\", map_location=torch.device('cpu'))\n",
        "curr_gc_factor_ests = [x.detach().numpy() for x in model.GC(\"fixed_factor_exclusive\", X=None, threshold=False, ignore_lag=False, combine_wavelet_representations=True, rank_wavelets=False)[0]]\n",
        "\n",
        "\n",
        "curr_gc_factor_ests = [x/np.max(x) for x in curr_gc_factor_ests]\n",
        "\n",
        "\n",
        "for i in range(len(curr_gc_factor_ests)):\n",
        "    fig, ax = plt.subplots()\n",
        "    fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "    im = ax.imshow(curr_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r')\n",
        "    fig.colorbar(im, orientation='vertical')\n",
        "    plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "    plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "    plt.xlabel(\"Driving Channels\")\n",
        "    plt.ylabel(\"Receiving Channels\")\n",
        "    plt.title(\"Est. Causality: \"+factor_names[i]+\"\\n\")\n",
        "    plt.show()\n",
        "\n",
        "print(\"DIFFERENCE BETWEEN FACTOR 1 AND FACTOR 2 ------------------------\")\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(i,3):\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_gc_factor_ests[j][:,:,:].sum(axis=2) - curr_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[j]+\" - \"+factor_names[i])\n",
        "        plt.show()\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_gc_factor_ests[i][:,:,:].sum(axis=2) - curr_gc_factor_ests[j][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[i]+\" - \"+factor_names[j])\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n\\n\\n # OFF-DIAGONAL VISUALIZATIONS ##########################################################################################################\")\n",
        "\n",
        "curr_offDiag_gc_factor_ests = [x.detach().numpy() for x in model.GC(\"fixed_factor_exclusive\", X=None, threshold=False, ignore_lag=False, combine_wavelet_representations=True, rank_wavelets=False)[0]]\n",
        "curr_offDiag_gc_factor_ests = [x - x*np.expand_dims(np.eye(x.shape[0]), axis=2) for x in curr_offDiag_gc_factor_ests]\n",
        "curr_offDiag_gc_factor_ests = [x/np.max(x) for x in curr_offDiag_gc_factor_ests]\n",
        "\n",
        "for i in range(len(curr_offDiag_gc_factor_ests)):\n",
        "    fig, ax = plt.subplots()\n",
        "    fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "    im = ax.imshow(curr_offDiag_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r')\n",
        "    fig.colorbar(im, orientation='vertical')\n",
        "    plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "    plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "    plt.xlabel(\"Driving Channels\")\n",
        "    plt.ylabel(\"Receiving Channels\")\n",
        "    plt.title(\"Est. Causality: \"+factor_names[i]+\"\\n\")\n",
        "    plt.show()\n",
        "\n",
        "print(\"DIFFERENCE BETWEEN FACTOR 1 AND FACTOR 2 ------------------------\")\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(i,3):\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_offDiag_gc_factor_ests[j][:,:,:].sum(axis=2) - curr_offDiag_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[j]+\" - \"+factor_names[i])\n",
        "        plt.show()\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_offDiag_gc_factor_ests[i][:,:,:].sum(axis=2) - curr_offDiag_gc_factor_ests[j][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[i]+\" - \"+factor_names[j])\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "X6TdaxSzSCji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fold 3"
      ],
      "metadata": {
        "id": "JfteyH-2R71a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle as pkl\n",
        "\n",
        "from general_utils.misc import get_topk_graph_mask\n",
        "\n",
        "FONT_SMALL_SIZE = 18\n",
        "FONT_MEDIUM_SIZE = 20\n",
        "FONT_BIGGER_SIZE = 22\n",
        "\n",
        "plt.rc('font', size=FONT_SMALL_SIZE)          # controls default text sizes\n",
        "plt.rc('axes', titlesize=FONT_BIGGER_SIZE)     # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=FONT_MEDIUM_SIZE)    # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=FONT_SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=FONT_SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=FONT_SMALL_SIZE)    # legend fontsize\n",
        "plt.rc('figure', titlesize=FONT_BIGGER_SIZE)  # fontsize of the figure title\n",
        "\n",
        "\n",
        "factor_names = [\"Home Cage (HC)\", \"Open Field (OF)\", \"Tail Suspended (TS)\",\n",
        "                \"UNKNOWN 1 (U1)\", \"UNKNOWN 2 (U2)\", \"UNKNOWN 3 (U3)\",\n",
        "                \"UNKNOWN 4 (U4)\", \"UNKNOWN 5 (U5)\", \"UNKNOWN 6 (U6)\", ]\n",
        "channel_names = [\n",
        "    'Acb_Core', 'Acb_Sh', 'IL_Cx', 'L_VTA', 'Md_Thal', 'PrL_Cx', 'R_VTA', 'aILH_Hab', 'IDHip', 'lSNC', 'mDHip', 'mSNC'\n",
        "]\n",
        "model = torch.load(\"final_best_model_FOLD3.bin\", map_location=torch.device('cpu'))\n",
        "curr_gc_factor_ests = [x.detach().numpy() for x in model.GC(\"fixed_factor_exclusive\", X=None, threshold=False, ignore_lag=False, combine_wavelet_representations=True, rank_wavelets=False)[0]]\n",
        "\n",
        "\n",
        "curr_gc_factor_ests = [x/np.max(x) for x in curr_gc_factor_ests]\n",
        "\n",
        "\n",
        "for i in range(len(curr_gc_factor_ests)):\n",
        "    fig, ax = plt.subplots()\n",
        "    fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "    im = ax.imshow(curr_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r')\n",
        "    fig.colorbar(im, orientation='vertical')\n",
        "    plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "    plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "    plt.xlabel(\"Driving Channels\")\n",
        "    plt.ylabel(\"Receiving Channels\")\n",
        "    plt.title(\"Est. Causality: \"+factor_names[i]+\"\\n\")\n",
        "    plt.show()\n",
        "\n",
        "print(\"DIFFERENCE BETWEEN FACTOR 1 AND FACTOR 2 ------------------------\")\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(i,3):\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_gc_factor_ests[j][:,:,:].sum(axis=2) - curr_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[j]+\" - \"+factor_names[i])\n",
        "        plt.show()\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_gc_factor_ests[i][:,:,:].sum(axis=2) - curr_gc_factor_ests[j][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[i]+\" - \"+factor_names[j])\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n\\n\\n # OFF-DIAGONAL VISUALIZATIONS ##########################################################################################################\")\n",
        "\n",
        "curr_offDiag_gc_factor_ests = [x.detach().numpy() for x in model.GC(\"fixed_factor_exclusive\", X=None, threshold=False, ignore_lag=False, combine_wavelet_representations=True, rank_wavelets=False)[0]]\n",
        "curr_offDiag_gc_factor_ests = [x - x*np.expand_dims(np.eye(x.shape[0]), axis=2) for x in curr_offDiag_gc_factor_ests]\n",
        "curr_offDiag_gc_factor_ests = [x/np.max(x) for x in curr_offDiag_gc_factor_ests]\n",
        "\n",
        "for i in range(len(curr_offDiag_gc_factor_ests)):\n",
        "    fig, ax = plt.subplots()\n",
        "    fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "    im = ax.imshow(curr_offDiag_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r')\n",
        "    fig.colorbar(im, orientation='vertical')\n",
        "    plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "    plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "    plt.xlabel(\"Driving Channels\")\n",
        "    plt.ylabel(\"Receiving Channels\")\n",
        "    plt.title(\"Est. Causality: \"+factor_names[i]+\"\\n\")\n",
        "    plt.show()\n",
        "\n",
        "print(\"DIFFERENCE BETWEEN FACTOR 1 AND FACTOR 2 ------------------------\")\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(i,3):\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_offDiag_gc_factor_ests[j][:,:,:].sum(axis=2) - curr_offDiag_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[j]+\" - \"+factor_names[i])\n",
        "        plt.show()\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_offDiag_gc_factor_ests[i][:,:,:].sum(axis=2) - curr_offDiag_gc_factor_ests[j][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[i]+\" - \"+factor_names[j])\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "uRW0sdp5SDG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fold 4"
      ],
      "metadata": {
        "id": "RspPZ1mdR7s7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle as pkl\n",
        "\n",
        "from general_utils.misc import get_topk_graph_mask\n",
        "\n",
        "FONT_SMALL_SIZE = 18\n",
        "FONT_MEDIUM_SIZE = 20\n",
        "FONT_BIGGER_SIZE = 22\n",
        "\n",
        "plt.rc('font', size=FONT_SMALL_SIZE)          # controls default text sizes\n",
        "plt.rc('axes', titlesize=FONT_BIGGER_SIZE)     # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=FONT_MEDIUM_SIZE)    # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=FONT_SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=FONT_SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=FONT_SMALL_SIZE)    # legend fontsize\n",
        "plt.rc('figure', titlesize=FONT_BIGGER_SIZE)  # fontsize of the figure title\n",
        "\n",
        "\n",
        "factor_names = [\"Home Cage (HC)\", \"Open Field (OF)\", \"Tail Suspended (TS)\",\n",
        "                \"UNKNOWN 1 (U1)\", \"UNKNOWN 2 (U2)\", \"UNKNOWN 3 (U3)\",\n",
        "                \"UNKNOWN 4 (U4)\", \"UNKNOWN 5 (U5)\", \"UNKNOWN 6 (U6)\", ]\n",
        "channel_names = [\n",
        "    'Acb_Core', 'Acb_Sh', 'IL_Cx', 'L_VTA', 'Md_Thal', 'PrL_Cx', 'R_VTA', 'aILH_Hab', 'IDHip', 'lSNC', 'mDHip', 'mSNC'\n",
        "]\n",
        "model = torch.load(\"final_best_model_FOLD4.bin\", map_location=torch.device('cpu'))\n",
        "curr_gc_factor_ests = [x.detach().numpy() for x in model.GC(\"fixed_factor_exclusive\", X=None, threshold=False, ignore_lag=False, combine_wavelet_representations=True, rank_wavelets=False)[0]]\n",
        "\n",
        "\n",
        "curr_gc_factor_ests = [x/np.max(x) for x in curr_gc_factor_ests]\n",
        "\n",
        "\n",
        "for i in range(len(curr_gc_factor_ests)):\n",
        "    fig, ax = plt.subplots()\n",
        "    fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "    im = ax.imshow(curr_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r')\n",
        "    fig.colorbar(im, orientation='vertical')\n",
        "    plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "    plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "    plt.xlabel(\"Driving Channels\")\n",
        "    plt.ylabel(\"Receiving Channels\")\n",
        "    plt.title(\"Est. Causality: \"+factor_names[i]+\"\\n\")\n",
        "    plt.show()\n",
        "\n",
        "print(\"DIFFERENCE BETWEEN FACTOR 1 AND FACTOR 2 ------------------------\")\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(i,3):\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_gc_factor_ests[j][:,:,:].sum(axis=2) - curr_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[j]+\" - \"+factor_names[i])\n",
        "        plt.show()\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_gc_factor_ests[i][:,:,:].sum(axis=2) - curr_gc_factor_ests[j][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[i]+\" - \"+factor_names[j])\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n\\n\\n # OFF-DIAGONAL VISUALIZATIONS ##########################################################################################################\")\n",
        "\n",
        "curr_offDiag_gc_factor_ests = [x.detach().numpy() for x in model.GC(\"fixed_factor_exclusive\", X=None, threshold=False, ignore_lag=False, combine_wavelet_representations=True, rank_wavelets=False)[0]]\n",
        "curr_offDiag_gc_factor_ests = [x - x*np.expand_dims(np.eye(x.shape[0]), axis=2) for x in curr_offDiag_gc_factor_ests]\n",
        "curr_offDiag_gc_factor_ests = [x/np.max(x) for x in curr_offDiag_gc_factor_ests]\n",
        "\n",
        "for i in range(len(curr_offDiag_gc_factor_ests)):\n",
        "    fig, ax = plt.subplots()\n",
        "    fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "    im = ax.imshow(curr_offDiag_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r')\n",
        "    fig.colorbar(im, orientation='vertical')\n",
        "    plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "    plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "    plt.xlabel(\"Driving Channels\")\n",
        "    plt.ylabel(\"Receiving Channels\")\n",
        "    plt.title(\"Est. Causality: \"+factor_names[i]+\"\\n\")\n",
        "    plt.show()\n",
        "\n",
        "print(\"DIFFERENCE BETWEEN FACTOR 1 AND FACTOR 2 ------------------------\")\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(i,3):\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_offDiag_gc_factor_ests[j][:,:,:].sum(axis=2) - curr_offDiag_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[j]+\" - \"+factor_names[i])\n",
        "        plt.show()\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_offDiag_gc_factor_ests[i][:,:,:].sum(axis=2) - curr_offDiag_gc_factor_ests[j][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[i]+\" - \"+factor_names[j])\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "ztcqNaZcSDjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Avg. Across Folds"
      ],
      "metadata": {
        "id": "FxLeXol2SFND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle as pkl\n",
        "\n",
        "from general_utils.misc import get_topk_graph_mask\n",
        "\n",
        "FONT_SMALL_SIZE = 18\n",
        "FONT_MEDIUM_SIZE = 20\n",
        "FONT_BIGGER_SIZE = 22\n",
        "\n",
        "plt.rc('font', size=FONT_SMALL_SIZE)          # controls default text sizes\n",
        "plt.rc('axes', titlesize=FONT_BIGGER_SIZE)     # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=FONT_MEDIUM_SIZE)    # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=FONT_SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=FONT_SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=FONT_SMALL_SIZE)    # legend fontsize\n",
        "plt.rc('figure', titlesize=FONT_BIGGER_SIZE)  # fontsize of the figure title\n",
        "\n",
        "\n",
        "factor_names = [\"Home Cage (HC)\", \"Open Field (OF)\", \"Tail Suspended (TS)\",\n",
        "                \"UNKNOWN 1 (U1)\", \"UNKNOWN 2 (U2)\", \"UNKNOWN 3 (U3)\",\n",
        "                \"UNKNOWN 4 (U4)\", \"UNKNOWN 5 (U5)\", \"UNKNOWN 6 (U6)\", ]\n",
        "channel_names = [\n",
        "    'Acb_Core', 'Acb_Sh', 'IL_Cx', 'L_VTA', 'Md_Thal', 'PrL_Cx', 'R_VTA', 'aILH_Hab', 'IDHip', 'lSNC', 'mDHip', 'mSNC'\n",
        "]\n",
        "model0 = torch.load(\"final_best_model_FOLD0.bin\", map_location=torch.device('cpu'))\n",
        "model1 = torch.load(\"final_best_model_FOLD1.bin\", map_location=torch.device('cpu'))\n",
        "model2 = torch.load(\"final_best_model_FOLD2.bin\", map_location=torch.device('cpu'))\n",
        "model3 = torch.load(\"final_best_model_FOLD3.bin\", map_location=torch.device('cpu'))\n",
        "model4 = torch.load(\"final_best_model_FOLD4.bin\", map_location=torch.device('cpu'))\n",
        "curr_gc_factor_ests0 = [x.detach().numpy() for x in model0.GC(\"fixed_factor_exclusive\", X=None, threshold=False, ignore_lag=False, combine_wavelet_representations=True, rank_wavelets=False)[0]]\n",
        "curr_gc_factor_ests0 = [x/np.max(x) for x in curr_gc_factor_ests0]\n",
        "curr_gc_factor_ests1 = [x.detach().numpy() for x in model1.GC(\"fixed_factor_exclusive\", X=None, threshold=False, ignore_lag=False, combine_wavelet_representations=True, rank_wavelets=False)[0]]\n",
        "curr_gc_factor_ests1 = [x/np.max(x) for x in curr_gc_factor_ests1]\n",
        "curr_gc_factor_ests2 = [x.detach().numpy() for x in model2.GC(\"fixed_factor_exclusive\", X=None, threshold=False, ignore_lag=False, combine_wavelet_representations=True, rank_wavelets=False)[0]]\n",
        "curr_gc_factor_ests2 = [x/np.max(x) for x in curr_gc_factor_ests2]\n",
        "curr_gc_factor_ests3 = [x.detach().numpy() for x in model3.GC(\"fixed_factor_exclusive\", X=None, threshold=False, ignore_lag=False, combine_wavelet_representations=True, rank_wavelets=False)[0]]\n",
        "curr_gc_factor_ests3 = [x/np.max(x) for x in curr_gc_factor_ests3]\n",
        "curr_gc_factor_ests4 = [x.detach().numpy() for x in model4.GC(\"fixed_factor_exclusive\", X=None, threshold=False, ignore_lag=False, combine_wavelet_representations=True, rank_wavelets=False)[0]]\n",
        "curr_gc_factor_ests4 = [x/np.max(x) for x in curr_gc_factor_ests4]\n",
        "\n",
        "\n",
        "curr_gc_factor_ests = [x0+x1+x2+x3+x4 for (x0,x1,x2,x3,x4) in zip(curr_gc_factor_ests0, curr_gc_factor_ests1, curr_gc_factor_ests2, curr_gc_factor_ests3, curr_gc_factor_ests4)]\n",
        "curr_gc_factor_ests = [x/5. for x in curr_gc_factor_ests]\n",
        "\n",
        "\n",
        "for i in range(len(curr_gc_factor_ests)):\n",
        "    fig, ax = plt.subplots()\n",
        "    fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "    im = ax.imshow(curr_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r')\n",
        "    fig.colorbar(im, orientation='vertical')\n",
        "    plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "    plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "    plt.xlabel(\"Driving Channels\")\n",
        "    plt.ylabel(\"Receiving Channels\")\n",
        "    plt.title(\"Est. Causality: \"+factor_names[i]+\"\\n\")\n",
        "    plt.show()\n",
        "\n",
        "print(\"DIFFERENCE BETWEEN FACTOR 1 AND FACTOR 2 ------------------------\")\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(i,3):\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_gc_factor_ests[j][:,:,:].sum(axis=2) - curr_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[j]+\" - \"+factor_names[i])\n",
        "        plt.show()\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_gc_factor_ests[i][:,:,:].sum(axis=2) - curr_gc_factor_ests[j][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[i]+\" - \"+factor_names[j])\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n\\n\\n # OFF-DIAGONAL VISUALIZATIONS ##########################################################################################################\")\n",
        "\n",
        "curr_offDiag_gc_factor_ests = [x.detach().numpy() for x in model.GC(\"fixed_factor_exclusive\", X=None, threshold=False, ignore_lag=False, combine_wavelet_representations=True, rank_wavelets=False)[0]]\n",
        "curr_offDiag_gc_factor_ests = [x - x*np.expand_dims(np.eye(x.shape[0]), axis=2) for x in curr_offDiag_gc_factor_ests]\n",
        "curr_offDiag_gc_factor_ests = [x/np.max(x) for x in curr_offDiag_gc_factor_ests]\n",
        "\n",
        "for i in range(len(curr_offDiag_gc_factor_ests)):\n",
        "    fig, ax = plt.subplots()\n",
        "    fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "    im = ax.imshow(curr_offDiag_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r')\n",
        "    fig.colorbar(im, orientation='vertical')\n",
        "    plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "    plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "    plt.xlabel(\"Driving Channels\")\n",
        "    plt.ylabel(\"Receiving Channels\")\n",
        "    plt.title(\"Est. Causality: \"+factor_names[i]+\"\\n\")\n",
        "    plt.show()\n",
        "\n",
        "print(\"DIFFERENCE BETWEEN FACTOR 1 AND FACTOR 2 ------------------------\")\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(i,3):\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_offDiag_gc_factor_ests[j][:,:,:].sum(axis=2) - curr_offDiag_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[j]+\" - \"+factor_names[i])\n",
        "        plt.show()\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_offDiag_gc_factor_ests[i][:,:,:].sum(axis=2) - curr_offDiag_gc_factor_ests[j][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[i]+\" - \"+factor_names[j])\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "4YL3MSKCSIlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization of Fold4 TST 9-factor REDCLIFF-S Model, 01/04/2025"
      ],
      "metadata": {
        "id": "9Duv9ChcrNQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle as pkl\n",
        "\n",
        "from general_utils.misc import get_topk_graph_mask\n",
        "\n",
        "FONT_SMALL_SIZE = 18\n",
        "FONT_MEDIUM_SIZE = 20\n",
        "FONT_BIGGER_SIZE = 22\n",
        "\n",
        "plt.rc('font', size=FONT_SMALL_SIZE)          # controls default text sizes\n",
        "plt.rc('axes', titlesize=FONT_BIGGER_SIZE)     # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=FONT_MEDIUM_SIZE)    # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=FONT_SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=FONT_SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=FONT_SMALL_SIZE)    # legend fontsize\n",
        "plt.rc('figure', titlesize=FONT_BIGGER_SIZE)  # fontsize of the figure title\n",
        "\n",
        "\n",
        "factor_names = [\"Home Cage (HC)\", \"Open Field (OF)\", \"Tail Suspended (TS)\",\n",
        "                \"UNKNOWN 1 (U1)\", \"UNKNOWN 2 (U2)\", \"UNKNOWN 3 (U3)\",\n",
        "                \"UNKNOWN 4 (U4)\", \"UNKNOWN 5 (U5)\", \"UNKNOWN 6 (U6)\", ]\n",
        "channel_names = [\n",
        "    'Acb_Core', 'Acb_Sh', 'IL_Cx', 'L_VTA', 'Md_Thal', 'PrL_Cx', 'R_VTA', 'aILH_Hab', 'IDHip', 'lSNC', 'mDHip', 'mSNC'\n",
        "]\n",
        "model = torch.load(\"RegAvg_final_best_model.bin\", map_location=torch.device('cpu'))\n",
        "curr_gc_factor_ests = [x.detach().numpy() for x in model.GC(\"fixed_factor_exclusive\", X=None, threshold=False, ignore_lag=False, combine_wavelet_representations=True, rank_wavelets=False)[0]]\n",
        "\n",
        "\n",
        "curr_gc_factor_ests = [x/np.max(x) for x in curr_gc_factor_ests]\n",
        "\n",
        "\n",
        "for i in range(len(curr_gc_factor_ests)):\n",
        "    fig, ax = plt.subplots()\n",
        "    fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "    im = ax.imshow(curr_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r')\n",
        "    fig.colorbar(im, orientation='vertical')\n",
        "    plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "    plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "    plt.xlabel(\"Driving Channels\")\n",
        "    plt.ylabel(\"Receiving Channels\")\n",
        "    plt.title(\"Est. Causality: \"+factor_names[i]+\"\\n\")\n",
        "    plt.show()\n",
        "\n",
        "print(\"DIFFERENCE BETWEEN FACTOR 1 AND FACTOR 2 ------------------------\")\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(i,3):\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_gc_factor_ests[j][:,:,:].sum(axis=2) - curr_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[j]+\" - \"+factor_names[i])\n",
        "        plt.show()\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_gc_factor_ests[i][:,:,:].sum(axis=2) - curr_gc_factor_ests[j][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")#.set_fontsize(15)\n",
        "        plt.ylabel(\"Receiving Channels\")#.set_fontsize(15)\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[i]+\" - \"+factor_names[j])#.set_fontsize(23)#plt.title(\"Factor\"+str(j)+\" - Factor\"+str(i)).set_fontsize(20)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n\\n\\n # OFF-DIAGONAL VISUALIZATIONS ##########################################################################################################\")\n",
        "\n",
        "curr_offDiag_gc_factor_ests = [x.detach().numpy() for x in model.GC(\"fixed_factor_exclusive\", X=None, threshold=False, ignore_lag=False, combine_wavelet_representations=True, rank_wavelets=False)[0]]\n",
        "curr_offDiag_gc_factor_ests = [x - x*np.expand_dims(np.eye(x.shape[0]), axis=2) for x in curr_offDiag_gc_factor_ests]\n",
        "curr_offDiag_gc_factor_ests = [x/np.max(x) for x in curr_offDiag_gc_factor_ests]\n",
        "\n",
        "for i in range(len(curr_offDiag_gc_factor_ests)):\n",
        "    fig, ax = plt.subplots()\n",
        "    fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "    im = ax.imshow(curr_offDiag_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r')\n",
        "    fig.colorbar(im, orientation='vertical')\n",
        "    plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "    plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "    plt.xlabel(\"Driving Channels\")\n",
        "    plt.ylabel(\"Receiving Channels\")\n",
        "    plt.title(\"Est. Causality: \"+factor_names[i]+\"\\n\")\n",
        "    plt.show()\n",
        "\n",
        "print(\"DIFFERENCE BETWEEN FACTOR 1 AND FACTOR 2 ------------------------\")\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(i,3):\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_offDiag_gc_factor_ests[j][:,:,:].sum(axis=2) - curr_offDiag_gc_factor_ests[i][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[j]+\" - \"+factor_names[i])\n",
        "        plt.show()\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        fig.set_size_inches(9, 9)# see https://stackoverflow.com/questions/14770735/how-do-i-change-the-figure-size-with-subplots\n",
        "        im = ax.imshow(curr_offDiag_gc_factor_ests[i][:,:,:].sum(axis=2) - curr_offDiag_gc_factor_ests[j][:,:,:].sum(axis=2), cmap='RdGy_r', vmin=-1., vmax=1.)\n",
        "        fig.colorbar(im, orientation='vertical')\n",
        "        plt.xticks(range(0,len(channel_names)), channel_names, rotation=70)\n",
        "        plt.yticks(range(0,len(channel_names)), channel_names, rotation=0)\n",
        "        plt.xlabel(\"Driving Channels\")\n",
        "        plt.ylabel(\"Receiving Channels\")\n",
        "        plt.title(\"Diff. in Estimated Granger Causality:\\n\"+factor_names[i]+\" - \"+factor_names[j])\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "329vm0bxrHAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TST REDCLIFF-S Factor Selection"
      ],
      "metadata": {
        "id": "bhq9iiizqcZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 01/02/2025: Comparing cross-validated stopping criteria performance of different numbers of factors for REDCLIFF-S (with smoothing) models on TST FULL\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "a = (1.8152634328206378 + 1.6735604640007018 + 1.7691205581029255 + 2.0231672916412355 + 1.8211184668540952)/5.\n",
        "\n",
        "b = (1.644940238793691 + 1.5510279677708942 + 1.5539443830490112 + 1.6118970626195268 + 1.5942805566628777)/5.\n",
        "\n",
        "c = (1.6701837122599286 + 1.4978212252934775 + 1.5763399982452393 + 1.3798458410898844 + 1.5405776233673096)/5.\n",
        "\n",
        "d = (1.3647625046412146 + 1.4716529840628305 + 1.521159366607666 + 1.538966859380404 + 1.6362474794705708)/5.\n",
        "\n",
        "e = (1.5955952912012736 + 1.560348970413208 + 1.1719687076687815 + 1.4126835092902184 + 1.4325757805506387)/5.\n",
        "\n",
        "f = (1.4241380001703898 + 1.4003433541456858 + 1.5324883454640708 + 1.3831266793568928 + 1.4104654241402943)/5.\n",
        "\n",
        "print(\"REDCLIFF_S_CMLP_nK3_nsK3: \", a)\n",
        "print(\"REDCLIFF_S_CMLP_nK4_nsK3: \", b)\n",
        "print(\"REDCLIFF_S_CMLP_nK5_nsK3: \", c)\n",
        "print(\"REDCLIFF_S_CMLP_nK6_nsK3: \", d)\n",
        "print(\"REDCLIFF_S_CMLP_nK9_nsK3: \", e)\n",
        "print(\"REDCLIFF_S_CMLP_nK18_nsK3: \", f)\n",
        "\n",
        "plt.plot([3,4,5,6,9,18,], [a,b,c,d,e,f], color='grey', alpha=0.5)\n",
        "plt.scatter([3,4,5,6,18,], [a,b,c,d,f,], marker=\"+\", color='k')\n",
        "plt.scatter([9,], [e,], marker=\"^\", label=\"Selected Model\", color=\"orangered\")\n",
        "plt.xlabel(\"Number of Factors in Model\")\n",
        "plt.ylabel(\"Avg. Stopping Criteria Performance Across Folds\")\n",
        "plt.title(\"Determining the Number of Factors for TST (Full) REDCLIFF-S Model\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JZ0tWv2GIY4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 01/02/2025: Comparing cross-validated stopping criteria performance of different numbers of factors for REDCLIFF-S (with smoothing) models on TST SUBSET\n",
        "print(\"REDCLIFF_S_CMLP_nK3_nsK3: \", (2.4684973526000977 + 2.954598375956217 + 2.9015039634704594 + 2.4891041628519694 + 2.678949788411458)/5.)\n",
        "\n",
        "print(\"REDCLIFF_S_CMLP_nK4_nsK3: \", (2.564681212107341 + 2.581714407602946 + 2.5638554255167647 + 2.7155224482218423 + 2.8519512557983395)/5.)\n",
        "\n",
        "print(\"REDCLIFF_S_CMLP_nK5_nsK3: \", (2.271371332804362 + 2.059069341023763 + 2.5489660135904946 + 2.4858938280741376 + 2.601390247344971)/5.)\n",
        "\n",
        "print(\"REDCLIFF_S_CMLP_nK6_nsK3: \", (2.195953181584676 + 2.5948117383321128 + 2.5258967526753744 + 2.5001147365570064 + 2.7355075772603357)/5.)\n",
        "\n",
        "print(\"REDCLIFF_S_CMLP_nK9_nsK3: \", (2.130304797490438 + 2.8107280000050863 + 2.250448354085287 + 2.1140146795908614 + 2.0482943630218506)/5.)\n",
        "\n",
        "print(\"REDCLIFF_S_CMLP_nK18_nsK3: \", (2.5113415718078613 + 2.098219045003255 + 2.7476954587300617 + 2.7606082439422606 + 2.124862407048543)/5.)\n",
        "\n",
        "print(\"REDCLIFF_S_CMLP_nK30_nsK3: \", (2.176120545069377 + 2.146807723045349 + 2.4143293126424155 + 2.2496908124287924 + 2.1703793573379517)/5.)\n",
        "\n",
        "print(\"REDCLIFF_S_CMLP_nK45_nsK3: \", (2.1492295328776043 + 2.4391604391733805 + 2.133251234690348 + 2.4489138730367026 + 2.380597751935323)/5.)\n",
        "\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "a = (2.4684973526000977 + 2.954598375956217 + 2.9015039634704594 + 2.4891041628519694 + 2.678949788411458)/5.\n",
        "b = (2.564681212107341 + 2.581714407602946 + 2.5638554255167647 + 2.7155224482218423 + 2.8519512557983395)/5.\n",
        "c = (2.271371332804362 + 2.059069341023763 + 2.5489660135904946 + 2.4858938280741376 + 2.601390247344971)/5.\n",
        "d = (2.195953181584676 + 2.5948117383321128 + 2.5258967526753744 + 2.5001147365570064 + 2.7355075772603357)/5.\n",
        "e = (2.130304797490438 + 2.8107280000050863 + 2.250448354085287 + 2.1140146795908614 + 2.0482943630218506)/5.\n",
        "f = (2.5113415718078613 + 2.098219045003255 + 2.7476954587300617 + 2.7606082439422606 + 2.124862407048543)/5.\n",
        "g = (2.176120545069377 + 2.146807723045349 + 2.4143293126424155 + 2.2496908124287924 + 2.1703793573379517)/5.\n",
        "h = (2.1492295328776043 + 2.4391604391733805 + 2.133251234690348 + 2.4489138730367026 + 2.380597751935323)/5.\n",
        "\n",
        "plt.plot([3,4,5,6,9,18,30,45], [a,b,c,d,e,f,g,h], color='grey', alpha=0.5)\n",
        "plt.scatter([3,4,5,6,18,30,45], [a,b,c,d,f,g,h], marker=\"+\", color='k')\n",
        "plt.scatter([9,], [e,], marker=\"^\", label=\"Selected Model\", color=\"orangered\")\n",
        "plt.xlabel(\"Number of Factors in Model\")\n",
        "plt.ylabel(\"Avg. Stopping Criteria Performance Across Folds\")\n",
        "plt.title(\"Determining the Number of Factors for TST (Subset) REDCLIFF-S Model\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BPcOqy8gAYe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing REDCLIFF-S TST Reg. Avg. Model Parameters for Appendices"
      ],
      "metadata": {
        "id": "Rdb8r_Ns9nmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# model parameters\n",
        "# tau_in (i.e. gen_lag_and_input_len) -> USE ORIGINAL VALUE IN CACHED ARGS\n",
        "# omega (i.e. FORECAST_COEFF)         -> USE ORIGINAL VALUE IN CACHED ARGS\n",
        "# rho (i.e. FACTOR_COS_SIM_COEFF) -> use FACTOR_COS_SIM_COEFF/sum([1.*i for i in range(1,args_dict[\"num_factors\"])])\n",
        "print(\"rho is \", 1.0/sum([1.*i for i in range(1,9)]))\n",
        "# eta (i.e. ADJ_L1_REG_COEFF) -> ADJ_L1_REG_COEFF*(1./(1.*args_dict[\"num_factors\"]))*(1./np.sqrt(args_dict[\"num_channels\"]**2. - 1.))\n",
        "print(\"eta is \", 0.1*(1./(1.*9))*(1./np.sqrt(12**2. - 1.)))\n",
        "# gamma (i.e. FACTOR_WEIGHT_L1_COEFF) -> USE ORIGINAL VALUE IN CACHED ARGS\n",
        "# lambda (i.e. FACTOR_SCORE_COEFF)    -> USE ORIGINAL VALUE IN CACHED ARGS\n"
      ],
      "metadata": {
        "id": "LOMJlVEq9t5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Synthetic Systems Experiment Analyses"
      ],
      "metadata": {
        "id": "CnHpQ37jqVMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SynSys 12-11-2 MSNR Analyses"
      ],
      "metadata": {
        "id": "iN_zOB5oieor"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NON-TRANSPOSED PREDICTION STATS"
      ],
      "metadata": {
        "id": "d83knmxMieXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle as pkl\n",
        "\n",
        "og_stats_fold0 = pkl.load(open(\"stats_by_alg_key_dict_fold0.pkl\", \"rb\"))\n",
        "og_stats_fold1 = pkl.load(open(\"stats_by_alg_key_dict_fold1.pkl\", \"rb\"))\n",
        "og_stats_fold2 = pkl.load(open(\"stats_by_alg_key_dict_fold2.pkl\", \"rb\"))\n",
        "og_stats_fold3 = pkl.load(open(\"stats_by_alg_key_dict_fold3.pkl\", \"rb\"))\n",
        "og_stats_fold4 = pkl.load(open(\"stats_by_alg_key_dict_fold4.pkl\", \"rb\"))\n",
        "\n",
        "print(\"og_stats_fold0.keys() == \", og_stats_fold0.keys())\n",
        "performance_across_folds_by_alg = {key[len(\"SynSys12112MSNRFold0_model_name_\"):]:{\"fold_\"+str(i): dict() for i in range(5)} for key in og_stats_fold0.keys() if key.startswith(\"SynSys12112MSNRFold0_model_name_\")}\n",
        "print(\"performance_across_folds_by_alg.keys() == \", performance_across_folds_by_alg.keys())\n",
        "\n",
        "for f_ind, og_stats in enumerate([og_stats_fold0, og_stats_fold1, og_stats_fold2, og_stats_fold3, og_stats_fold4]):\n",
        "    print(\"f_ind == \", f_ind)\n",
        "    for og_alg_key in og_stats.keys():\n",
        "        for alg_key in performance_across_folds_by_alg.keys():\n",
        "            if alg_key in og_alg_key:\n",
        "                for factor_key in sorted(list(og_stats[og_alg_key].keys())):\n",
        "                    for stat_key in og_stats[og_alg_key][factor_key].keys():\n",
        "                        if stat_key in performance_across_folds_by_alg[alg_key][f\"fold_{f_ind}\"].keys():\n",
        "                            if \"ancestor_aid\" in stat_key or \"oset_aid\" in stat_key or \"parent_aid\" in stat_key or \"_shd\" in stat_key:\n",
        "                                try:\n",
        "                                    performance_across_folds_by_alg[alg_key][f\"fold_{f_ind}\"][stat_key][\"normalized\"].append(og_stats[og_alg_key][factor_key][stat_key][0])\n",
        "                                    performance_across_folds_by_alg[alg_key][f\"fold_{f_ind}\"][stat_key][\"raw_count\"].append(og_stats[og_alg_key][factor_key][stat_key][1])\n",
        "                                except:\n",
        "                                    performance_across_folds_by_alg[alg_key][f\"fold_{f_ind}\"][stat_key][\"normalized\"].append(og_stats[og_alg_key][factor_key][stat_key])\n",
        "                                    performance_across_folds_by_alg[alg_key][f\"fold_{f_ind}\"][stat_key][\"raw_count\"].append(og_stats[og_alg_key][factor_key][stat_key])\n",
        "                            else:\n",
        "                                performance_across_folds_by_alg[alg_key][f\"fold_{f_ind}\"][stat_key].append(og_stats[og_alg_key][factor_key][stat_key])\n",
        "                        else:\n",
        "                            if \"ancestor_aid\" in stat_key or \"oset_aid\" in stat_key or \"parent_aid\" in stat_key or \"_shd\" in stat_key:\n",
        "                                try:\n",
        "                                    performance_across_folds_by_alg[alg_key][f\"fold_{f_ind}\"][stat_key] = {\n",
        "                                        \"normalized\": [og_stats[og_alg_key][factor_key][stat_key][0]],\n",
        "                                        \"raw_count\": [og_stats[og_alg_key][factor_key][stat_key][1]]\n",
        "                                    }\n",
        "                                except:\n",
        "                                    performance_across_folds_by_alg[alg_key][f\"fold_{f_ind}\"][stat_key] = {\n",
        "                                        \"normalized\": [og_stats[og_alg_key][factor_key][stat_key]],\n",
        "                                        \"raw_count\": [og_stats[og_alg_key][factor_key][stat_key]]\n",
        "                                    }\n",
        "                            else:\n",
        "                                performance_across_folds_by_alg[alg_key][f\"fold_{f_ind}\"][stat_key] = [og_stats[og_alg_key][factor_key][stat_key]]\n",
        "\n",
        "print(\"performance_across_folds_by_alg == \", performance_across_folds_by_alg)\n",
        "summary_stats_by_alg = {alg_key: dict() for alg_key in performance_across_folds_by_alg.keys()}\n",
        "for alg_key in performance_across_folds_by_alg.keys():\n",
        "    for fold_key in performance_across_folds_by_alg[alg_key].keys():\n",
        "        for stat_key in performance_across_folds_by_alg[alg_key][fold_key].keys():\n",
        "            if stat_key in summary_stats_by_alg[alg_key].keys():\n",
        "                if \"ancestor_aid\" in stat_key or \"oset_aid\" in stat_key or \"parent_aid\" in stat_key or \"_shd\" in stat_key:\n",
        "                    for substat_key in performance_across_folds_by_alg[alg_key][fold_key][stat_key].keys():\n",
        "                        summary_stats_by_alg[alg_key][stat_key][substat_key][\"fold_means\"].append(np.mean(performance_across_folds_by_alg[alg_key][fold_key][stat_key][substat_key]))\n",
        "                        summary_stats_by_alg[alg_key][stat_key][substat_key][\"stat_vals_across_folds_and_factors\"] = summary_stats_by_alg[alg_key][stat_key][substat_key][\"stat_vals_across_folds_and_factors\"] + performance_across_folds_by_alg[alg_key][fold_key][stat_key][substat_key]\n",
        "                else:\n",
        "                    summary_stats_by_alg[alg_key][stat_key][\"fold_means\"].append(np.mean(performance_across_folds_by_alg[alg_key][fold_key][stat_key]))\n",
        "                    summary_stats_by_alg[alg_key][stat_key][\"stat_vals_across_folds_and_factors\"] = summary_stats_by_alg[alg_key][stat_key][\"stat_vals_across_folds_and_factors\"] + performance_across_folds_by_alg[alg_key][fold_key][stat_key]\n",
        "            else:\n",
        "                if \"ancestor_aid\" in stat_key or \"oset_aid\" in stat_key or \"parent_aid\" in stat_key or \"_shd\" in stat_key:\n",
        "                    summary_stats_by_alg[alg_key][stat_key] = dict()\n",
        "                    for substat_key in performance_across_folds_by_alg[alg_key][fold_key][stat_key].keys():\n",
        "                        summary_stats_by_alg[alg_key][stat_key][substat_key] = {\n",
        "                            \"fold_means\": [np.mean(performance_across_folds_by_alg[alg_key][fold_key][stat_key][substat_key])],\n",
        "                            \"stat_vals_across_folds_and_factors\": []+performance_across_folds_by_alg[alg_key][fold_key][stat_key][substat_key],\n",
        "                            \"combo_stats_mean\": None,\n",
        "                            \"combo_stats_sem\": None,\n",
        "                            \"mean_of_fold_means\": None,\n",
        "                            \"sem_of_fold_means\": None,\n",
        "                        }\n",
        "                else:\n",
        "                    summary_stats_by_alg[alg_key][stat_key] = {\n",
        "                        \"fold_means\": [np.mean(performance_across_folds_by_alg[alg_key][fold_key][stat_key])],\n",
        "                        \"stat_vals_across_folds_and_factors\": []+performance_across_folds_by_alg[alg_key][fold_key][stat_key],\n",
        "                        \"combo_stats_mean\": None,\n",
        "                        \"combo_stats_sem\": None,\n",
        "                        \"mean_of_fold_means\": None,\n",
        "                        \"sem_of_fold_means\": None,\n",
        "                    }\n",
        "    for stat_key in summary_stats_by_alg[alg_key].keys():\n",
        "        if \"ancestor_aid\" in stat_key or \"oset_aid\" in stat_key or \"parent_aid\" in stat_key or \"_shd\" in stat_key:\n",
        "            for substat_key in performance_across_folds_by_alg[alg_key][fold_key][stat_key].keys():\n",
        "                summary_stats_by_alg[alg_key][stat_key][substat_key][\"combo_stats_mean\"] = np.mean(summary_stats_by_alg[alg_key][stat_key][substat_key][\"stat_vals_across_folds_and_factors\"])\n",
        "                summary_stats_by_alg[alg_key][stat_key][substat_key][\"combo_stats_sem\"] = np.std(summary_stats_by_alg[alg_key][stat_key][substat_key][\"stat_vals_across_folds_and_factors\"]) / np.sqrt(len(summary_stats_by_alg[alg_key][stat_key][substat_key][\"stat_vals_across_folds_and_factors\"]))\n",
        "                summary_stats_by_alg[alg_key][stat_key][substat_key][\"mean_of_fold_means\"] = np.mean(summary_stats_by_alg[alg_key][stat_key][substat_key][\"fold_means\"])\n",
        "                summary_stats_by_alg[alg_key][stat_key][substat_key][\"sem_of_fold_means\"] = np.std(summary_stats_by_alg[alg_key][stat_key][substat_key][\"fold_means\"]) / np.sqrt(len(summary_stats_by_alg[alg_key][stat_key][substat_key][\"fold_means\"]))\n",
        "        else:\n",
        "            summary_stats_by_alg[alg_key][stat_key][\"combo_stats_mean\"] = np.mean(summary_stats_by_alg[alg_key][stat_key][\"stat_vals_across_folds_and_factors\"])\n",
        "            summary_stats_by_alg[alg_key][stat_key][\"combo_stats_sem\"] = np.std(summary_stats_by_alg[alg_key][stat_key][\"stat_vals_across_folds_and_factors\"]) / np.sqrt(len(summary_stats_by_alg[alg_key][stat_key][\"stat_vals_across_folds_and_factors\"]))\n",
        "            summary_stats_by_alg[alg_key][stat_key][\"mean_of_fold_means\"] = np.mean(summary_stats_by_alg[alg_key][stat_key][\"fold_means\"])\n",
        "            summary_stats_by_alg[alg_key][stat_key][\"sem_of_fold_means\"] = np.std(summary_stats_by_alg[alg_key][stat_key][\"fold_means\"]) / np.sqrt(len(summary_stats_by_alg[alg_key][stat_key][\"fold_means\"]))\n",
        "\n",
        "print(\"summary_stats_by_alg == \", summary_stats_by_alg)\n",
        "for alg in summary_stats_by_alg.keys():\n",
        "    print(\"alg == \", alg)\n",
        "    for stat in summary_stats_by_alg[alg].keys():\n",
        "        print(\"\\t stat == \", stat)\n",
        "        for summary_key in summary_stats_by_alg[alg][stat].keys():\n",
        "            if \"_aid\" in stat or \"_shd\" in stat:\n",
        "                print(\"\\t\\t sub_stat == \", summary_key)\n",
        "                for sub_stat_summary in summary_stats_by_alg[alg][stat][summary_key].keys():\n",
        "                    print(\"\\t\\t\\t summary_key == \", sub_stat_summary, \" == \", summary_stats_by_alg[alg][stat][summary_key][sub_stat_summary])\n",
        "            else:\n",
        "                print(\"\\t\\t summary_key == \", summary_key, \" == \", summary_stats_by_alg[alg][stat][summary_key])"
      ],
      "metadata": {
        "id": "ZnQou3skieMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRANSPOSED PREDICTION STATS"
      ],
      "metadata": {
        "id": "2bpwx8lmid--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle as pkl\n",
        "\n",
        "og_stats_fold0 = pkl.load(open(\"stats_by_alg_key_dict_fold0.pkl\", \"rb\"))\n",
        "og_stats_fold1 = pkl.load(open(\"stats_by_alg_key_dict_fold1.pkl\", \"rb\"))\n",
        "og_stats_fold2 = pkl.load(open(\"stats_by_alg_key_dict_fold2.pkl\", \"rb\"))\n",
        "og_stats_fold3 = pkl.load(open(\"stats_by_alg_key_dict_fold3.pkl\", \"rb\"))\n",
        "og_stats_fold4 = pkl.load(open(\"stats_by_alg_key_dict_fold4.pkl\", \"rb\"))\n",
        "\n",
        "print(\"og_stats_fold0.keys() == \", og_stats_fold0.keys())\n",
        "performance_across_folds_by_alg = {key[len(\"SynSys12112MSNRFold0_model_name_\"):]:{\"fold_\"+str(i): dict() for i in range(5)} for key in og_stats_fold0.keys() if key.startswith(\"SynSys12112MSNRFold0_model_name_\")}\n",
        "print(\"performance_across_folds_by_alg.keys() == \", performance_across_folds_by_alg.keys())\n",
        "\n",
        "for f_ind, og_stats in enumerate([og_stats_fold0, og_stats_fold1, og_stats_fold2, og_stats_fold3, og_stats_fold4]):\n",
        "    print(\"f_ind == \", f_ind)\n",
        "    for og_alg_key in og_stats.keys():\n",
        "        for alg_key in performance_across_folds_by_alg.keys():\n",
        "            if alg_key in og_alg_key:\n",
        "                for factor_key in sorted(list(og_stats[og_alg_key].keys())):\n",
        "                    for stat_key in og_stats[og_alg_key][factor_key].keys():\n",
        "                        if stat_key in performance_across_folds_by_alg[alg_key][f\"fold_{f_ind}\"].keys():\n",
        "                            if \"ancestor_aid\" in stat_key or \"oset_aid\" in stat_key or \"parent_aid\" in stat_key or \"_shd\" in stat_key:\n",
        "                                try:\n",
        "                                    performance_across_folds_by_alg[alg_key][f\"fold_{f_ind}\"][stat_key][\"normalized\"].append(og_stats[og_alg_key][factor_key][stat_key][0])\n",
        "                                    performance_across_folds_by_alg[alg_key][f\"fold_{f_ind}\"][stat_key][\"raw_count\"].append(og_stats[og_alg_key][factor_key][stat_key][1])\n",
        "                                except:\n",
        "                                    performance_across_folds_by_alg[alg_key][f\"fold_{f_ind}\"][stat_key][\"normalized\"].append(og_stats[og_alg_key][factor_key][stat_key])\n",
        "                                    performance_across_folds_by_alg[alg_key][f\"fold_{f_ind}\"][stat_key][\"raw_count\"].append(og_stats[og_alg_key][factor_key][stat_key])\n",
        "                            else:\n",
        "                                performance_across_folds_by_alg[alg_key][f\"fold_{f_ind}\"][stat_key].append(og_stats[og_alg_key][factor_key][stat_key])\n",
        "                        else:\n",
        "                            if \"ancestor_aid\" in stat_key or \"oset_aid\" in stat_key or \"parent_aid\" in stat_key or \"_shd\" in stat_key:\n",
        "                                try:\n",
        "                                    performance_across_folds_by_alg[alg_key][f\"fold_{f_ind}\"][stat_key] = {\n",
        "                                        \"normalized\": [og_stats[og_alg_key][factor_key][stat_key][0]],\n",
        "                                        \"raw_count\": [og_stats[og_alg_key][factor_key][stat_key][1]]\n",
        "                                    }\n",
        "                                except:\n",
        "                                    performance_across_folds_by_alg[alg_key][f\"fold_{f_ind}\"][stat_key] = {\n",
        "                                        \"normalized\": [og_stats[og_alg_key][factor_key][stat_key]],\n",
        "                                        \"raw_count\": [og_stats[og_alg_key][factor_key][stat_key]]\n",
        "                                    }\n",
        "                            else:\n",
        "                                performance_across_folds_by_alg[alg_key][f\"fold_{f_ind}\"][stat_key] = [og_stats[og_alg_key][factor_key][stat_key]]\n",
        "\n",
        "print(\"performance_across_folds_by_alg == \", performance_across_folds_by_alg)\n",
        "summary_stats_by_alg = {alg_key: dict() for alg_key in performance_across_folds_by_alg.keys()}\n",
        "for alg_key in performance_across_folds_by_alg.keys():\n",
        "    for fold_key in performance_across_folds_by_alg[alg_key].keys():\n",
        "        for stat_key in performance_across_folds_by_alg[alg_key][fold_key].keys():\n",
        "            if stat_key in summary_stats_by_alg[alg_key].keys():\n",
        "                if \"ancestor_aid\" in stat_key or \"oset_aid\" in stat_key or \"parent_aid\" in stat_key or \"_shd\" in stat_key:\n",
        "                    for substat_key in performance_across_folds_by_alg[alg_key][fold_key][stat_key].keys():\n",
        "                        summary_stats_by_alg[alg_key][stat_key][substat_key][\"fold_means\"].append(np.mean(performance_across_folds_by_alg[alg_key][fold_key][stat_key][substat_key]))\n",
        "                        summary_stats_by_alg[alg_key][stat_key][substat_key][\"stat_vals_across_folds_and_factors\"] = summary_stats_by_alg[alg_key][stat_key][substat_key][\"stat_vals_across_folds_and_factors\"] + performance_across_folds_by_alg[alg_key][fold_key][stat_key][substat_key]\n",
        "                else:\n",
        "                    summary_stats_by_alg[alg_key][stat_key][\"fold_means\"].append(np.mean(performance_across_folds_by_alg[alg_key][fold_key][stat_key]))\n",
        "                    summary_stats_by_alg[alg_key][stat_key][\"stat_vals_across_folds_and_factors\"] = summary_stats_by_alg[alg_key][stat_key][\"stat_vals_across_folds_and_factors\"] + performance_across_folds_by_alg[alg_key][fold_key][stat_key]\n",
        "            else:\n",
        "                if \"ancestor_aid\" in stat_key or \"oset_aid\" in stat_key or \"parent_aid\" in stat_key or \"_shd\" in stat_key:\n",
        "                    summary_stats_by_alg[alg_key][stat_key] = dict()\n",
        "                    for substat_key in performance_across_folds_by_alg[alg_key][fold_key][stat_key].keys():\n",
        "                        summary_stats_by_alg[alg_key][stat_key][substat_key] = {\n",
        "                            \"fold_means\": [np.mean(performance_across_folds_by_alg[alg_key][fold_key][stat_key][substat_key])],\n",
        "                            \"stat_vals_across_folds_and_factors\": []+performance_across_folds_by_alg[alg_key][fold_key][stat_key][substat_key],\n",
        "                            \"combo_stats_mean\": None,\n",
        "                            \"combo_stats_sem\": None,\n",
        "                            \"mean_of_fold_means\": None,\n",
        "                            \"sem_of_fold_means\": None,\n",
        "                        }\n",
        "                else:\n",
        "                    summary_stats_by_alg[alg_key][stat_key] = {\n",
        "                        \"fold_means\": [np.mean(performance_across_folds_by_alg[alg_key][fold_key][stat_key])],\n",
        "                        \"stat_vals_across_folds_and_factors\": []+performance_across_folds_by_alg[alg_key][fold_key][stat_key],\n",
        "                        \"combo_stats_mean\": None,\n",
        "                        \"combo_stats_sem\": None,\n",
        "                        \"mean_of_fold_means\": None,\n",
        "                        \"sem_of_fold_means\": None,\n",
        "                    }\n",
        "    for stat_key in summary_stats_by_alg[alg_key].keys():\n",
        "        if \"ancestor_aid\" in stat_key or \"oset_aid\" in stat_key or \"parent_aid\" in stat_key or \"_shd\" in stat_key:\n",
        "            for substat_key in performance_across_folds_by_alg[alg_key][fold_key][stat_key].keys():\n",
        "                summary_stats_by_alg[alg_key][stat_key][substat_key][\"combo_stats_mean\"] = np.mean(summary_stats_by_alg[alg_key][stat_key][substat_key][\"stat_vals_across_folds_and_factors\"])\n",
        "                summary_stats_by_alg[alg_key][stat_key][substat_key][\"combo_stats_sem\"] = np.std(summary_stats_by_alg[alg_key][stat_key][substat_key][\"stat_vals_across_folds_and_factors\"]) / np.sqrt(len(summary_stats_by_alg[alg_key][stat_key][substat_key][\"stat_vals_across_folds_and_factors\"]))\n",
        "                summary_stats_by_alg[alg_key][stat_key][substat_key][\"mean_of_fold_means\"] = np.mean(summary_stats_by_alg[alg_key][stat_key][substat_key][\"fold_means\"])\n",
        "                summary_stats_by_alg[alg_key][stat_key][substat_key][\"sem_of_fold_means\"] = np.std(summary_stats_by_alg[alg_key][stat_key][substat_key][\"fold_means\"]) / np.sqrt(len(summary_stats_by_alg[alg_key][stat_key][substat_key][\"fold_means\"]))\n",
        "        else:\n",
        "            summary_stats_by_alg[alg_key][stat_key][\"combo_stats_mean\"] = np.mean(summary_stats_by_alg[alg_key][stat_key][\"stat_vals_across_folds_and_factors\"])\n",
        "            summary_stats_by_alg[alg_key][stat_key][\"combo_stats_sem\"] = np.std(summary_stats_by_alg[alg_key][stat_key][\"stat_vals_across_folds_and_factors\"]) / np.sqrt(len(summary_stats_by_alg[alg_key][stat_key][\"stat_vals_across_folds_and_factors\"]))\n",
        "            summary_stats_by_alg[alg_key][stat_key][\"mean_of_fold_means\"] = np.mean(summary_stats_by_alg[alg_key][stat_key][\"fold_means\"])\n",
        "            summary_stats_by_alg[alg_key][stat_key][\"sem_of_fold_means\"] = np.std(summary_stats_by_alg[alg_key][stat_key][\"fold_means\"]) / np.sqrt(len(summary_stats_by_alg[alg_key][stat_key][\"fold_means\"]))\n",
        "\n",
        "print(\"summary_stats_by_alg == \", summary_stats_by_alg)\n",
        "for alg in summary_stats_by_alg.keys():\n",
        "    print(\"alg == \", alg)\n",
        "    for stat in summary_stats_by_alg[alg].keys():\n",
        "        print(\"\\t stat == \", stat)\n",
        "        for summary_key in summary_stats_by_alg[alg][stat].keys():\n",
        "            if \"_aid\" in stat or \"_shd\" in stat:\n",
        "                print(\"\\t\\t sub_stat == \", summary_key)\n",
        "                for sub_stat_summary in summary_stats_by_alg[alg][stat][summary_key].keys():\n",
        "                    print(\"\\t\\t\\t summary_key == \", sub_stat_summary, \" == \", summary_stats_by_alg[alg][stat][summary_key][sub_stat_summary])\n",
        "            else:\n",
        "                print(\"\\t\\t summary_key == \", summary_key, \" == \", summary_stats_by_alg[alg][stat][summary_key])"
      ],
      "metadata": {
        "id": "e5SI-2njidvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing Estimated Synthetic Systems Factors 01/29/2025"
      ],
      "metadata": {
        "id": "jvjBftnjfvkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torcheeg"
      ],
      "metadata": {
        "id": "BdgoGQ2Ofvag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch_scatter"
      ],
      "metadata": {
        "id": "lbuefdj-f4dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "# configure model\n",
        "model_645Fold4 = torch.load(\"645Fold4_final_model.bin\")\n",
        "model_645Fold4.primary_gc_est_mode = \"fixed_factor_exclusive\""
      ],
      "metadata": {
        "id": "VqP7cvAFf4KP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get gc factor ests\n",
        "gc_ests_by_sample = model_645Fold4.GC(model_645Fold4.primary_gc_est_mode, X=None, threshold=False, ignore_lag=False, combine_wavelet_representations=True, rank_wavelets=False)\n",
        "assert len(gc_ests_by_sample) == 1\n",
        "gc_ests = [x.detach().numpy() for x in gc_ests_by_sample[0]]\n",
        "\n",
        "print(\"len(gc_ests) == \", len(gc_ests))\n",
        "print(\"gc_ests[0].shape == \", gc_ests[0].shape)\n",
        "\n",
        "gc_ests_noLags = [np.sum(x, axis=2) for x in gc_ests]\n",
        "print(\"gc_ests_noLags[0].shape == \", gc_ests_noLags[0].shape)\n",
        "\n",
        "off_diag_nolag_ests = [x-np.eye(x.shape[0])*x for x in gc_ests_noLags]\n",
        "off_diag_nolag_ests = [x/np.max(x) for x in off_diag_nolag_ests]\n",
        "\n",
        "mask = off_diag_nolag_ests[1] > 0.34\n",
        "f1_gc_nolag_est = off_diag_nolag_ests[1] * mask\n",
        "im1 = plt.imshow(f1_gc_nolag_est)\n",
        "plt.title('Factor 1 Top-5 GC Estimate, Threshold: '+str(0.34))\n",
        "plt.ylabel('Affected series')\n",
        "plt.xlabel('Causal series')\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.colorbar(im1)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "mask = off_diag_nolag_ests[3] > 0.4\n",
        "f3_gc_nolag_est = off_diag_nolag_ests[3] * mask\n",
        "im2 = plt.imshow(f3_gc_nolag_est)\n",
        "plt.title('Factor 3 Top-5 GC Estimate, Threshold: '+str(0.4))\n",
        "plt.ylabel('Affected series')\n",
        "plt.xlabel('Causal series')\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.colorbar(im2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "flFZtb3Zi0rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "# configure model\n",
        "model_12_11_5_Fold4 = torch.load(\"12_11_5_Fold4_final_model.bin\")\n",
        "model_12_11_5_Fold4.primary_gc_est_mode = \"fixed_factor_exclusive\""
      ],
      "metadata": {
        "id": "4dx-jwWQxOSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get gc factor ests\n",
        "gc_ests_by_sample = model_12_11_5_Fold4.GC(model_12_11_5_Fold4.primary_gc_est_mode, X=None, threshold=False, ignore_lag=False, combine_wavelet_representations=True, rank_wavelets=False)\n",
        "assert len(gc_ests_by_sample) == 1\n",
        "gc_ests = [x.detach().numpy() for x in gc_ests_by_sample[0]]\n",
        "\n",
        "print(\"len(gc_ests) == \", len(gc_ests))\n",
        "print(\"gc_ests[0].shape == \", gc_ests[0].shape)\n",
        "\n",
        "gc_ests_noLags = [np.sum(x, axis=2) for x in gc_ests]\n",
        "print(\"gc_ests_noLags[0].shape == \", gc_ests_noLags[0].shape)\n",
        "\n",
        "off_diag_nolag_ests = [x-np.eye(x.shape[0])*x for x in gc_ests_noLags]\n",
        "off_diag_nolag_ests = [x/np.max(x) for x in off_diag_nolag_ests]\n",
        "\n",
        "masking_thresholds = [0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, ]\n",
        "for t in masking_thresholds:\n",
        "    print(\"Threshold: \", t, \" ---------------------------------------------\")\n",
        "    for i, gc_nolag_est in enumerate(off_diag_nolag_ests):\n",
        "        mask = gc_nolag_est > t\n",
        "        gc_nolag_est = gc_nolag_est * mask\n",
        "        im1 = plt.imshow(gc_nolag_est)\n",
        "        plt.title('GC Estimate, Threshold: '+str(t))\n",
        "        plt.ylabel('Affected series')\n",
        "        plt.xlabel('Causal series')\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.colorbar(im1)\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "jZ5Vq6s4xZft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Highlighted Synth Data Results (01/21/2025)"
      ],
      "metadata": {
        "id": "7J6dYXlRdsSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "\n",
        "FONT_SMALL_SIZE = 18\n",
        "FONT_MEDIUM_SIZE = 20\n",
        "FONT_BIGGER_SIZE = 22\n",
        "\n",
        "plt.rc('font', size=FONT_SMALL_SIZE)          # controls default text sizes\n",
        "plt.rc('axes', titlesize=FONT_BIGGER_SIZE)     # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=FONT_MEDIUM_SIZE)    # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=FONT_SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=FONT_SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=FONT_SMALL_SIZE)    # legend fontsize\n",
        "plt.rc('figure', titlesize=FONT_BIGGER_SIZE)  # fontsize of the figure title\n",
        "\n",
        "\n",
        "\n",
        "def get_data_name_alias_for_plot_axes(orig_name):\n",
        "    return orig_name + \"   \"\n",
        "\n",
        "def get_data_name_alias(orig_name):\n",
        "    split_data_name = orig_name.split(\"_\")\n",
        "    abrieve_split_data_name = [int(x[2:]) for x in split_data_name]\n",
        "    data_name_alias = \"-\".join([str(x) for x in abrieve_split_data_name])\n",
        "    return data_name_alias\n",
        "\n",
        "def get_alg_name_alias(orig_name):\n",
        "    if orig_name == 'REDCLIFF_S_CMLP':\n",
        "        return 'REDCLIFF-S (cMLP)'\n",
        "    elif orig_name == 'REDCLIFF_S_CMLP_WithSmoothing':\n",
        "        return 'REDCLIFF-S (cMLP)'\n",
        "    elif orig_name == 'CMLP':\n",
        "        return 'cMLP'\n",
        "    elif orig_name == 'CLSTM':\n",
        "        return 'cLSTM'\n",
        "    elif orig_name == 'DCSFA':\n",
        "        return 'dCSFA-NMF'\n",
        "    elif orig_name == 'DYNOTEARS_Vanilla':\n",
        "        return 'DYNOTEARS'\n",
        "    elif orig_name == 'NAVAR_CMLP':\n",
        "        return 'NAVAR-P'\n",
        "    elif orig_name == 'NAVAR_CLSTM':\n",
        "        return 'NAVAR-R'\n",
        "    return orig_name\n",
        "\n",
        "\n",
        "\n",
        "dataset_names = [\n",
        "    \"nN6_nE2_nF2\",\n",
        "    \"nN6_nE4_nF2\",\n",
        "    \"nN12_nE11_nF2\",\n",
        "    \"nN12_nE11_nF5\",\n",
        "]\n",
        "alg_names = []\n",
        "mean_colors = [\"darkorange\", \"darkred\", \"mediumvioletred\", \"darkslateblue\", \"indigo\"]\n",
        "sem_colors = [\"orangered\", \"tomato\", \"lightcoral\", \"slategrey\", \"mediumpurple\"]\n",
        "\n",
        "alg_performance_means_tOpt = None\n",
        "alg_performance_sems_tOpt = None\n",
        "alg_vREDC_performance_means_tOpt = None\n",
        "alg_vREDC_performance_sems_tOpt = None\n",
        "\n",
        "\n",
        "for d, dataset in enumerate(dataset_names):\n",
        "    curr_alg_performance_means_tOpt = []\n",
        "    curr_alg_performance_sems_tOpt = []\n",
        "    curr_alg_vREDC_performance_means_tOpt = []\n",
        "    curr_alg_vREDC_performance_sems_tOpt = []\n",
        "\n",
        "    # read in bsOH results\n",
        "    curr_synth_results = None\n",
        "    with open(dataset+\"_full_comparrisson_summary.pkl\", \"rb\") as f:\n",
        "        curr_synth_results = pkl.load(f)\n",
        "\n",
        "    assert len(curr_synth_results.keys()) == 1\n",
        "    cv_key = list(curr_synth_results.keys())[0]\n",
        "    for i, alg_key in enumerate(curr_synth_results[cv_key]['key_stats_estGC_normOffDiag_vs_trueGC_normOffDiag'].keys()):\n",
        "        if d == 0:\n",
        "            alg_names.append(get_alg_name_alias(alg_key))\n",
        "        else:\n",
        "            assert get_alg_name_alias(alg_key) == alg_names[i]\n",
        "\n",
        "        curr_alg_eval_stats = curr_synth_results[cv_key]['key_stats_estGC_normOffDiag_vs_trueGC_normOffDiag'][alg_key]\n",
        "        for stat_key in curr_alg_eval_stats.keys():\n",
        "            if 'f1' in stat_key and \"mean_across_factors\" in stat_key:\n",
        "                curr_alg_performance_means_tOpt.append(curr_alg_eval_stats[stat_key])\n",
        "            elif 'f1' in stat_key and \"mean_std_err_across_factors\" in stat_key:\n",
        "                curr_alg_performance_sems_tOpt.append(curr_alg_eval_stats[stat_key])\n",
        "            elif 'f1' in stat_key and \"vals_across_factors\" in stat_key:\n",
        "                curr_diffs = [x-y for x, y in zip(curr_synth_results[cv_key]['key_stats_estGC_normOffDiag_vs_trueGC_normOffDiag']['REDCLIFF_S_CMLP_WithSmoothing'][stat_key], curr_alg_eval_stats[stat_key])]\n",
        "                curr_alg_vREDC_performance_means_tOpt.append(np.mean(curr_diffs))\n",
        "                curr_alg_vREDC_performance_sems_tOpt.append(np.std(curr_diffs)/np.sqrt(1.*len(curr_diffs)))\n",
        "\n",
        "        assert len(curr_alg_performance_means_tOpt) == i+1\n",
        "        assert len(curr_alg_performance_sems_tOpt) == i+1\n",
        "        assert len(curr_alg_vREDC_performance_means_tOpt) == i+1\n",
        "        assert len(curr_alg_vREDC_performance_sems_tOpt) == i+1\n",
        "\n",
        "    if d == 0:\n",
        "        alg_performance_means_tOpt = [None for _ in range(len(dataset_names)) for _ in range(len(alg_names))]\n",
        "        alg_performance_sems_tOpt = [None for _ in range(len(dataset_names)) for _ in range(len(alg_names))]\n",
        "        alg_vREDC_performance_means_tOpt = [None for _ in range(len(dataset_names)) for _ in range(len(alg_names))]\n",
        "        alg_vREDC_performance_sems_tOpt = [None for _ in range(len(dataset_names)) for _ in range(len(alg_names))]\n",
        "\n",
        "    for i in range(len(alg_names)):\n",
        "        if curr_alg_performance_means_tOpt[i] is None or np.isfinite(curr_alg_performance_means_tOpt[i]):\n",
        "            alg_performance_means_tOpt[d*len(alg_names) + i] = curr_alg_performance_means_tOpt[i]\n",
        "        else:\n",
        "            alg_performance_means_tOpt[d*len(alg_names) + i] = np.nan\n",
        "        if curr_alg_performance_sems_tOpt[i] is None or np.isfinite(curr_alg_performance_sems_tOpt[i]):\n",
        "            alg_performance_sems_tOpt[d*len(alg_names) + i] = curr_alg_performance_sems_tOpt[i]\n",
        "        else:\n",
        "            alg_performance_sems_tOpt[d*len(alg_names) + i] = np.nan\n",
        "        if curr_alg_vREDC_performance_means_tOpt[i] is None or np.isfinite(curr_alg_vREDC_performance_means_tOpt[i]):\n",
        "            alg_vREDC_performance_means_tOpt[d*len(alg_names) + i] = curr_alg_vREDC_performance_means_tOpt[i]\n",
        "        else:\n",
        "            alg_vREDC_performance_means_tOpt[d*len(alg_names) + i] = np.nan\n",
        "        if curr_alg_vREDC_performance_sems_tOpt[i] is None or np.isfinite(curr_alg_vREDC_performance_sems_tOpt[i]):\n",
        "            alg_vREDC_performance_sems_tOpt[d*len(alg_names) + i] = curr_alg_vREDC_performance_sems_tOpt[i]\n",
        "        else:\n",
        "            alg_vREDC_performance_sems_tOpt[d*len(alg_names) + i] = np.nan\n",
        "\n",
        "\n",
        "# remainder of code drafted with help from ChatGPT\n",
        "# Create figure and axis\n",
        "fig = plt.figure(figsize=(9.5, 7))\n",
        "gs = gridspec.GridSpec(1, 1)\n",
        "ax1 = plt.subplot(gs[0])\n",
        "\n",
        "\n",
        "bar_width = 0.9\n",
        "index = np.arange((len(alg_names)+1)*len(dataset_names))\n",
        "total_num_bars_per_dset = len(alg_names)# * 2.\n",
        "width_of_bars_per_dset = bar_width#/2\n",
        "\n",
        "alg_names = alg_names + [None]\n",
        "mean_colors = mean_colors + [None]\n",
        "sem_colors = sem_colors + [None]\n",
        "alg_index_offset = []\n",
        "for d in range(len(dataset_names)):\n",
        "    alg_index_offset = alg_index_offset + [d for _ in range(len(alg_names))]\n",
        "\n",
        "# Horizontal bar plot with whiskers\n",
        "for a, (alg_name, mean_color, sem_color) in enumerate(zip(alg_names, mean_colors, sem_colors)):\n",
        "    if alg_name is not None:\n",
        "        curr_inds = None\n",
        "        curr_means = None\n",
        "        curr_sems = None\n",
        "\n",
        "        print(\"alg_name == \", alg_name)\n",
        "        print(\"\\t len(alg_performance_means_tOpt) == \", len(alg_performance_means_tOpt))\n",
        "\n",
        "        curr_inds = [ind for ind in index if ind % len(alg_names) == a]\n",
        "        print(\"\\t curr_inds == \", curr_inds)\n",
        "        curr_means = [alg_performance_means_tOpt[ind-offset] for ind, offset in zip(index, alg_index_offset) if ind % len(alg_names) == a]\n",
        "        curr_sems = [alg_performance_sems_tOpt[ind-offset] for ind, offset in zip(index, alg_index_offset) if ind % len(alg_names) == a]\n",
        "\n",
        "        print(\"\\t len(curr_sems) == \", len(curr_sems))\n",
        "\n",
        "        ax1.barh([ind - width_of_bars_per_dset/2 for ind in curr_inds], curr_means, xerr=curr_sems, ecolor=sem_color, height=bar_width, color=mean_color, capsize=5, label=alg_name)\n",
        "\n",
        "ax1.set_yticks([i-1 for i in index])\n",
        "ylabels = []\n",
        "for ind, offset in zip(index, alg_index_offset):\n",
        "    if ind % len(alg_names) == 0:\n",
        "        curr_label = None\n",
        "        curr_data_loc = offset\n",
        "        curr_label = dataset_names[curr_data_loc]\n",
        "        curr_label = get_data_name_alias(curr_label)\n",
        "        ylabels.append(curr_label)\n",
        "    else:\n",
        "        ylabels.append(\"\")\n",
        "ax1.set_yticklabels([get_data_name_alias_for_plot_axes(lab) for lab in ylabels], rotation=90)\n",
        "ax1.yaxis.set_ticks_position('none')\n",
        "\n",
        "# Customize the grid: Add both major and minor grid lines\n",
        "ax1.grid(True, axis='x', which='major', linestyle=':', linewidth=0.75, color='grey')  # Major grid lines\n",
        "ax1.minorticks_on()  # Enable minor ticks\n",
        "ax1.grid(True, axis='x', which='minor', linestyle=':', linewidth=0.5, color='lightgray')  # Minor grid lines\n",
        "\n",
        "# Optional: Customize appearance\n",
        "ax1.invert_yaxis()  # Invert y-axis to display the first category at the top\n",
        "\n",
        "# Add legend\n",
        "ax1.legend()\n",
        "\n",
        "# Show plot\n",
        "ax1.set_title('Synthetic System Edge Prediction')\n",
        "ax1.set_xlabel('Avg. Optimal F1-Score '+r'$\\pm$'+' Std. Err. of the Mean')\n",
        "ax1.set_ylabel(\"Synthetic System Name (\"+r'$n_c$'+\"-\"+r'$n_e$'+\"-\"+r'$n_k$'+\")\")\n",
        "ax1.set_xlim(.0, 0.70)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# remainder of code drafted with help from ChatGPT\n",
        "# Create figure and axis\n",
        "fig = plt.figure(figsize=(9.5, 7))\n",
        "gs = gridspec.GridSpec(1, 1)\n",
        "ax1 = plt.subplot(gs[0])\n",
        "\n",
        "# Horizontal bar plot with whiskers\n",
        "for a, (alg_name, mean_color, sem_color) in enumerate(zip(alg_names, mean_colors, sem_colors)):\n",
        "    if alg_name is not None:\n",
        "        curr_inds = None\n",
        "        curr_means = None\n",
        "        curr_sems = None\n",
        "\n",
        "        print(\"alg_name == \", alg_name)\n",
        "        print(\"\\t len(alg_vREDC_performance_means_tOpt) == \", len(alg_vREDC_performance_means_tOpt))\n",
        "\n",
        "        curr_inds = [ind for ind in index if ind % len(alg_names) == a]\n",
        "        print(\"\\t curr_inds == \", curr_inds)\n",
        "        curr_means = [alg_vREDC_performance_means_tOpt[ind-offset] for ind, offset in zip(index, alg_index_offset) if ind % len(alg_names) == a]\n",
        "        curr_sems = [alg_vREDC_performance_sems_tOpt[ind-offset] for ind, offset in zip(index, alg_index_offset) if ind % len(alg_names) == a]\n",
        "\n",
        "        print(\"\\t len(curr_sems) == \", len(curr_sems))\n",
        "\n",
        "        ax1.barh([ind - width_of_bars_per_dset/2 for ind in curr_inds], curr_means, xerr=curr_sems, ecolor=sem_color, height=bar_width, color=mean_color, capsize=5, label=alg_name)\n",
        "\n",
        "ax1.set_yticks([i-1 for i in index])\n",
        "ylabels = []\n",
        "for ind, offset in zip(index, alg_index_offset):\n",
        "    if ind % len(alg_names) == 0:\n",
        "        curr_label = None\n",
        "        curr_data_loc = offset\n",
        "        curr_label = dataset_names[curr_data_loc]\n",
        "        curr_label = get_data_name_alias(curr_label)\n",
        "        ylabels.append(curr_label)\n",
        "    else:\n",
        "        ylabels.append(\"\")\n",
        "ax1.set_yticklabels([get_data_name_alias_for_plot_axes(lab) for lab in ylabels], rotation=90)\n",
        "ax1.yaxis.set_ticks_position('none')\n",
        "\n",
        "# Customize the grid: Add both major and minor grid lines\n",
        "ax1.grid(True, axis='x', which='major', linestyle=':', linewidth=0.75, color='grey')  # Major grid lines\n",
        "ax1.minorticks_on()  # Enable minor ticks\n",
        "ax1.grid(True, axis='x', which='minor', linestyle=':', linewidth=0.5, color='lightgray')  # Minor grid lines\n",
        "\n",
        "# Optional: Customize appearance\n",
        "ax1.invert_yaxis()  # Invert y-axis to display the first category at the top\n",
        "\n",
        "# Add legend\n",
        "ax1.legend()\n",
        "\n",
        "# Show plot\n",
        "ax1.set_title('Pair-wise Improvement by REDCLIFF-S for\\nSynthetic System Edge Prediction')\n",
        "ax1.set_xlabel('Avg. Difference In Optimal F1-Score '+r'$\\pm$'+' Std. Err. of the Mean')\n",
        "ax1.set_ylabel(\"Synthetic System Name (\"+r'$n_c$'+\"-\"+r'$n_e$'+\"-\"+r'$n_k$'+\")\")\n",
        "ax1.set_xlim(-.005, 0.4)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NXl8ut-LdsGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summarizing All Synthetic Systems Experiments 01/21/2025"
      ],
      "metadata": {
        "id": "Sf32Hzekd_el"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# REDCLIFF-S WITH NO SIGMOID ACITVATION Improvements On Gaussian-noise/Innov Data\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "FONT_SMALL_SIZE = 18\n",
        "FONT_MEDIUM_SIZE = 20\n",
        "FONT_BIGGER_SIZE = 22\n",
        "\n",
        "plt.rc('font', size=FONT_SMALL_SIZE)          # controls default text sizes\n",
        "plt.rc('axes', titlesize=FONT_BIGGER_SIZE)     # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=FONT_MEDIUM_SIZE)    # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=FONT_SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=FONT_SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=FONT_SMALL_SIZE)    # legend fontsize\n",
        "plt.rc('figure', titlesize=FONT_BIGGER_SIZE)  # fontsize of the figure title\n",
        "\n",
        "systems = [\n",
        "    \"3-1-2\", \"3-1-3\", \"3-1-4\", \"3-1-5\", \"3-2-2\",\n",
        "    \"6-2-2\", \"6-2-3\", \"6-2-4\", \"6-2-5\", \"6-2-6\", \"6-2-7\", \"6-2-8\", \"6-2-9\", \"6-2-10\",\n",
        "    \"6-4-2\", \"6-4-3\", \"6-4-4\", \"6-4-5\", \"6-4-6\",\n",
        "    \"6-6-2\", \"6-6-3\", \"6-6-4\", \"6-8-2\", \"6-8-3\", \"6-10-2\", \"6-12-2\",\n",
        "    \"12-11-2\", \"12-11-3\", \"12-11-4\", \"12-11-5\", \"12-11-6\", \"12-11-7\", \"12-11-8\", \"12-11-9\", \"12-11-10\",\n",
        "    \"12-12-2\", \"12-12-3\", \"12-12-4\", \"12-12-5\", \"12-12-6\", \"12-12-7\", \"12-12-8\", \"12-12-9\",\n",
        "    \"12-22-2\", \"12-22-3\", \"12-22-4\", \"12-22-5\",\n",
        "    \"12-33-2\", \"12-33-3\", \"12-44-2\", \"12-55-2\",\n",
        "]\n",
        "\n",
        "systems_where_no_significant_improvement_shown = {\n",
        "    \"3-1-2\": [-1], \"3-1-3\": [-1], \"3-1-4\": [-1], \"3-1-5\": [-1], \"3-2-2\": [-1],\n",
        "    \"6-2-5\": [-1], \"6-4-3\": [-1], \"6-6-3\": [-1], \"6-8-2\": [-1], \"6-8-3\": [-1], \"6-12-2\": [-1],\n",
        "    \"12-22-3\": [-1], \"12-22-4\": [-1], \"12-22-5\": [-1],\n",
        "    \"12-33-2\": [-1], \"12-33-3\": [-1], \"12-44-2\": [-1], \"12-55-2\": [-1],\n",
        "}\n",
        "systems_where_signif_improv_shown_withOptThresh = {\n",
        "    \"6-2-2\": [1], \"6-2-3\": [1], \"6-2-6\": [1], \"6-2-7\": [1], \"6-2-8\": [1], \"6-2-9\": [1],\n",
        "    \"6-4-2\": [1], \"6-4-4\": [1], \"6-4-5\": [1], \"6-4-6\": [1], \"6-6-2\": [1], \"6-6-4\": [1], \"6-10-2\": [1],\n",
        "    \"12-11-2\": [1], \"12-11-3\": [1], \"12-11-4\": [1], \"12-11-5\": [1], \"12-11-6\": [1], \"12-11-7\": [1], \"12-11-8\": [1], \"12-11-9\": [1],\n",
        "    \"12-12-2\": [1], \"12-12-3\": [1], \"12-12-4\": [1], \"12-12-5\": [1], \"12-12-6\": [1], \"12-12-7\": [1], \"12-12-8\": [1], \"12-12-9\": [1], \"12-22-2\": [1],\n",
        "}\n",
        "systems_with_no_results = {\n",
        "    \"6-2-4\": [0],\n",
        "    \"6-2-10\": [0],\n",
        "    \"12-11-10\": [0],\n",
        "}\n",
        "\n",
        "system_colors = ['grey','darkorange', 'blue']\n",
        "system_markers = ['X', 'P', 'o']\n",
        "system_labels = ['Not Significant for All Baselines', \"Significant for All Baselines\", \"No Result\"]\n",
        "\n",
        "C = lambda x: (x[1]/(x[0]**2 - x[0]))**(-1)\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (17,8)\n",
        "labels_plotted = []\n",
        "for key in systems:\n",
        "    split_key = key.split(\"-\")\n",
        "    nc = int(split_key[0])\n",
        "    ne = int(split_key[1])\n",
        "    nk = int(split_key[2])\n",
        "    curr_complexity = C((nc, ne, nk))\n",
        "\n",
        "    print(\"nc \", nc, \", ne \", ne, \", nk \", nk, \": C == \", curr_complexity)\n",
        "\n",
        "    for i, dataset_to_score_map in enumerate([systems_where_no_significant_improvement_shown, systems_where_signif_improv_shown_withOptThresh, systems_with_no_results]):\n",
        "        if key in dataset_to_score_map.keys():\n",
        "            if i not in labels_plotted:\n",
        "                plt.scatter([key], [curr_complexity], color=system_colors[i], marker=system_markers[i], s=100, label=system_labels[i], alpha=1)\n",
        "                labels_plotted.append(i)\n",
        "            else:\n",
        "                plt.scatter([key], [curr_complexity], color=system_colors[i], marker=system_markers[i], s=100, alpha=1)\n",
        "\n",
        "plt.plot([7. for _ in range(len(systems))], '-k')\n",
        "plt.plot([13. for _ in range(len(systems))], '-k')\n",
        "plt.xticks(rotation=70)\n",
        "plt.ylim(6.,14.)\n",
        "plt.ylabel(\"System Complexity (\"+r'$\\mathfrak{C}$'+\")\")\n",
        "plt.xlabel(\"Synthetic System Name (\"+r'$n_c$'+\"-\"+r'$n_e$'+\"-\"+r'$n_k$'+\")\")\n",
        "plt.title(\"Smoothed REDCLIFF-S Improvement Over Baselines (Gaussian Noise): Pair-wise Optimal F1-Scores\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (17,8)\n",
        "labels_plotted = []\n",
        "for key in systems:\n",
        "    split_key = key.split(\"-\")\n",
        "    nc = int(split_key[0])\n",
        "    ne = int(split_key[1])\n",
        "    nk = int(split_key[2])\n",
        "    curr_complexity = C((nc, ne, nk))\n",
        "\n",
        "    print(\"nc \", nc, \", ne \", ne, \", nk \", nk, \": C == \", curr_complexity)\n",
        "\n",
        "    for i, dataset_to_score_map in enumerate([systems_where_no_significant_improvement_shown, systems_where_signif_improv_shown_withOptThresh, systems_with_no_results]):\n",
        "        if key in dataset_to_score_map.keys():\n",
        "            if i not in labels_plotted:\n",
        "                print(\"\\t key == \", key)\n",
        "                plt.scatter([key], [curr_complexity], color=system_colors[i], marker=system_markers[i], s=100, label=system_labels[i], alpha=1)\n",
        "                labels_plotted.append(i)\n",
        "            else:\n",
        "                plt.scatter([key], [curr_complexity], color=system_colors[i], marker=system_markers[i], s=100, alpha=1)\n",
        "\n",
        "plt.plot([7. for _ in range(len(systems))], '-k')\n",
        "plt.plot([13. for _ in range(len(systems))], '-k')\n",
        "plt.xticks(rotation=70)\n",
        "plt.ylabel(\"System Complexity (\"+r'$\\mathfrak{C}$'+\")\")\n",
        "plt.xlabel(\"Synthetic System Name (\"+r'$n_c$'+\"-\"+r'$n_e$'+\"-\"+r'$n_k$'+\")\")\n",
        "plt.title(\"REDCLIFF-S Improvement Over Baselines (Gaussian Noise): Pair-wise Optimal F1-Scores\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QwPJgfi1d_RY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing REDCLIFF-S Synthetic Systems Model Parameters for Appendices"
      ],
      "metadata": {
        "id": "1LYTbkR0qx6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# model parameters\n",
        "# tau_in (i.e. gen_lag_and_input_len) -> USE ORIGINAL VALUE IN CACHED ARGS\n",
        "# omega (i.e. FORECAST_COEFF)         -> USE ORIGINAL VALUE IN CACHED ARGS\n",
        "# rho (i.e. FACTOR_COS_SIM_COEFF) -> use FACTOR_COS_SIM_COEFF/sum([1.*i for i in range(1,args_dict[\"num_factors\"])])\n",
        "print(\"rho is \", _/sum([1.*i for i in range(1,_)]))\n",
        "# eta (i.e. ADJ_L1_REG_COEFF) -> ADJ_L1_REG_COEFF*(1./(1.*args_dict[\"num_factors\"]))*(1./np.sqrt(args_dict[\"num_channels\"]**2. - 1.))\n",
        "print(\"eta is \", _*(1./(1.*_))*(1./np.sqrt(_**2. - 1.)))\n",
        "# gamma (i.e. FACTOR_WEIGHT_L1_COEFF) -> USE ORIGINAL VALUE IN CACHED ARGS\n",
        "# lambda (i.e. FACTOR_SCORE_COEFF)    -> USE ORIGINAL VALUE IN CACHED ARGS\n"
      ],
      "metadata": {
        "id": "WrB9MU3Tqwev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Highlighted Synth Data Results (01/18/2025)"
      ],
      "metadata": {
        "id": "SRFpj-ZfcmVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "\n",
        "FONT_SMALL_SIZE = 18\n",
        "FONT_MEDIUM_SIZE = 20\n",
        "FONT_BIGGER_SIZE = 22\n",
        "\n",
        "plt.rc('font', size=FONT_SMALL_SIZE)          # controls default text sizes\n",
        "plt.rc('axes', titlesize=FONT_BIGGER_SIZE)     # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=FONT_MEDIUM_SIZE)    # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=FONT_SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=FONT_SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=FONT_SMALL_SIZE)    # legend fontsize\n",
        "plt.rc('figure', titlesize=FONT_BIGGER_SIZE)  # fontsize of the figure title\n",
        "\n",
        "\n",
        "\n",
        "def get_data_name_alias_for_plot_axes(orig_name):\n",
        "    return orig_name + \"   \"\n",
        "\n",
        "def get_data_name_alias(orig_name):\n",
        "    split_data_name = orig_name.split(\"_\")\n",
        "    abrieve_split_data_name = [int(x[2:]) for x in split_data_name]\n",
        "    data_name_alias = \"-\".join([str(x) for x in abrieve_split_data_name])\n",
        "    return data_name_alias\n",
        "\n",
        "def get_alg_name_alias(orig_name):\n",
        "    if orig_name == 'REDCLIFF_S_CMLP':\n",
        "        return 'REDCLIFF-S (cMLP)'\n",
        "    elif orig_name == 'REDCLIFF_S_CMLP_WithSmoothing':\n",
        "        return 'REDCLIFF-S (cMLP)'\n",
        "    elif orig_name == 'CMLP':\n",
        "        return 'cMLP'\n",
        "    elif orig_name == 'CLSTM':\n",
        "        return 'cLSTM'\n",
        "    elif orig_name == 'DCSFA':\n",
        "        return 'dCSFA-NMF'\n",
        "    elif orig_name == 'DYNOTEARS_Vanilla':\n",
        "        return 'DYNOTEARS'\n",
        "    elif orig_name == 'NAVAR_CMLP':\n",
        "        return 'NAVAR-P'\n",
        "    elif orig_name == 'NAVAR_CLSTM':\n",
        "        return 'NAVAR-R'\n",
        "    return orig_name\n",
        "\n",
        "\n",
        "\n",
        "dataset_names = [\n",
        "    \"nN6_nE2_nF2\",\n",
        "    \"nN6_nE4_nF2\",\n",
        "    \"nN12_nE11_nF2\",\n",
        "    \"nN12_nE11_nF5\",\n",
        "]\n",
        "alg_names = []\n",
        "mean_colors = [\"darkorange\", \"darkred\", \"mediumvioletred\", \"darkslateblue\", \"indigo\"]\n",
        "sem_colors = [\"orangered\", \"tomato\", \"lightcoral\", \"slategrey\", \"mediumpurple\"]\n",
        "\n",
        "alg_performance_means_tOpt = None\n",
        "alg_performance_sems_tOpt = None\n",
        "alg_vREDC_performance_means_tOpt = None\n",
        "alg_vREDC_performance_sems_tOpt = None\n",
        "\n",
        "\n",
        "for d, dataset in enumerate(dataset_names):\n",
        "    curr_alg_performance_means_tOpt = []\n",
        "    curr_alg_performance_sems_tOpt = []\n",
        "    curr_alg_vREDC_performance_means_tOpt = []\n",
        "    curr_alg_vREDC_performance_sems_tOpt = []\n",
        "\n",
        "    # read in bsOH results\n",
        "    curr_synth_results = None\n",
        "    with open(dataset+\"_full_comparrisson_summary.pkl\", \"rb\") as f:\n",
        "        curr_synth_results = pkl.load(f)\n",
        "\n",
        "    assert len(curr_synth_results.keys()) == 1\n",
        "    cv_key = list(curr_synth_results.keys())[0]\n",
        "    for i, alg_key in enumerate(curr_synth_results[cv_key]['key_stats_estGC_normOffDiag_vs_trueGC_normOffDiag'].keys()):\n",
        "        if d == 0:\n",
        "            alg_names.append(get_alg_name_alias(alg_key))\n",
        "        else:\n",
        "            assert get_alg_name_alias(alg_key) == alg_names[i]\n",
        "\n",
        "        curr_alg_eval_stats = curr_synth_results[cv_key]['key_stats_estGC_normOffDiag_vs_trueGC_normOffDiag'][alg_key]\n",
        "        for stat_key in curr_alg_eval_stats.keys():\n",
        "            if 'f1' in stat_key and \"mean_across_factors\" in stat_key:\n",
        "                curr_alg_performance_means_tOpt.append(curr_alg_eval_stats[stat_key])\n",
        "            elif 'f1' in stat_key and \"mean_std_err_across_factors\" in stat_key:\n",
        "                curr_alg_performance_sems_tOpt.append(curr_alg_eval_stats[stat_key])\n",
        "            elif 'f1' in stat_key and \"vals_across_factors\" in stat_key:\n",
        "                curr_diffs = [x-y for x, y in zip(curr_synth_results[cv_key]['key_stats_estGC_normOffDiag_vs_trueGC_normOffDiag']['REDCLIFF_S_CMLP_WithSmoothing'][stat_key], curr_alg_eval_stats[stat_key])]\n",
        "                curr_alg_vREDC_performance_means_tOpt.append(np.mean(curr_diffs))\n",
        "                curr_alg_vREDC_performance_sems_tOpt.append(np.std(curr_diffs)/np.sqrt(1.*len(curr_diffs)))\n",
        "\n",
        "        assert len(curr_alg_performance_means_tOpt) == i+1\n",
        "        assert len(curr_alg_performance_sems_tOpt) == i+1\n",
        "        assert len(curr_alg_vREDC_performance_means_tOpt) == i+1\n",
        "        assert len(curr_alg_vREDC_performance_sems_tOpt) == i+1\n",
        "\n",
        "    if d == 0:\n",
        "        alg_performance_means_tOpt = [None for _ in range(len(dataset_names)) for _ in range(len(alg_names))]\n",
        "        alg_performance_sems_tOpt = [None for _ in range(len(dataset_names)) for _ in range(len(alg_names))]\n",
        "        alg_vREDC_performance_means_tOpt = [None for _ in range(len(dataset_names)) for _ in range(len(alg_names))]\n",
        "        alg_vREDC_performance_sems_tOpt = [None for _ in range(len(dataset_names)) for _ in range(len(alg_names))]\n",
        "\n",
        "    for i in range(len(alg_names)):\n",
        "        if curr_alg_performance_means_tOpt[i] is None or np.isfinite(curr_alg_performance_means_tOpt[i]):\n",
        "            alg_performance_means_tOpt[d*len(alg_names) + i] = curr_alg_performance_means_tOpt[i]\n",
        "        else:\n",
        "            alg_performance_means_tOpt[d*len(alg_names) + i] = np.nan\n",
        "        if curr_alg_performance_sems_tOpt[i] is None or np.isfinite(curr_alg_performance_sems_tOpt[i]):\n",
        "            alg_performance_sems_tOpt[d*len(alg_names) + i] = curr_alg_performance_sems_tOpt[i]\n",
        "        else:\n",
        "            alg_performance_sems_tOpt[d*len(alg_names) + i] = np.nan\n",
        "        if curr_alg_vREDC_performance_means_tOpt[i] is None or np.isfinite(curr_alg_vREDC_performance_means_tOpt[i]):\n",
        "            alg_vREDC_performance_means_tOpt[d*len(alg_names) + i] = curr_alg_vREDC_performance_means_tOpt[i]\n",
        "        else:\n",
        "            alg_vREDC_performance_means_tOpt[d*len(alg_names) + i] = np.nan\n",
        "        if curr_alg_vREDC_performance_sems_tOpt[i] is None or np.isfinite(curr_alg_vREDC_performance_sems_tOpt[i]):\n",
        "            alg_vREDC_performance_sems_tOpt[d*len(alg_names) + i] = curr_alg_vREDC_performance_sems_tOpt[i]\n",
        "        else:\n",
        "            alg_vREDC_performance_sems_tOpt[d*len(alg_names) + i] = np.nan\n",
        "\n",
        "\n",
        "# remainder of code drafted with help from ChatGPT\n",
        "# Create figure and axis\n",
        "fig = plt.figure(figsize=(9.5, 7))\n",
        "gs = gridspec.GridSpec(1, 1)\n",
        "ax1 = plt.subplot(gs[0])\n",
        "\n",
        "\n",
        "bar_width = 0.9\n",
        "index = np.arange((len(alg_names)+1)*len(dataset_names))\n",
        "total_num_bars_per_dset = len(alg_names)# * 2.\n",
        "width_of_bars_per_dset = bar_width#/2\n",
        "\n",
        "alg_names = alg_names + [None]\n",
        "mean_colors = mean_colors + [None]\n",
        "sem_colors = sem_colors + [None]\n",
        "alg_index_offset = []\n",
        "for d in range(len(dataset_names)):\n",
        "    alg_index_offset = alg_index_offset + [d for _ in range(len(alg_names))]\n",
        "\n",
        "# Horizontal bar plot with whiskers\n",
        "for a, (alg_name, mean_color, sem_color) in enumerate(zip(alg_names, mean_colors, sem_colors)):\n",
        "    if alg_name is not None:\n",
        "        curr_inds = None\n",
        "        curr_means = None\n",
        "        curr_sems = None\n",
        "\n",
        "        print(\"alg_name == \", alg_name)\n",
        "        print(\"\\t len(alg_performance_means_tOpt) == \", len(alg_performance_means_tOpt))\n",
        "\n",
        "        curr_inds = [ind for ind in index if ind % len(alg_names) == a]\n",
        "        print(\"\\t curr_inds == \", curr_inds)\n",
        "        curr_means = [alg_performance_means_tOpt[ind-offset] for ind, offset in zip(index, alg_index_offset) if ind % len(alg_names) == a]\n",
        "        curr_sems = [alg_performance_sems_tOpt[ind-offset] for ind, offset in zip(index, alg_index_offset) if ind % len(alg_names) == a]\n",
        "\n",
        "        print(\"\\t len(curr_sems) == \", len(curr_sems))\n",
        "\n",
        "        ax1.barh([ind - width_of_bars_per_dset/2 for ind in curr_inds], curr_means, xerr=curr_sems, ecolor=sem_color, height=bar_width, color=mean_color, capsize=5, label=alg_name)\n",
        "\n",
        "ax1.set_yticks([i-1 for i in index])\n",
        "ylabels = []\n",
        "for ind, offset in zip(index, alg_index_offset):\n",
        "    if ind % len(alg_names) == 0:\n",
        "        curr_label = None\n",
        "        curr_data_loc = offset\n",
        "        curr_label = dataset_names[curr_data_loc]\n",
        "        curr_label = get_data_name_alias(curr_label)\n",
        "        ylabels.append(curr_label)\n",
        "    else:\n",
        "        ylabels.append(\"\")\n",
        "ax1.set_yticklabels([get_data_name_alias_for_plot_axes(lab) for lab in ylabels], rotation=90)\n",
        "ax1.yaxis.set_ticks_position('none')\n",
        "\n",
        "# Customize the grid: Add both major and minor grid lines\n",
        "ax1.grid(True, axis='x', which='major', linestyle=':', linewidth=0.75, color='grey')  # Major grid lines\n",
        "ax1.minorticks_on()  # Enable minor ticks\n",
        "ax1.grid(True, axis='x', which='minor', linestyle=':', linewidth=0.5, color='lightgray')  # Minor grid lines\n",
        "\n",
        "# Optional: Customize appearance\n",
        "ax1.invert_yaxis()  # Invert y-axis to display the first category at the top\n",
        "\n",
        "# Add legend\n",
        "ax1.legend()\n",
        "\n",
        "# Show plot\n",
        "ax1.set_title('Synthetic System Edge Prediction')\n",
        "ax1.set_xlabel('Avg. Optimal F1-Score '+r'$\\pm$'+' Std. Err. of the Mean')\n",
        "ax1.set_ylabel(\"Synthetic System Name (\"+r'$n_c$'+\"-\"+r'$n_e$'+\"-\"+r'$n_k$'+\")\")\n",
        "ax1.set_xlim(.0, 0.70)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# remainder of code drafted with help from ChatGPT\n",
        "# Create figure and axis\n",
        "fig = plt.figure(figsize=(9.5, 7))\n",
        "gs = gridspec.GridSpec(1, 1)\n",
        "ax1 = plt.subplot(gs[0])\n",
        "\n",
        "# Horizontal bar plot with whiskers\n",
        "for a, (alg_name, mean_color, sem_color) in enumerate(zip(alg_names, mean_colors, sem_colors)):\n",
        "    if alg_name is not None:\n",
        "        curr_inds = None\n",
        "        curr_means = None\n",
        "        curr_sems = None\n",
        "\n",
        "        print(\"alg_name == \", alg_name)\n",
        "        print(\"\\t len(alg_vREDC_performance_means_tOpt) == \", len(alg_vREDC_performance_means_tOpt))\n",
        "\n",
        "        curr_inds = [ind for ind in index if ind % len(alg_names) == a]\n",
        "        print(\"\\t curr_inds == \", curr_inds)\n",
        "        curr_means = [alg_vREDC_performance_means_tOpt[ind-offset] for ind, offset in zip(index, alg_index_offset) if ind % len(alg_names) == a]\n",
        "        curr_sems = [alg_vREDC_performance_sems_tOpt[ind-offset] for ind, offset in zip(index, alg_index_offset) if ind % len(alg_names) == a]\n",
        "\n",
        "        print(\"\\t len(curr_sems) == \", len(curr_sems))\n",
        "\n",
        "        ax1.barh([ind - width_of_bars_per_dset/2 for ind in curr_inds], curr_means, xerr=curr_sems, ecolor=sem_color, height=bar_width, color=mean_color, capsize=5, label=alg_name)\n",
        "\n",
        "ax1.set_yticks([i-1 for i in index])\n",
        "ylabels = []\n",
        "for ind, offset in zip(index, alg_index_offset):\n",
        "    if ind % len(alg_names) == 0:\n",
        "        curr_label = None\n",
        "        curr_data_loc = offset\n",
        "        curr_label = dataset_names[curr_data_loc]\n",
        "        curr_label = get_data_name_alias(curr_label)\n",
        "        ylabels.append(curr_label)\n",
        "    else:\n",
        "        ylabels.append(\"\")\n",
        "ax1.set_yticklabels([get_data_name_alias_for_plot_axes(lab) for lab in ylabels], rotation=90)\n",
        "ax1.yaxis.set_ticks_position('none')\n",
        "\n",
        "# Customize the grid: Add both major and minor grid lines\n",
        "ax1.grid(True, axis='x', which='major', linestyle=':', linewidth=0.75, color='grey')  # Major grid lines\n",
        "ax1.minorticks_on()  # Enable minor ticks\n",
        "ax1.grid(True, axis='x', which='minor', linestyle=':', linewidth=0.5, color='lightgray')  # Minor grid lines\n",
        "\n",
        "# Optional: Customize appearance\n",
        "ax1.invert_yaxis()  # Invert y-axis to display the first category at the top\n",
        "\n",
        "# Add legend\n",
        "ax1.legend()\n",
        "\n",
        "# Show plot\n",
        "ax1.set_title('Pair-wise Improvement by REDCLIFF-S for\\nSynthetic System Edge Prediction')\n",
        "ax1.set_xlabel('Avg. Difference In Optimal F1-Score '+r'$\\pm$'+' Std. Err. of the Mean')\n",
        "ax1.set_ylabel(\"Synthetic System Name (\"+r'$n_c$'+\"-\"+r'$n_e$'+\"-\"+r'$n_k$'+\")\")\n",
        "ax1.set_xlim(-.005, 0.4)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "x84uP1vbcmzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summarizing All Synthetic Systems Experiments 01/17/2025"
      ],
      "metadata": {
        "id": "IQ-UEyxacZWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# REDCLIFF-S WITH NO SIGMOID ACITVATION Improvements On Gaussian-noise/Innov Data\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "FONT_SMALL_SIZE = 18\n",
        "FONT_MEDIUM_SIZE = 20\n",
        "FONT_BIGGER_SIZE = 22\n",
        "\n",
        "plt.rc('font', size=FONT_SMALL_SIZE)          # controls default text sizes\n",
        "plt.rc('axes', titlesize=FONT_BIGGER_SIZE)     # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=FONT_MEDIUM_SIZE)    # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=FONT_SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=FONT_SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=FONT_SMALL_SIZE)    # legend fontsize\n",
        "plt.rc('figure', titlesize=FONT_BIGGER_SIZE)  # fontsize of the figure title\n",
        "\n",
        "systems = [\n",
        "    \"3-1-2\", \"3-1-3\", \"3-1-4\", \"3-1-5\", \"3-2-2\",\n",
        "    \"6-2-2\", \"6-2-3\", \"6-2-4\", \"6-2-5\", \"6-2-6\", \"6-2-7\", \"6-2-8\", \"6-2-9\", \"6-2-10\",\n",
        "    \"6-4-2\", \"6-4-3\", \"6-4-4\", \"6-4-5\", \"6-4-6\",\n",
        "    \"6-6-2\", \"6-6-3\", \"6-6-4\", \"6-8-2\", \"6-8-3\", \"6-10-2\", \"6-12-2\",\n",
        "    \"12-11-2\", \"12-11-3\", \"12-11-4\", \"12-11-5\", \"12-11-6\", \"12-11-7\", \"12-11-8\", \"12-11-9\", \"12-11-10\",\n",
        "    \"12-12-2\", \"12-12-3\", \"12-12-4\", \"12-12-5\", \"12-12-6\", \"12-12-7\", \"12-12-8\", \"12-12-9\",\n",
        "    \"12-22-2\", \"12-22-3\", \"12-22-4\", \"12-22-5\",\n",
        "    \"12-33-2\", \"12-33-3\", \"12-44-2\", \"12-55-2\",\n",
        "]\n",
        "\n",
        "systems_where_no_significant_improvement_shown = {\n",
        "    \"3-1-2\": [-1], \"3-1-3\": [-1], \"3-1-4\": [-1], \"3-1-5\": [-1], \"3-2-2\": [-1],\n",
        "    \"6-2-5\": [-1], \"6-4-3\": [-1], \"6-6-3\": [-1], \"6-8-2\": [-1], \"6-8-3\": [-1], \"6-12-2\": [-1],\n",
        "    \"12-12-7\": [-1], \"12-22-3\": [-1], \"12-22-4\": [-1], \"12-22-5\": [-1],\n",
        "    \"12-33-2\": [-1], \"12-33-3\": [-1], \"12-44-2\": [-1], \"12-55-2\": [-1],\n",
        "}\n",
        "systems_where_signif_improv_shown_withOptThresh = {\n",
        "    \"6-2-2\": [1], \"6-2-3\": [1], \"6-2-6\": [1], \"6-2-7\": [1], \"6-2-8\": [1], \"6-2-9\": [1],\n",
        "    \"6-4-2\": [1], \"6-4-4\": [1], \"6-4-5\": [1], \"6-4-6\": [1], \"6-6-2\": [1], \"6-6-4\": [1], \"6-10-2\": [1],\n",
        "    \"12-11-2\": [1], \"12-11-3\": [1], \"12-11-4\": [1], \"12-11-5\": [1], \"12-11-6\": [1], \"12-11-7\": [1], \"12-11-8\": [1], \"12-11-9\": [1],\n",
        "    \"12-12-2\": [1], \"12-12-3\": [1], \"12-12-4\": [1], \"12-12-5\": [1], \"12-12-6\": [1], \"12-12-8\": [1], \"12-12-9\": [1], \"12-22-2\": [1],\n",
        "}\n",
        "systems_with_no_results = {\n",
        "    \"6-2-4\": [0],\n",
        "    \"6-2-10\": [0],\n",
        "    \"12-11-10\": [0],\n",
        "}\n",
        "\n",
        "system_colors = ['grey','darkorange', 'blue']\n",
        "system_markers = ['X', 'P', 'o']\n",
        "system_labels = ['Not Significant for All Baselines', \"Significant for All Baselines\", \"No Result\"]\n",
        "\n",
        "C = lambda x: (x[1]/(x[0]**2 - x[0]))**(-1)\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (17,8)\n",
        "labels_plotted = []\n",
        "for key in systems:\n",
        "    split_key = key.split(\"-\")\n",
        "    nc = int(split_key[0])\n",
        "    ne = int(split_key[1])\n",
        "    nk = int(split_key[2])\n",
        "    curr_complexity = C((nc, ne, nk))\n",
        "\n",
        "    print(\"nc \", nc, \", ne \", ne, \", nk \", nk, \": C == \", curr_complexity)\n",
        "\n",
        "    for i, dataset_to_score_map in enumerate([systems_where_no_significant_improvement_shown, systems_where_signif_improv_shown_withOptThresh, systems_with_no_results]):\n",
        "        if key in dataset_to_score_map.keys():\n",
        "            if i not in labels_plotted:\n",
        "                plt.scatter([key], [curr_complexity], color=system_colors[i], marker=system_markers[i], s=100, label=system_labels[i], alpha=1)\n",
        "                labels_plotted.append(i)\n",
        "            else:\n",
        "                plt.scatter([key], [curr_complexity], color=system_colors[i], marker=system_markers[i], s=100, alpha=1)\n",
        "\n",
        "plt.plot([7. for _ in range(len(systems))], '-k')\n",
        "plt.plot([13. for _ in range(len(systems))], '-k')\n",
        "plt.xticks(rotation=70)\n",
        "plt.ylim(6.,14.)\n",
        "plt.ylabel(\"System Complexity (\"+r'$\\mathfrak{C}$'+\")\")\n",
        "plt.xlabel(\"Synthetic System Name (\"+r'$n_c$'+\"-\"+r'$n_e$'+\"-\"+r'$n_k$'+\")\")\n",
        "plt.title(\"Smoothed REDCLIFF-S Improvement Over Baselines (Gaussian Noise): Pair-wise Optimal F1-Scores\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (17,8)\n",
        "labels_plotted = []\n",
        "for key in systems:\n",
        "    split_key = key.split(\"-\")\n",
        "    nc = int(split_key[0])\n",
        "    ne = int(split_key[1])\n",
        "    nk = int(split_key[2])\n",
        "    curr_complexity = C((nc, ne, nk))\n",
        "\n",
        "    print(\"nc \", nc, \", ne \", ne, \", nk \", nk, \": C == \", curr_complexity)\n",
        "\n",
        "    for i, dataset_to_score_map in enumerate([systems_where_no_significant_improvement_shown, systems_where_signif_improv_shown_withOptThresh, systems_with_no_results]):\n",
        "        if key in dataset_to_score_map.keys():\n",
        "            if i not in labels_plotted:\n",
        "                print(\"\\t key == \", key)\n",
        "                plt.scatter([key], [curr_complexity], color=system_colors[i], marker=system_markers[i], s=100, label=system_labels[i], alpha=1)\n",
        "                labels_plotted.append(i)\n",
        "            else:\n",
        "                plt.scatter([key], [curr_complexity], color=system_colors[i], marker=system_markers[i], s=100, alpha=1)\n",
        "\n",
        "plt.plot([7. for _ in range(len(systems))], '-k')\n",
        "plt.plot([13. for _ in range(len(systems))], '-k')\n",
        "plt.xticks(rotation=70)\n",
        "plt.ylabel(\"System Complexity (\"+r'$\\mathfrak{C}$'+\")\")\n",
        "plt.xlabel(\"Synthetic System Name (\"+r'$n_c$'+\"-\"+r'$n_e$'+\"-\"+r'$n_k$'+\")\")\n",
        "plt.title(\"REDCLIFF-S Improvement Over Baselines (Gaussian Noise): Pair-wise Optimal F1-Scores\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0DvffuQBMZeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# D4IC Experiment Analyses\n"
      ],
      "metadata": {
        "id": "2lKNFVNfMUX1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ablation Summaries"
      ],
      "metadata": {
        "id": "jvJDlsiFiUHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# CosSim (rho) ablation: key_stats_estGC_normOffDiag_vs_trueGC_normOffDiag, f1_vals_across_factors\n",
        "print(\"CosSim (rho) ablation:\")\n",
        "curr_results_by_alg = {\n",
        "    'REDCLIFF_S_CMLP': [0.4, 0.28846153846153844, 0.27027027027027023, 0.30303030303030304, 0.31884057971014496, 0.30508474576271183, 0.3, 0.2553191489361702, 0.29411764705882354, 0.32, 0.3555555555555555, 0.297029702970297, 0.2666666666666667, 0.2777777777777778, 0.3137254901960785, 0.3414634146341463, 0.30927835051546393, 0.26829268292682923, 0.3050847457627119, 0.3018867924528302, 0.3157894736842105, 0.30303030303030304, 0.2531645569620253, 0.30985915492957744, 0.3287671232876712],\n",
        "    'CMLP': [0.36363636363636365, 0.30985915492957744, 0.2962962962962963, 0.37735849056603776, 0.35, 0.3846153846153846, 0.2857142857142857, 0.23529411764705882, 0.27777777777777773, 0.37037037037037035, 0.4444444444444445, 0.33898305084745756, 0.24999999999999997, 0.4000000000000001, 0.3333333333333333, 0.4, 0.29032258064516125, 0.24489795918367346, 0.4375, 0.3137254901960785, 0.31578947368421056, 0.3488372093023256, 0.2758620689655173, 0.2857142857142857, 0.3018867924528302], 'CLSTM': [0.3448275862068966, 0.29166666666666663, 0.2553191489361702, 0.3225806451612903, 0.32941176470588235, 0.3384615384615385, 0.32558139534883723, 0.2553191489361702, 0.2758620689655173, 0.42857142857142855, 0.3, 0.37499999999999994, 0.26373626373626374, 0.3111111111111111, 0.3076923076923077, 0.34615384615384615, 0.3157894736842105, 0.3333333333333333, 0.33333333333333337, 0.37209302325581395, 0.34146341463414637, 0.339622641509434, 0.26666666666666666, 0.30769230769230776, 0.3529411764705882], 'DGCNN': [0.3636363636363636, 0.2857142857142857, 0.2608695652173913, 0.34285714285714286, 0.325, 0.3636363636363636, 0.2857142857142857, 0.2608695652173913, 0.34285714285714286, 0.325, 0.3636363636363636, 0.2857142857142857, 0.2608695652173913, 0.34285714285714286, 0.325, 0.3636363636363636, 0.2857142857142857, 0.2608695652173913, 0.34285714285714286, 0.325, 0.3636363636363636, 0.2857142857142857, 0.2608695652173913, 0.34285714285714286, 0.325], 'DCSFA': [0.3037974683544304, 0.32608695652173914, 0.2857142857142857, 0.28, 0.4166666666666667, 0.2912621359223301, 0.2912621359223301, 0.30303030303030304, 0.2857142857142857, 0.3018867924528302, 0.3157894736842105, 0.325, 0.2784810126582279, 0.32, 0.3018867924528302, 0.3137254901960784, 0.2857142857142857, 0.32432432432432434, 0.3181818181818182, 0.3902439024390244, 0.3466666666666666, 0.29411764705882354, 0.3703703703703704, 0.2857142857142857, 0.34285714285714286], 'DYNOTEARS_Vanilla': [0.27522935779816515, 0.36363636363636365, 0.2439024390243903, 0.24074074074074076, 0.3684210526315789, 0.3, 0.3703703703703704, 0.3448275862068966, 0.24074074074074076, 0.2926829268292683, 0.2803738317757009, 0.42857142857142855, 0.2962962962962963, 0.2476190476190476, 0.45714285714285713, 0.28846153846153844, 0.38709677419354843, 0.3333333333333333, 0.24528301886792453, 0.36363636363636365, 0.2857142857142857, 0.38095238095238093, 0.22727272727272727, 0.24299065420560748, 0.326530612244898], 'NAVAR_CLSTM': [0.3076923076923077, 0.3023255813953489, 0.24000000000000002, 0.3055555555555555, 0.3106796116504854, 0.3, 0.3146067415730337, 0.25641025641025644, 0.3157894736842105, 0.3106796116504854, 0.39344262295081966, 0.29268292682926833, 0.25, 0.3636363636363637, 0.30476190476190473, 0.3055555555555555, 0.303030303030303, 0.26829268292682923, 0.32, 0.3137254901960785, 0.3, 0.28846153846153844, 0.2439024390243903, 0.29411764705882354, 0.30927835051546393], 'NAVAR_CMLP': [0.3384615384615385, 0.28846153846153844, 0.25925925925925924, 0.3428571428571428, 0.34090909090909094, 0.3661971830985915, 0.30303030303030304, 0.26373626373626374, 0.3076923076923077, 0.4307692307692308, 0.36363636363636365, 0.29411764705882354, 0.28571428571428575, 0.3333333333333333, 0.375, 0.3728813559322034, 0.325, 0.25, 0.2978723404255319, 0.4057971014492754, 0.3478260869565218, 0.3, 0.28571428571428575, 0.3225806451612903, 0.39999999999999997]}\n",
        "\n",
        "print(np.mean(curr_results_by_alg['REDCLIFF_S_CMLP']))\n",
        "print(np.std(curr_results_by_alg['REDCLIFF_S_CMLP'])/np.sqrt(len(curr_results_by_alg['REDCLIFF_S_CMLP'])))\n",
        "\n",
        "\n",
        "# 1-Factor Ablation: key_stats_estGC_normOffDiag_vs_trueGC_normOffDiag, f1_vals_across_factors\n",
        "print(\"\\n 1-Factor Ablation:\")\n",
        "curr_results_by_alg = {\n",
        "    'REDCLIFF_S_CMLP': [0.3333333333333333, 0.2912621359223301, 0.25, 0.26000000000000006, 0.4166666666666667, 0.32352941176470584, 0.3611111111111111, 0.2758620689655173, 0.3870967741935484, 0.3333333333333333, 0.3188405797101449, 0.325, 0.23529411764705882, 0.2702702702702703, 0.4210526315789473, 0.30612244897959184, 0.2921348314606742, 0.2424242424242424, 0.2758620689655173, 0.392156862745098, 0.325, 0.3294117647058824, 0.24175824175824176, 0.2894736842105263, 0.4],\n",
        "    'CMLP': [0.36363636363636365, 0.30985915492957744, 0.2962962962962963, 0.37735849056603776, 0.35, 0.3846153846153846, 0.2857142857142857, 0.23529411764705882, 0.27777777777777773, 0.37037037037037035, 0.4444444444444445, 0.33898305084745756, 0.24999999999999997, 0.4000000000000001, 0.3333333333333333, 0.4, 0.29032258064516125, 0.24489795918367346, 0.4375, 0.3137254901960785, 0.31578947368421056, 0.3488372093023256, 0.2758620689655173, 0.2857142857142857, 0.3018867924528302], 'CLSTM': [0.3448275862068966, 0.29166666666666663, 0.2553191489361702, 0.3225806451612903, 0.32941176470588235, 0.3384615384615385, 0.32558139534883723, 0.2553191489361702, 0.2758620689655173, 0.42857142857142855, 0.3, 0.37499999999999994, 0.26373626373626374, 0.3111111111111111, 0.3076923076923077, 0.34615384615384615, 0.3157894736842105, 0.3333333333333333, 0.33333333333333337, 0.37209302325581395, 0.34146341463414637, 0.339622641509434, 0.26666666666666666, 0.30769230769230776, 0.3529411764705882], 'DGCNN': [0.3636363636363636, 0.2857142857142857, 0.2608695652173913, 0.34285714285714286, 0.325, 0.3636363636363636, 0.2857142857142857, 0.2608695652173913, 0.34285714285714286, 0.325, 0.3636363636363636, 0.2857142857142857, 0.2608695652173913, 0.34285714285714286, 0.325, 0.3636363636363636, 0.2857142857142857, 0.2608695652173913, 0.34285714285714286, 0.325, 0.3636363636363636, 0.2857142857142857, 0.2608695652173913, 0.34285714285714286, 0.325], 'DCSFA': [0.3037974683544304, 0.32608695652173914, 0.2857142857142857, 0.28, 0.4166666666666667, 0.2912621359223301, 0.2912621359223301, 0.30303030303030304, 0.2857142857142857, 0.3018867924528302, 0.3157894736842105, 0.325, 0.2784810126582279, 0.32, 0.3018867924528302, 0.3137254901960784, 0.2857142857142857, 0.32432432432432434, 0.3181818181818182, 0.3902439024390244, 0.3466666666666666, 0.29411764705882354, 0.3703703703703704, 0.2857142857142857, 0.34285714285714286], 'DYNOTEARS_Vanilla': [0.27522935779816515, 0.36363636363636365, 0.2439024390243903, 0.24074074074074076, 0.3684210526315789, 0.3, 0.3703703703703704, 0.3448275862068966, 0.24074074074074076, 0.2926829268292683, 0.2803738317757009, 0.42857142857142855, 0.2962962962962963, 0.2476190476190476, 0.45714285714285713, 0.28846153846153844, 0.38709677419354843, 0.3333333333333333, 0.24528301886792453, 0.36363636363636365, 0.2857142857142857, 0.38095238095238093, 0.22727272727272727, 0.24299065420560748, 0.326530612244898], 'NAVAR_CLSTM': [0.3076923076923077, 0.3023255813953489, 0.24000000000000002, 0.3055555555555555, 0.3106796116504854, 0.3, 0.3146067415730337, 0.25641025641025644, 0.3157894736842105, 0.3106796116504854, 0.39344262295081966, 0.29268292682926833, 0.25, 0.3636363636363637, 0.30476190476190473, 0.3055555555555555, 0.303030303030303, 0.26829268292682923, 0.32, 0.3137254901960785, 0.3, 0.28846153846153844, 0.2439024390243903, 0.29411764705882354, 0.30927835051546393], 'NAVAR_CMLP': [0.3384615384615385, 0.28846153846153844, 0.25925925925925924, 0.3428571428571428, 0.34090909090909094, 0.3661971830985915, 0.30303030303030304, 0.26373626373626374, 0.3076923076923077, 0.4307692307692308, 0.36363636363636365, 0.29411764705882354, 0.28571428571428575, 0.3333333333333333, 0.375, 0.3728813559322034, 0.325, 0.25, 0.2978723404255319, 0.4057971014492754, 0.3478260869565218, 0.3, 0.28571428571428575, 0.3225806451612903, 0.39999999999999997]}\n",
        "\n",
        "print(np.mean(curr_results_by_alg['REDCLIFF_S_CMLP']))\n",
        "print(np.std(curr_results_by_alg['REDCLIFF_S_CMLP'])/np.sqrt(len(curr_results_by_alg['REDCLIFF_S_CMLP'])))\n",
        "\n",
        "# Fixed-Factor (alpha) ablation: key_stats_estGC_normOffDiag_vs_trueGC_normOffDiag, f1_vals_across_factors\n",
        "print(\"\\n Fixed-Factor (alpha) ablation:\")\n",
        "curr_results_by_alg = {\n",
        "    'REDCLIFF_S_CMLP': [0.31578947368421056, 0.4067796610169491, 0.2857142857142857, 0.3333333333333333, 0.34210526315789475, 0.34285714285714286, 0.4, 0.25974025974025977, 0.3589743589743589, 0.35714285714285715, 0.30769230769230765, 0.4067796610169491, 0.29411764705882354, 0.35000000000000003, 0.31884057971014496, 0.3103448275862069, 0.4, 0.2608695652173913, 0.3888888888888889, 0.3404255319148936, 0.3272727272727273, 0.3793103448275862, 0.27586206896551724, 0.31250000000000006, 0.3846153846153846], 'CMLP': [0.36363636363636365, 0.30985915492957744, 0.2962962962962963, 0.37735849056603776, 0.35, 0.3846153846153846, 0.2857142857142857, 0.23529411764705882, 0.27777777777777773, 0.37037037037037035, 0.4444444444444445, 0.33898305084745756, 0.24999999999999997, 0.4000000000000001, 0.3333333333333333, 0.4, 0.29032258064516125, 0.24489795918367346, 0.4375, 0.3137254901960785, 0.31578947368421056, 0.3488372093023256, 0.2758620689655173, 0.2857142857142857, 0.3018867924528302], 'CLSTM': [0.3448275862068966, 0.29166666666666663, 0.2553191489361702, 0.3225806451612903, 0.32941176470588235, 0.3384615384615385, 0.32558139534883723, 0.2553191489361702, 0.2758620689655173, 0.42857142857142855, 0.3, 0.37499999999999994, 0.26373626373626374, 0.3111111111111111, 0.3076923076923077, 0.34615384615384615, 0.3157894736842105, 0.3333333333333333, 0.33333333333333337, 0.37209302325581395, 0.34146341463414637, 0.339622641509434, 0.26666666666666666, 0.30769230769230776, 0.3529411764705882], 'DGCNN': [0.3636363636363636, 0.2857142857142857, 0.2608695652173913, 0.34285714285714286, 0.325, 0.3636363636363636, 0.2857142857142857, 0.2608695652173913, 0.34285714285714286, 0.325, 0.3636363636363636, 0.2857142857142857, 0.2608695652173913, 0.34285714285714286, 0.325, 0.3636363636363636, 0.2857142857142857, 0.2608695652173913, 0.34285714285714286, 0.325, 0.3636363636363636, 0.2857142857142857, 0.2608695652173913, 0.34285714285714286, 0.325], 'DCSFA': [0.3037974683544304, 0.32608695652173914, 0.2857142857142857, 0.28, 0.4166666666666667, 0.2912621359223301, 0.2912621359223301, 0.30303030303030304, 0.2857142857142857, 0.3018867924528302, 0.3157894736842105, 0.325, 0.2784810126582279, 0.32, 0.3018867924528302, 0.3137254901960784, 0.2857142857142857, 0.32432432432432434, 0.3181818181818182, 0.3902439024390244, 0.3466666666666666, 0.29411764705882354, 0.3703703703703704, 0.2857142857142857, 0.34285714285714286], 'DYNOTEARS_Vanilla': [0.27522935779816515, 0.36363636363636365, 0.2439024390243903, 0.24074074074074076, 0.3684210526315789, 0.3, 0.3703703703703704, 0.3448275862068966, 0.24074074074074076, 0.2926829268292683, 0.2803738317757009, 0.42857142857142855, 0.2962962962962963, 0.2476190476190476, 0.45714285714285713, 0.28846153846153844, 0.38709677419354843, 0.3333333333333333, 0.24528301886792453, 0.36363636363636365, 0.2857142857142857, 0.38095238095238093, 0.22727272727272727, 0.24299065420560748, 0.326530612244898], 'NAVAR_CLSTM': [0.3076923076923077, 0.3023255813953489, 0.24000000000000002, 0.3055555555555555, 0.3106796116504854, 0.3, 0.3146067415730337, 0.25641025641025644, 0.3157894736842105, 0.3106796116504854, 0.39344262295081966, 0.29268292682926833, 0.25, 0.3636363636363637, 0.30476190476190473, 0.3055555555555555, 0.303030303030303, 0.26829268292682923, 0.32, 0.3137254901960785, 0.3, 0.28846153846153844, 0.2439024390243903, 0.29411764705882354, 0.30927835051546393], 'NAVAR_CMLP': [0.3384615384615385, 0.28846153846153844, 0.25925925925925924, 0.3428571428571428, 0.34090909090909094, 0.3661971830985915, 0.30303030303030304, 0.26373626373626374, 0.3076923076923077, 0.4307692307692308, 0.36363636363636365, 0.29411764705882354, 0.28571428571428575, 0.3333333333333333, 0.375, 0.3728813559322034, 0.325, 0.25, 0.2978723404255319, 0.4057971014492754, 0.3478260869565218, 0.3, 0.28571428571428575, 0.3225806451612903, 0.39999999999999997]}\n",
        "\n",
        "print(np.mean(curr_results_by_alg['REDCLIFF_S_CMLP']))\n",
        "print(np.std(curr_results_by_alg['REDCLIFF_S_CMLP'])/np.sqrt(len(curr_results_by_alg['REDCLIFF_S_CMLP'])))\n",
        "\n",
        "# Unsupervised (lambda) ablation: key_stats_estGC_normOffDiag_vs_trueGC_normOffDiag, f1_vals_across_factors\n",
        "print(\"\\n Unsupervised (lambda) ablation:\")\n",
        "curr_results_by_alg = {\n",
        "    'REDCLIFF_S_CMLP': [0.32608695652173914, 0.3829787234042553, 0.2962962962962963, 0.31999999999999995, 0.3376623376623376, 0.32183908045977017, 0.3661971830985915, 0.3225806451612903, 0.326530612244898, 0.33333333333333337, 0.32967032967032966, 0.37037037037037035, 0.30303030303030304, 0.30434782608695654, 0.37681159420289856, 0.3181818181818181, 0.4, 0.275, 0.31999999999999995, 0.3376623376623376, 0.31111111111111106, 0.3793103448275862, 0.30303030303030304, 0.3333333333333333, 0.31683168316831684], 'CMLP': [0.36363636363636365, 0.30985915492957744, 0.2962962962962963, 0.37735849056603776, 0.35, 0.3846153846153846, 0.2857142857142857, 0.23529411764705882, 0.27777777777777773, 0.37037037037037035, 0.4444444444444445, 0.33898305084745756, 0.24999999999999997, 0.4000000000000001, 0.3333333333333333, 0.4, 0.29032258064516125, 0.24489795918367346, 0.4375, 0.3137254901960785, 0.31578947368421056, 0.3488372093023256, 0.2758620689655173, 0.2857142857142857, 0.3018867924528302], 'CLSTM': [0.3448275862068966, 0.29166666666666663, 0.2553191489361702, 0.3225806451612903, 0.32941176470588235, 0.3384615384615385, 0.32558139534883723, 0.2553191489361702, 0.2758620689655173, 0.42857142857142855, 0.3, 0.37499999999999994, 0.26373626373626374, 0.3111111111111111, 0.3076923076923077, 0.34615384615384615, 0.3157894736842105, 0.3333333333333333, 0.33333333333333337, 0.37209302325581395, 0.34146341463414637, 0.339622641509434, 0.26666666666666666, 0.30769230769230776, 0.3529411764705882], 'DGCNN': [0.3636363636363636, 0.2857142857142857, 0.2608695652173913, 0.34285714285714286, 0.325, 0.3636363636363636, 0.2857142857142857, 0.2608695652173913, 0.34285714285714286, 0.325, 0.3636363636363636, 0.2857142857142857, 0.2608695652173913, 0.34285714285714286, 0.325, 0.3636363636363636, 0.2857142857142857, 0.2608695652173913, 0.34285714285714286, 0.325, 0.3636363636363636, 0.2857142857142857, 0.2608695652173913, 0.34285714285714286, 0.325], 'DCSFA': [0.3037974683544304, 0.32608695652173914, 0.2857142857142857, 0.28, 0.4166666666666667, 0.2912621359223301, 0.2912621359223301, 0.30303030303030304, 0.2857142857142857, 0.3018867924528302, 0.3157894736842105, 0.325, 0.2784810126582279, 0.32, 0.3018867924528302, 0.3137254901960784, 0.2857142857142857, 0.32432432432432434, 0.3181818181818182, 0.3902439024390244, 0.3466666666666666, 0.29411764705882354, 0.3703703703703704, 0.2857142857142857, 0.34285714285714286], 'DYNOTEARS_Vanilla': [0.27522935779816515, 0.36363636363636365, 0.2439024390243903, 0.24074074074074076, 0.3684210526315789, 0.3, 0.3703703703703704, 0.3448275862068966, 0.24074074074074076, 0.2926829268292683, 0.2803738317757009, 0.42857142857142855, 0.2962962962962963, 0.2476190476190476, 0.45714285714285713, 0.28846153846153844, 0.38709677419354843, 0.3333333333333333, 0.24528301886792453, 0.36363636363636365, 0.2857142857142857, 0.38095238095238093, 0.22727272727272727, 0.24299065420560748, 0.326530612244898], 'NAVAR_CLSTM': [0.3076923076923077, 0.3023255813953489, 0.24000000000000002, 0.3055555555555555, 0.3106796116504854, 0.3, 0.3146067415730337, 0.25641025641025644, 0.3157894736842105, 0.3106796116504854, 0.39344262295081966, 0.29268292682926833, 0.25, 0.3636363636363637, 0.30476190476190473, 0.3055555555555555, 0.303030303030303, 0.26829268292682923, 0.32, 0.3137254901960785, 0.3, 0.28846153846153844, 0.2439024390243903, 0.29411764705882354, 0.30927835051546393], 'NAVAR_CMLP': [0.3384615384615385, 0.28846153846153844, 0.25925925925925924, 0.3428571428571428, 0.34090909090909094, 0.3661971830985915, 0.30303030303030304, 0.26373626373626374, 0.3076923076923077, 0.4307692307692308, 0.36363636363636365, 0.29411764705882354, 0.28571428571428575, 0.3333333333333333, 0.375, 0.3728813559322034, 0.325, 0.25, 0.2978723404255319, 0.4057971014492754, 0.3478260869565218, 0.3, 0.28571428571428575, 0.3225806451612903, 0.39999999999999997]}\n",
        "\n",
        "print(np.mean(curr_results_by_alg['REDCLIFF_S_CMLP']))\n",
        "print(np.std(curr_results_by_alg['REDCLIFF_S_CMLP'])/np.sqrt(len(curr_results_by_alg['REDCLIFF_S_CMLP'])))"
      ],
      "metadata": {
        "id": "K9F6seTaiT0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary Analyses V03312025"
      ],
      "metadata": {
        "id": "ITbFmyacNWPv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NON-TRANSPOSED PREDICTION RESULTS"
      ],
      "metadata": {
        "id": "gelefnrgNWC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle as pkl\n",
        "\n",
        "og_stats_fold0 = pkl.load(open(\"stats_by_alg_key_dict_fold0.pkl\", \"rb\"))\n",
        "og_stats_fold1 = pkl.load(open(\"stats_by_alg_key_dict_fold1.pkl\", \"rb\"))\n",
        "og_stats_fold2 = pkl.load(open(\"stats_by_alg_key_dict_fold2.pkl\", \"rb\"))\n",
        "og_stats_fold3 = pkl.load(open(\"stats_by_alg_key_dict_fold3.pkl\", \"rb\"))\n",
        "#og_stats_fold4 = pkl.load(open(\"stats_by_alg_key_dict_fold4.pkl\", \"rb\")) # MISSING DUE TO KILLED JOB 03/31/2025\n",
        "\n",
        "print(\"og_stats_fold0.keys() == \", og_stats_fold0.keys())\n",
        "performance_across_folds_by_alg = {key[len(\"D4ICMSNRFold0_model_name_\"):]:{\"fold_\"+str(i): dict() for i in range(4)} for key in og_stats_fold0.keys() if key.startswith(\"D4ICMSNRFold0_model_name_\") and \"Fold4\" not in key}\n",
        "print(\"performance_across_folds_by_alg.keys() == \", performance_across_folds_by_alg.keys())\n",
        "\n",
        "for f_ind, og_stats in enumerate([og_stats_fold0, og_stats_fold1, og_stats_fold2, og_stats_fold3, og_stats_fold4]):\n",
        "    print(\"f_ind == \", f_ind)\n",
        "    for og_alg_key in og_stats.keys():\n",
        "        if \"Fold4\" not in og_alg_key:\n",
        "            for alg_key in performance_across_folds_by_alg.keys():\n",
        "                if alg_key in og_alg_key:\n",
        "                    for factor_key in sorted(list(og_stats[og_alg_key].keys())):\n",
        "                        for stat_key in og_stats[og_alg_key][factor_key].keys():\n",
        "                            if stat_key in performance_across_folds_by_alg[alg_key][f\"fold_{f_ind}\"].keys():\n",
        "                                if \"ancestor_aid\" in stat_key or \"oset_aid\" in stat_key or \"parent_aid\" in stat_key or \"_shd\" in stat_key:\n",
        "                                    try:\n",
        "                                        performance_across_folds_by_alg[alg_key][f\"fold_{f_ind}\"][stat_key][\"normalized\"].append(og_stats[og_alg_key][factor_key][stat_key][0])\n",
        "                                        performance_across_folds_by_alg[alg_key][f\"fold_{f_ind}\"][stat_key][\"raw_count\"].append(og_stats[og_alg_key][factor_key][stat_key][1])\n",
        "                                    except:\n",
        "                                        performance_across_folds_by_alg[alg_key][f\"fold_{f_ind}\"][stat_key][\"normalized\"].append(og_stats[og_alg_key][factor_key][stat_key])\n",
        "                                        performance_across_folds_by_alg[alg_key][f\"fold_{f_ind}\"][stat_key][\"raw_count\"].append(og_stats[og_alg_key][factor_key][stat_key])\n",
        "                                else:\n",
        "                                    performance_across_folds_by_alg[alg_key][f\"fold_{f_ind}\"][stat_key].append(og_stats[og_alg_key][factor_key][stat_key])\n",
        "                            else:\n",
        "                                if \"ancestor_aid\" in stat_key or \"oset_aid\" in stat_key or \"parent_aid\" in stat_key or \"_shd\" in stat_key:\n",
        "                                    try:\n",
        "                                        performance_across_folds_by_alg[alg_key][f\"fold_{f_ind}\"][stat_key] = {\n",
        "                                            \"normalized\": [og_stats[og_alg_key][factor_key][stat_key][0]],\n",
        "                                            \"raw_count\": [og_stats[og_alg_key][factor_key][stat_key][1]]\n",
        "                                        }\n",
        "                                    except:\n",
        "                                        performance_across_folds_by_alg[alg_key][f\"fold_{f_ind}\"][stat_key] = {\n",
        "                                            \"normalized\": [og_stats[og_alg_key][factor_key][stat_key]],\n",
        "                                            \"raw_count\": [og_stats[og_alg_key][factor_key][stat_key]]\n",
        "                                        }\n",
        "                                else:\n",
        "                                    performance_across_folds_by_alg[alg_key][f\"fold_{f_ind}\"][stat_key] = [og_stats[og_alg_key][factor_key][stat_key]]\n",
        "\n",
        "print(\"performance_across_folds_by_alg == \", performance_across_folds_by_alg)\n",
        "summary_stats_by_alg = {alg_key: dict() for alg_key in performance_across_folds_by_alg.keys()}\n",
        "for alg_key in performance_across_folds_by_alg.keys():\n",
        "    for fold_key in performance_across_folds_by_alg[alg_key].keys():\n",
        "        for stat_key in performance_across_folds_by_alg[alg_key][fold_key].keys():\n",
        "            if stat_key in summary_stats_by_alg[alg_key].keys():\n",
        "                if \"ancestor_aid\" in stat_key or \"oset_aid\" in stat_key or \"parent_aid\" in stat_key or \"_shd\" in stat_key:\n",
        "                    for substat_key in performance_across_folds_by_alg[alg_key][fold_key][stat_key].keys():\n",
        "                        summary_stats_by_alg[alg_key][stat_key][substat_key][\"fold_means\"].append(np.mean(performance_across_folds_by_alg[alg_key][fold_key][stat_key][substat_key]))\n",
        "                        summary_stats_by_alg[alg_key][stat_key][substat_key][\"stat_vals_across_folds_and_factors\"] = summary_stats_by_alg[alg_key][stat_key][substat_key][\"stat_vals_across_folds_and_factors\"] + performance_across_folds_by_alg[alg_key][fold_key][stat_key][substat_key]\n",
        "                else:\n",
        "                    summary_stats_by_alg[alg_key][stat_key][\"fold_means\"].append(np.mean(performance_across_folds_by_alg[alg_key][fold_key][stat_key]))\n",
        "                    summary_stats_by_alg[alg_key][stat_key][\"stat_vals_across_folds_and_factors\"] = summary_stats_by_alg[alg_key][stat_key][\"stat_vals_across_folds_and_factors\"] + performance_across_folds_by_alg[alg_key][fold_key][stat_key]\n",
        "            else:\n",
        "                if \"ancestor_aid\" in stat_key or \"oset_aid\" in stat_key or \"parent_aid\" in stat_key or \"_shd\" in stat_key:\n",
        "                    summary_stats_by_alg[alg_key][stat_key] = dict()\n",
        "                    for substat_key in performance_across_folds_by_alg[alg_key][fold_key][stat_key].keys():\n",
        "                        summary_stats_by_alg[alg_key][stat_key][substat_key] = {\n",
        "                            \"fold_means\": [np.mean(performance_across_folds_by_alg[alg_key][fold_key][stat_key][substat_key])],\n",
        "                            \"stat_vals_across_folds_and_factors\": []+performance_across_folds_by_alg[alg_key][fold_key][stat_key][substat_key],\n",
        "                            \"combo_stats_mean\": None,\n",
        "                            \"combo_stats_sem\": None,\n",
        "                            \"mean_of_fold_means\": None,\n",
        "                            \"sem_of_fold_means\": None,\n",
        "                        }\n",
        "                else:\n",
        "                    summary_stats_by_alg[alg_key][stat_key] = {\n",
        "                        \"fold_means\": [np.mean(performance_across_folds_by_alg[alg_key][fold_key][stat_key])],\n",
        "                        \"stat_vals_across_folds_and_factors\": []+performance_across_folds_by_alg[alg_key][fold_key][stat_key],\n",
        "                        \"combo_stats_mean\": None,\n",
        "                        \"combo_stats_sem\": None,\n",
        "                        \"mean_of_fold_means\": None,\n",
        "                        \"sem_of_fold_means\": None,\n",
        "                    }\n",
        "    for stat_key in summary_stats_by_alg[alg_key].keys():\n",
        "        if \"ancestor_aid\" in stat_key or \"oset_aid\" in stat_key or \"parent_aid\" in stat_key or \"_shd\" in stat_key:\n",
        "            for substat_key in performance_across_folds_by_alg[alg_key][fold_key][stat_key].keys():\n",
        "                summary_stats_by_alg[alg_key][stat_key][substat_key][\"combo_stats_mean\"] = np.mean(summary_stats_by_alg[alg_key][stat_key][substat_key][\"stat_vals_across_folds_and_factors\"])\n",
        "                summary_stats_by_alg[alg_key][stat_key][substat_key][\"combo_stats_sem\"] = np.std(summary_stats_by_alg[alg_key][stat_key][substat_key][\"stat_vals_across_folds_and_factors\"]) / np.sqrt(len(summary_stats_by_alg[alg_key][stat_key][substat_key][\"stat_vals_across_folds_and_factors\"]))\n",
        "                summary_stats_by_alg[alg_key][stat_key][substat_key][\"mean_of_fold_means\"] = np.mean(summary_stats_by_alg[alg_key][stat_key][substat_key][\"fold_means\"])\n",
        "                summary_stats_by_alg[alg_key][stat_key][substat_key][\"sem_of_fold_means\"] = np.std(summary_stats_by_alg[alg_key][stat_key][substat_key][\"fold_means\"]) / np.sqrt(len(summary_stats_by_alg[alg_key][stat_key][substat_key][\"fold_means\"]))\n",
        "        else:\n",
        "            summary_stats_by_alg[alg_key][stat_key][\"combo_stats_mean\"] = np.mean(summary_stats_by_alg[alg_key][stat_key][\"stat_vals_across_folds_and_factors\"])\n",
        "            summary_stats_by_alg[alg_key][stat_key][\"combo_stats_sem\"] = np.std(summary_stats_by_alg[alg_key][stat_key][\"stat_vals_across_folds_and_factors\"]) / np.sqrt(len(summary_stats_by_alg[alg_key][stat_key][\"stat_vals_across_folds_and_factors\"]))\n",
        "            summary_stats_by_alg[alg_key][stat_key][\"mean_of_fold_means\"] = np.mean(summary_stats_by_alg[alg_key][stat_key][\"fold_means\"])\n",
        "            summary_stats_by_alg[alg_key][stat_key][\"sem_of_fold_means\"] = np.std(summary_stats_by_alg[alg_key][stat_key][\"fold_means\"]) / np.sqrt(len(summary_stats_by_alg[alg_key][stat_key][\"fold_means\"]))\n",
        "\n",
        "print(\"summary_stats_by_alg == \", summary_stats_by_alg)\n",
        "for alg in summary_stats_by_alg.keys():\n",
        "    print(\"alg == \", alg)\n",
        "    for stat in summary_stats_by_alg[alg].keys():\n",
        "        print(\"\\t stat == \", stat)\n",
        "        for summary_key in summary_stats_by_alg[alg][stat].keys():\n",
        "            if \"_aid\" in stat or \"_shd\" in stat:\n",
        "                print(\"\\t\\t sub_stat == \", summary_key)\n",
        "                for sub_stat_summary in summary_stats_by_alg[alg][stat][summary_key].keys():\n",
        "                    print(\"\\t\\t\\t summary_key == \", sub_stat_summary, \" == \", summary_stats_by_alg[alg][stat][summary_key][sub_stat_summary])\n",
        "            else:\n",
        "                print(\"\\t\\t summary_key == \", summary_key, \" == \", summary_stats_by_alg[alg][stat][summary_key])"
      ],
      "metadata": {
        "id": "_TejnDVyNVz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRANSPOSED PREDICTION RESULTS"
      ],
      "metadata": {
        "id": "-8g2X6jSNVnH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IWWx38hxNVYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## R-PCMCI D4IC HSNR Experiments\n",
        "\n",
        "Resources:\n",
        " - tutorial: https://github.com/jakobrunge/tigramite/blob/master/tutorials/causal_discovery/tigramite_tutorial_regime_pcmci.ipynb\n",
        " - \"Reconstructing regime-dependent causal relationships from observational time series\" by Elena Saggioro; Jana de Wiljes; Marlene Kretschmer; Jakob Runge (https://pubs.aip.org/aip/cha/article/30/11/113115/595926/Reconstructing-regime-dependent-causal)"
      ],
      "metadata": {
        "id": "2NUImZTtvDZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install tigramite\n",
        "%pip install ortools\n",
        "%pip install dcor"
      ],
      "metadata": {
        "id": "YTCRHsq1xVYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import sklearn\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "import tigramite\n",
        "from tigramite import data_processing as pp\n",
        "from tigramite.toymodels import structural_causal_processes as toys\n",
        "from tigramite import plotting as tp\n",
        "from tigramite.pcmci import PCMCI\n",
        "from tigramite.rpcmci import RPCMCI\n",
        "\n",
        "\n",
        "from tigramite.independence_tests.parcorr import ParCorr\n",
        "from tigramite.independence_tests.gpdc import GPDC\n",
        "from tigramite.independence_tests.cmiknn import CMIknn\n",
        "from tigramite.independence_tests.cmisymb import CMIsymb"
      ],
      "metadata": {
        "id": "pbZXClNevDDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle as pkl\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_recall_curve\n",
        "\n",
        "def get_d4ic_HSNR_repeat_true_standardized_graphs(repeat_id):\n",
        "    net1_adjacency_tensor, net2_adjacency_tensor, net3_adjacency_tensor, net4_adjacency_tensor, net5_adjacency_tensor = None, None, None, None, None\n",
        "    if repeat_id == 0:\n",
        "        net1_adjacency_tensor = np.array([[[0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.]], [[1.], [0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.], [0.]], [[0.], [1.], [1.], [0.], [0.], [0.], [1.], [1.], [0.], [0.]], [[0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [1.], [1.], [0.], [0.], [1.], [1.]], [[0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]]]).squeeze()\n",
        "        net2_adjacency_tensor = np.array([[[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[1.], [0.], [0.], [0.], [0.], [1.], [0.], [1.], [0.], [0.]], [[1.], [0.], [0.], [1.], [0.], [0.], [1.], [0.], [0.], [1.]], [[1.], [0.], [1.], [0.], [0.], [0.], [1.], [0.], [0.], [1.]], [[1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.]], [[0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.]]]).squeeze()\n",
        "        net3_adjacency_tensor = np.array([[[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.]], [[1.], [0.], [0.], [1.], [0.], [0.], [1.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.]], [[0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [1.], [0.], [1.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]]]).squeeze()\n",
        "        net4_adjacency_tensor = np.array([[[0.], [0.], [0.], [1.], [1.], [0.], [1.], [0.], [0.], [0.]], [[1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [1.], [0.], [0.], [0.], [1.], [0.], [1.], [0.], [0.]], [[0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [1.], [0.], [1.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]]]).squeeze()\n",
        "        net5_adjacency_tensor = np.array([[[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[1.], [0.], [0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [1.], [1.], [0.], [0.], [0.], [0.], [1.]], [[0.], [1.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [1.], [1.], [1.], [0.], [0.], [0.], [0.], [1.], [0.]], [[0.], [1.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.]], [[0.], [1.], [0.], [0.], [0.], [1.], [0.], [0.], [0.], [0.]], [[0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]]]).squeeze()\n",
        "    elif repeat_id == 1:\n",
        "        net1_adjacency_tensor = np.array([[[0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.]], [[1.], [0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.], [0.]], [[0.], [1.], [1.], [0.], [0.], [0.], [1.], [1.], [0.], [0.]], [[0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [1.], [1.], [0.], [0.], [1.], [1.]], [[0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]]]).squeeze()\n",
        "        net2_adjacency_tensor = np.array([[[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[1.], [0.], [0.], [0.], [0.], [1.], [0.], [1.], [0.], [0.]], [[1.], [0.], [0.], [1.], [0.], [0.], [1.], [0.], [0.], [1.]], [[1.], [0.], [1.], [0.], [0.], [0.], [1.], [0.], [0.], [1.]], [[1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.]], [[0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.]]]).squeeze()\n",
        "        net3_adjacency_tensor = np.array([[[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.]], [[1.], [0.], [0.], [1.], [0.], [0.], [1.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.]], [[0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [1.], [0.], [1.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]]]).squeeze()\n",
        "        net4_adjacency_tensor = np.array([[[0.], [0.], [0.], [1.], [1.], [0.], [1.], [0.], [0.], [0.]], [[1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [1.], [0.], [0.], [0.], [1.], [0.], [1.], [0.], [0.]], [[0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [1.], [0.], [1.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]]]).squeeze()\n",
        "        net5_adjacency_tensor = np.array([[[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[1.], [0.], [0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [1.], [1.], [0.], [0.], [0.], [0.], [1.]], [[0.], [1.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [1.], [1.], [1.], [0.], [0.], [0.], [0.], [1.], [0.]], [[0.], [1.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.]], [[0.], [1.], [0.], [0.], [0.], [1.], [0.], [0.], [0.], [0.]], [[0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]]]).squeeze()\n",
        "    elif repeat_id == 2:\n",
        "        net1_adjacency_tensor = np.array([[[0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.]], [[1.], [0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.], [0.]], [[0.], [1.], [1.], [0.], [0.], [0.], [1.], [1.], [0.], [0.]], [[0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [1.], [1.], [0.], [0.], [1.], [1.]], [[0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]]]).squeeze()\n",
        "        net2_adjacency_tensor = np.array([[[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[1.], [0.], [0.], [0.], [0.], [1.], [0.], [1.], [0.], [0.]], [[1.], [0.], [0.], [1.], [0.], [0.], [1.], [0.], [0.], [1.]], [[1.], [0.], [1.], [0.], [0.], [0.], [1.], [0.], [0.], [1.]], [[1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.]], [[0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.]]]).squeeze()\n",
        "        net3_adjacency_tensor = np.array([[[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.]], [[1.], [0.], [0.], [1.], [0.], [0.], [1.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.]], [[0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [1.], [0.], [1.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]]]).squeeze()\n",
        "        net4_adjacency_tensor = np.array([[[0.], [0.], [0.], [1.], [1.], [0.], [1.], [0.], [0.], [0.]], [[1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [1.], [0.], [0.], [0.], [1.], [0.], [1.], [0.], [0.]], [[0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [1.], [0.], [1.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]]]).squeeze()\n",
        "        net5_adjacency_tensor = np.array([[[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[1.], [0.], [0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [1.], [1.], [0.], [0.], [0.], [0.], [1.]], [[0.], [1.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [1.], [1.], [1.], [0.], [0.], [0.], [0.], [1.], [0.]], [[0.], [1.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.]], [[0.], [1.], [0.], [0.], [0.], [1.], [0.], [0.], [0.], [0.]], [[0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]]]).squeeze()\n",
        "    elif repeat_id == 3:\n",
        "        net1_adjacency_tensor = np.array([[[0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.]], [[1.], [0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.], [0.]], [[0.], [1.], [1.], [0.], [0.], [0.], [1.], [1.], [0.], [0.]], [[0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [1.], [1.], [0.], [0.], [1.], [1.]], [[0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]]]).squeeze()\n",
        "        net2_adjacency_tensor = np.array([[[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[1.], [0.], [0.], [0.], [0.], [1.], [0.], [1.], [0.], [0.]], [[1.], [0.], [0.], [1.], [0.], [0.], [1.], [0.], [0.], [1.]], [[1.], [0.], [1.], [0.], [0.], [0.], [1.], [0.], [0.], [1.]], [[1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.]], [[0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.]]]).squeeze()\n",
        "        net3_adjacency_tensor = np.array([[[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.]], [[1.], [0.], [0.], [1.], [0.], [0.], [1.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.]], [[0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [1.], [0.], [1.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]]]).squeeze()\n",
        "        net4_adjacency_tensor = np.array([[[0.], [0.], [0.], [1.], [1.], [0.], [1.], [0.], [0.], [0.]], [[1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [1.], [0.], [0.], [0.], [1.], [0.], [1.], [0.], [0.]], [[0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [1.], [0.], [1.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]]]).squeeze()\n",
        "        net5_adjacency_tensor = np.array([[[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[1.], [0.], [0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [1.], [1.], [0.], [0.], [0.], [0.], [1.]], [[0.], [1.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [1.], [1.], [1.], [0.], [0.], [0.], [0.], [1.], [0.]], [[0.], [1.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.]], [[0.], [1.], [0.], [0.], [0.], [1.], [0.], [0.], [0.], [0.]], [[0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]]]).squeeze()\n",
        "    elif repeat_id == 4:\n",
        "        net1_adjacency_tensor = np.array([[[0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.]], [[1.], [0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.], [0.]], [[0.], [1.], [1.], [0.], [0.], [0.], [1.], [1.], [0.], [0.]], [[0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [1.], [1.], [0.], [0.], [1.], [1.]], [[0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]]]).squeeze()\n",
        "        net2_adjacency_tensor = np.array([[[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[1.], [0.], [0.], [0.], [0.], [1.], [0.], [1.], [0.], [0.]], [[1.], [0.], [0.], [1.], [0.], [0.], [1.], [0.], [0.], [1.]], [[1.], [0.], [1.], [0.], [0.], [0.], [1.], [0.], [0.], [1.]], [[1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.]], [[0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.]]]).squeeze()\n",
        "        net3_adjacency_tensor = np.array([[[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.]], [[1.], [0.], [0.], [1.], [0.], [0.], [1.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.]], [[0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [1.], [0.], [1.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]]]).squeeze()\n",
        "        net4_adjacency_tensor = np.array([[[0.], [0.], [0.], [1.], [1.], [0.], [1.], [0.], [0.], [0.]], [[1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [1.], [0.], [0.], [0.], [1.], [0.], [1.], [0.], [0.]], [[0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [1.], [0.], [1.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]]]).squeeze()\n",
        "        net5_adjacency_tensor = np.array([[[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[1.], [0.], [0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [1.], [1.], [0.], [0.], [0.], [0.], [1.]], [[0.], [1.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [1.], [1.], [1.], [0.], [0.], [0.], [0.], [1.], [0.]], [[0.], [1.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.]], [[0.], [1.], [0.], [0.], [0.], [1.], [0.], [0.], [0.], [0.]], [[0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]]]).squeeze()\n",
        "    else:\n",
        "        raise ValueError()\n",
        "    true_graphs_by_regime = {\n",
        "        0: net1_adjacency_tensor,\n",
        "        1: net2_adjacency_tensor,\n",
        "        2: net3_adjacency_tensor,\n",
        "        3: net4_adjacency_tensor,\n",
        "        4: net5_adjacency_tensor,\n",
        "    }\n",
        "    return true_graphs_by_regime\n",
        "\n",
        "def prepare_data_for_rpcmci_modeling(orig_data):\n",
        "    num_samps = len(orig_data)\n",
        "    rpcmci_data = None\n",
        "    rpcmci_labels = None\n",
        "    T_window_size = None\n",
        "    N = None\n",
        "    num_regimes = None\n",
        "    masks_by_regime_index = None\n",
        "    for i, samp in enumerate(orig_data):\n",
        "        x = samp[0]\n",
        "        y = samp[1]\n",
        "        curr_dom_regime = np.argmax(y.squeeze())\n",
        "        if rpcmci_data is None:\n",
        "            assert rpcmci_labels is None\n",
        "            T_window_size = x.shape[0]\n",
        "            N = x.shape[1]\n",
        "            rpcmci_data = x\n",
        "            assert rpcmci_data.shape == (T_window_size, N)\n",
        "            num_regimes = y.shape[0]\n",
        "            rpcmci_labels = np.concatenate([y.T for _ in range(T_window_size)], axis=0)\n",
        "            assert rpcmci_labels.shape == (T_window_size, num_regimes)\n",
        "            masks_by_regime_index = {r:np.zeros(rpcmci_data.shape) for r in range(num_regimes)}\n",
        "        else:\n",
        "            rpcmci_data = np.concatenate((rpcmci_data, x), axis=0)\n",
        "            rpcmci_labels = np.concatenate([rpcmci_labels]+[y.T for _ in range(T_window_size)], axis=0)\n",
        "            for r in masks_by_regime_index.keys():\n",
        "                masks_by_regime_index[r] = np.concatenate([masks_by_regime_index[r], np.zeros(x.shape)], axis=0)\n",
        "        for r in masks_by_regime_index.keys():\n",
        "            assert masks_by_regime_index[r].shape == rpcmci_data.shape\n",
        "        masks_by_regime_index[curr_dom_regime][-1*T_window_size:,:] = masks_by_regime_index[curr_dom_regime][-1*T_window_size:,:] + 1\n",
        "    T = T_window_size*num_samps\n",
        "    assert rpcmci_data.shape == (T, N)\n",
        "    assert rpcmci_labels.shape == (T, num_regimes)\n",
        "    assert np.max([np.max(masks_by_regime_index[r]) for r in range(num_regimes)]) == 1\n",
        "    assert np.min([np.min(masks_by_regime_index[r]) for r in range(num_regimes)]) == 0\n",
        "    return rpcmci_data, rpcmci_labels, masks_by_regime_index, T_window_size, T, N, num_regimes\n",
        "\n",
        "def get_standardized_off_diagonal_relation_predictions(A_tensor, transpose=True):\n",
        "    assert len(A_tensor.shape) == 3\n",
        "    assert A_tensor.shape[0] == A_tensor.shape[1]\n",
        "    standard_A = np.sum(np.abs(A_tensor), axis=2) # standard convention is that columns drive rows\n",
        "    if transpose:\n",
        "        standard_A = standard_A.T\n",
        "    off_diag_mask = np.ones(standard_A.shape) - np.eye(standard_A.shape[0])\n",
        "    off_diag_standard_A = standard_A*off_diag_mask\n",
        "    return off_diag_standard_A\n",
        "\n",
        "def compute_optimal_f1(labels, pred_logits):\n",
        "    \"\"\"\n",
        "    See:\n",
        "     - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html\n",
        "     - https://stackoverflow.com/questions/70902917/how-to-calculate-precision-recall-and-f1-for-entity-prediction#:~:text=The%20F1%20score%20of%20a,a%20class%20in%20one%20metric.\n",
        "     - https://stackoverflow.com/questions/57060907/compute-maximum-f1-score-using-precision-recall-curve\n",
        "    \"\"\"\n",
        "    precision, recall, thresholds = precision_recall_curve(labels, pred_logits)\n",
        "    precision = precision[:-1] # see https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html\n",
        "    recall = recall[:-1] # see https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html\n",
        "    f1_scores_by_threshold = (2.0 * precision * recall) / (precision + recall)\n",
        "    for ind, f1 in enumerate(f1_scores_by_threshold):\n",
        "        if not np.isfinite(f1):\n",
        "            f1_scores_by_threshold[ind] = 0.\n",
        "    opt_threshold = np.argmax(f1_scores_by_threshold)\n",
        "    opt_f1 = np.max(f1_scores_by_threshold)\n",
        "    assert np.isfinite(opt_f1)\n",
        "    return opt_threshold, opt_f1\n",
        "\n",
        "def get_pcmci_edge_preds_from_graph(graph):\n",
        "    assert len(graph.shape) == 3\n",
        "    assert graph.shape[0] == graph.shape[1]\n",
        "    edge_pred_tensor = np.zeros(graph.shape)\n",
        "    for i in range(graph.shape[0]):\n",
        "        for j in range(graph.shape[1]):\n",
        "            for k in range(graph.shape[2]):\n",
        "                if graph[i,j,k] == \"-->\":\n",
        "                    edge_pred_tensor[i,j,k] = 1\n",
        "    return edge_pred_tensor\n"
      ],
      "metadata": {
        "id": "CgdnbrZCM786"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_d4ic_experiment(data_file_name, repeat_id, pred_source=\"graph\", transpose=True):\n",
        "    # load data and initialize necessary variables\n",
        "    orig_train_data = pkl.load(open(data_file_name, \"rb\"))\n",
        "    train_data, train_labels, masks_by_regime_index, T_window_size, T, N, num_regimes = prepare_data_for_rpcmci_modeling(orig_train_data)\n",
        "    var_names = [\"c\"+str(i) for i in range(N)]\n",
        "    datatime = np.arange(T)\n",
        "\n",
        "    dataframe_plotting_by_regime = dict()\n",
        "    for r in range(num_regimes):\n",
        "        dataframe_plotting_by_regime[r] = pp.DataFrame(train_data, mask=masks_by_regime_index[r])\n",
        "\n",
        "    # Case where causal regimes are known\n",
        "    pcmci_by_regime = {r:PCMCI(dataframe=dataframe_plotting_by_regime[r], cond_ind_test=ParCorr(mask_type='y')) for r in range(num_regimes)}\n",
        "    pcmci_results_by_regime = {r: pcmci_by_regime[r].run_pcmci(tau_min=1, tau_max=2, pc_alpha=0.2, alpha_level=0.01) for r in range(num_regimes)}\n",
        "\n",
        "    pcmci_edge_preds_by_regime = None\n",
        "    if pred_source == \"graph\":\n",
        "        pcmci_edge_preds_by_regime = {r:get_pcmci_edge_preds_from_graph(pcmci_results_by_regime[r]['graph']) for r in range(num_regimes)}\n",
        "    elif pred_source == \"val_matrix\":\n",
        "        pcmci_edge_preds_by_regime = {r:pcmci_results_by_regime[r]['val_matrix'] for r in range(num_regimes)}\n",
        "    else:\n",
        "        raise ValueError()\n",
        "    pcmci_standardizedRelationPreds_by_regime = {r:get_standardized_off_diagonal_relation_predictions(pcmci_edge_preds_by_regime[r], transpose=transpose) for r in range(num_regimes)}\n",
        "\n",
        "    true_graphs_by_regime = get_d4ic_HSNR_repeat_true_standardized_graphs(repeat_id)\n",
        "    pcmci_optF1Scores_by_regime = dict()\n",
        "    for r in range(num_regimes):\n",
        "        _, opt_f1 = compute_optimal_f1(true_graphs_by_regime[r].flatten(), pcmci_standardizedRelationPreds_by_regime[r].flatten())\n",
        "        pcmci_optF1Scores_by_regime[r] = opt_f1\n",
        "    pcmci_optF1Score_cross_regime_mean = np.mean([pcmci_optF1Scores_by_regime[r] for r in pcmci_optF1Scores_by_regime.keys()])\n",
        "    pcmci_optF1Score_cross_regime_sem = np.std([pcmci_optF1Scores_by_regime[r] for r in pcmci_optF1Scores_by_regime.keys()])/np.sqrt(len(pcmci_optF1Scores_by_regime.keys()))\n",
        "    print(\"pcmci_optF1Scores_by_regime == \", pcmci_optF1Scores_by_regime)\n",
        "    print(\"mean_optF1Score for PCMCI on D4IC HSNR REPEAT0: \", pcmci_optF1Score_cross_regime_mean)\n",
        "    print(\"sem_optF1Score for PCMCI on D4IC HSNR REPEAT0: \", pcmci_optF1Score_cross_regime_sem)\n",
        "    return pcmci_optF1Scores_by_regime, pcmci_optF1Score_cross_regime_mean, pcmci_optF1Score_cross_regime_sem\n",
        "\n"
      ],
      "metadata": {
        "id": "o8bCN5uJN1p6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment using results' graph key as edge prediction matrix\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "pcmci_optF1Scores_d4icHSNR_repeat0, rep0_f1ScoreMean, _ = run_d4ic_experiment(\"d4ic_hsnr_repeat0_train_subset_0.pkl\", 0, pred_source=\"graph\", transpose=True)\n",
        "pcmci_optF1Scores_d4icHSNR_repeat1, rep1_f1ScoreMean, _ = run_d4ic_experiment(\"d4ic_hsnr_repeat1_train_subset_0.pkl\", 1, pred_source=\"graph\", transpose=True)\n",
        "pcmci_optF1Scores_d4icHSNR_repeat2, rep2_f1ScoreMean, _ = run_d4ic_experiment(\"d4ic_hsnr_repeat2_train_subset_0.pkl\", 2, pred_source=\"graph\", transpose=True)\n",
        "pcmci_optF1Scores_d4icHSNR_repeat3, rep3_f1ScoreMean, _ = run_d4ic_experiment(\"d4ic_hsnr_repeat3_train_subset_0.pkl\", 3, pred_source=\"graph\", transpose=True)\n",
        "pcmci_optF1Scores_d4icHSNR_repeat4, rep4_f1ScoreMean, _ = run_d4ic_experiment(\"d4ic_hsnr_repeat4_train_subset_0.pkl\", 4, pred_source=\"graph\", transpose=True)\n",
        "\n",
        "print(\"\\n\\n FULL EXPERIMENT SUMMARY STATISTICS -------------------------\")\n",
        "cross_exp_pcmci_optF1ScoreMeans = [rep0_f1ScoreMean, rep1_f1ScoreMean, rep2_f1ScoreMean, rep3_f1ScoreMean, rep4_f1ScoreMean]\n",
        "print(\"cross_exp_pcmci_optF1ScoreMeans == \", cross_exp_pcmci_optF1ScoreMeans)\n",
        "print(\"np.mean(cross_exp_pcmci_optF1ScoreMeans) == \", np.mean(cross_exp_pcmci_optF1ScoreMeans))\n",
        "print(\"sem(cross_exp_pcmci_optF1ScoreMeans) == \", np.std(cross_exp_pcmci_optF1ScoreMeans) / np.sqrt(len(cross_exp_pcmci_optF1ScoreMeans)))\n",
        "\n",
        "cross_exp_pcmci_optF1Scores = []\n",
        "for repeat_map in [pcmci_optF1Scores_d4icHSNR_repeat0, pcmci_optF1Scores_d4icHSNR_repeat1, pcmci_optF1Scores_d4icHSNR_repeat2, pcmci_optF1Scores_d4icHSNR_repeat3, pcmci_optF1Scores_d4icHSNR_repeat4]:\n",
        "    for key in repeat_map.keys():\n",
        "        cross_exp_pcmci_optF1Scores.append(repeat_map[key])\n",
        "print(\"cross_exp_pcmci_optF1Scores == \", cross_exp_pcmci_optF1Scores)\n",
        "print(\"np.mean(cross_exp_pcmci_optF1Scores) == \", np.mean(cross_exp_pcmci_optF1Scores))\n",
        "print(\"sem(cross_exp_pcmci_optF1Scores) == \", np.std(cross_exp_pcmci_optF1Scores)/np.sqrt(len(cross_exp_pcmci_optF1Scores)))"
      ],
      "metadata": {
        "id": "tczx5YyyR1e2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment using results' graph key as edge prediction matrix and NOT transposing it\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "pcmci_optF1Scores_d4icHSNR_repeat0, rep0_f1ScoreMean, _ = run_d4ic_experiment(\"d4ic_hsnr_repeat0_train_subset_0.pkl\", 0, pred_source=\"graph\", transpose=False)\n",
        "pcmci_optF1Scores_d4icHSNR_repeat1, rep1_f1ScoreMean, _ = run_d4ic_experiment(\"d4ic_hsnr_repeat1_train_subset_0.pkl\", 1, pred_source=\"graph\", transpose=False)\n",
        "pcmci_optF1Scores_d4icHSNR_repeat2, rep2_f1ScoreMean, _ = run_d4ic_experiment(\"d4ic_hsnr_repeat2_train_subset_0.pkl\", 2, pred_source=\"graph\", transpose=False)\n",
        "pcmci_optF1Scores_d4icHSNR_repeat3, rep3_f1ScoreMean, _ = run_d4ic_experiment(\"d4ic_hsnr_repeat3_train_subset_0.pkl\", 3, pred_source=\"graph\", transpose=False)\n",
        "pcmci_optF1Scores_d4icHSNR_repeat4, rep4_f1ScoreMean, _ = run_d4ic_experiment(\"d4ic_hsnr_repeat4_train_subset_0.pkl\", 4, pred_source=\"graph\", transpose=False)\n",
        "\n",
        "print(\"\\n\\n FULL EXPERIMENT SUMMARY STATISTICS -------------------------\")\n",
        "cross_exp_pcmci_optF1ScoreMeans = [rep0_f1ScoreMean, rep1_f1ScoreMean, rep2_f1ScoreMean, rep3_f1ScoreMean, rep4_f1ScoreMean]\n",
        "print(\"cross_exp_pcmci_optF1ScoreMeans == \", cross_exp_pcmci_optF1ScoreMeans)\n",
        "print(\"np.mean(cross_exp_pcmci_optF1ScoreMeans) == \", np.mean(cross_exp_pcmci_optF1ScoreMeans))\n",
        "print(\"sem(cross_exp_pcmci_optF1ScoreMeans) == \", np.std(cross_exp_pcmci_optF1ScoreMeans) / np.sqrt(len(cross_exp_pcmci_optF1ScoreMeans)))\n",
        "\n",
        "cross_exp_pcmci_optF1Scores = []\n",
        "for repeat_map in [pcmci_optF1Scores_d4icHSNR_repeat0, pcmci_optF1Scores_d4icHSNR_repeat1, pcmci_optF1Scores_d4icHSNR_repeat2, pcmci_optF1Scores_d4icHSNR_repeat3, pcmci_optF1Scores_d4icHSNR_repeat4]:\n",
        "    for key in repeat_map.keys():\n",
        "        cross_exp_pcmci_optF1Scores.append(repeat_map[key])\n",
        "print(\"cross_exp_pcmci_optF1Scores == \", cross_exp_pcmci_optF1Scores)\n",
        "print(\"np.mean(cross_exp_pcmci_optF1Scores) == \", np.mean(cross_exp_pcmci_optF1Scores))\n",
        "print(\"sem(cross_exp_pcmci_optF1Scores) == \", np.std(cross_exp_pcmci_optF1Scores)/np.sqrt(len(cross_exp_pcmci_optF1Scores)))"
      ],
      "metadata": {
        "id": "AKFVefNsTlUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment using results' val_matrix key as edge prediction matrix\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "pcmci_optF1Scores_d4icHSNR_repeat0, rep0_f1ScoreMean, _ = run_d4ic_experiment(\"d4ic_hsnr_repeat0_train_subset_0.pkl\", 0, pred_source=\"val_matrix\", transpose=True)\n",
        "pcmci_optF1Scores_d4icHSNR_repeat1, rep1_f1ScoreMean, _ = run_d4ic_experiment(\"d4ic_hsnr_repeat1_train_subset_0.pkl\", 1, pred_source=\"val_matrix\", transpose=True)\n",
        "pcmci_optF1Scores_d4icHSNR_repeat2, rep2_f1ScoreMean, _ = run_d4ic_experiment(\"d4ic_hsnr_repeat2_train_subset_0.pkl\", 2, pred_source=\"val_matrix\", transpose=True)\n",
        "pcmci_optF1Scores_d4icHSNR_repeat3, rep3_f1ScoreMean, _ = run_d4ic_experiment(\"d4ic_hsnr_repeat3_train_subset_0.pkl\", 3, pred_source=\"val_matrix\", transpose=True)\n",
        "pcmci_optF1Scores_d4icHSNR_repeat4, rep4_f1ScoreMean, _ = run_d4ic_experiment(\"d4ic_hsnr_repeat4_train_subset_0.pkl\", 4, pred_source=\"val_matrix\", transpose=True)\n",
        "\n",
        "print(\"\\n\\n FULL EXPERIMENT SUMMARY STATISTICS -------------------------\")\n",
        "cross_exp_pcmci_optF1ScoreMeans = [rep0_f1ScoreMean, rep1_f1ScoreMean, rep2_f1ScoreMean, rep3_f1ScoreMean, rep4_f1ScoreMean]\n",
        "print(\"cross_exp_pcmci_optF1ScoreMeans == \", cross_exp_pcmci_optF1ScoreMeans)\n",
        "print(\"np.mean(cross_exp_pcmci_optF1ScoreMeans) == \", np.mean(cross_exp_pcmci_optF1ScoreMeans))\n",
        "print(\"sem(cross_exp_pcmci_optF1ScoreMeans) == \", np.std(cross_exp_pcmci_optF1ScoreMeans) / np.sqrt(len(cross_exp_pcmci_optF1ScoreMeans)))\n",
        "\n",
        "cross_exp_pcmci_optF1Scores = []\n",
        "for repeat_map in [pcmci_optF1Scores_d4icHSNR_repeat0, pcmci_optF1Scores_d4icHSNR_repeat1, pcmci_optF1Scores_d4icHSNR_repeat2, pcmci_optF1Scores_d4icHSNR_repeat3, pcmci_optF1Scores_d4icHSNR_repeat4]:\n",
        "    for key in repeat_map.keys():\n",
        "        cross_exp_pcmci_optF1Scores.append(repeat_map[key])\n",
        "print(\"cross_exp_pcmci_optF1Scores == \", cross_exp_pcmci_optF1Scores)\n",
        "print(\"np.mean(cross_exp_pcmci_optF1Scores) == \", np.mean(cross_exp_pcmci_optF1Scores))\n",
        "print(\"sem(cross_exp_pcmci_optF1Scores) == \", np.std(cross_exp_pcmci_optF1Scores)/np.sqrt(len(cross_exp_pcmci_optF1Scores)))"
      ],
      "metadata": {
        "id": "ie65vNnXadmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment using results' val_matrix key as edge prediction matrix and NOT transposing it\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "pcmci_optF1Scores_d4icHSNR_repeat0, rep0_f1ScoreMean, _ = run_d4ic_experiment(\"d4ic_hsnr_repeat0_train_subset_0.pkl\", 0, pred_source=\"val_matrix\", transpose=False)\n",
        "pcmci_optF1Scores_d4icHSNR_repeat1, rep1_f1ScoreMean, _ = run_d4ic_experiment(\"d4ic_hsnr_repeat1_train_subset_0.pkl\", 1, pred_source=\"val_matrix\", transpose=False)\n",
        "pcmci_optF1Scores_d4icHSNR_repeat2, rep2_f1ScoreMean, _ = run_d4ic_experiment(\"d4ic_hsnr_repeat2_train_subset_0.pkl\", 2, pred_source=\"val_matrix\", transpose=False)\n",
        "pcmci_optF1Scores_d4icHSNR_repeat3, rep3_f1ScoreMean, _ = run_d4ic_experiment(\"d4ic_hsnr_repeat3_train_subset_0.pkl\", 3, pred_source=\"val_matrix\", transpose=False)\n",
        "pcmci_optF1Scores_d4icHSNR_repeat4, rep4_f1ScoreMean, _ = run_d4ic_experiment(\"d4ic_hsnr_repeat4_train_subset_0.pkl\", 4, pred_source=\"val_matrix\", transpose=False)\n",
        "\n",
        "print(\"\\n\\n FULL EXPERIMENT SUMMARY STATISTICS -------------------------\")\n",
        "cross_exp_pcmci_optF1ScoreMeans = [rep0_f1ScoreMean, rep1_f1ScoreMean, rep2_f1ScoreMean, rep3_f1ScoreMean, rep4_f1ScoreMean]\n",
        "print(\"cross_exp_pcmci_optF1ScoreMeans == \", cross_exp_pcmci_optF1ScoreMeans)\n",
        "print(\"np.mean(cross_exp_pcmci_optF1ScoreMeans) == \", np.mean(cross_exp_pcmci_optF1ScoreMeans))\n",
        "print(\"sem(cross_exp_pcmci_optF1ScoreMeans) == \", np.std(cross_exp_pcmci_optF1ScoreMeans) / np.sqrt(len(cross_exp_pcmci_optF1ScoreMeans)))\n",
        "\n",
        "cross_exp_pcmci_optF1Scores = []\n",
        "for repeat_map in [pcmci_optF1Scores_d4icHSNR_repeat0, pcmci_optF1Scores_d4icHSNR_repeat1, pcmci_optF1Scores_d4icHSNR_repeat2, pcmci_optF1Scores_d4icHSNR_repeat3, pcmci_optF1Scores_d4icHSNR_repeat4]:\n",
        "    for key in repeat_map.keys():\n",
        "        cross_exp_pcmci_optF1Scores.append(repeat_map[key])\n",
        "print(\"cross_exp_pcmci_optF1Scores == \", cross_exp_pcmci_optF1Scores)\n",
        "print(\"np.mean(cross_exp_pcmci_optF1Scores) == \", np.mean(cross_exp_pcmci_optF1Scores))\n",
        "print(\"sem(cross_exp_pcmci_optF1Scores) == \", np.std(cross_exp_pcmci_optF1Scores)/np.sqrt(len(cross_exp_pcmci_optF1Scores)))"
      ],
      "metadata": {
        "id": "oobw44q5Ttxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sandbox"
      ],
      "metadata": {
        "id": "_jPWfmBoMybd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data_for_rpcmci_modeling(orig_data):\n",
        "    num_samps = len(orig_data)\n",
        "    rpcmci_data = None\n",
        "    rpcmci_labels = None\n",
        "    T_window_size = None\n",
        "    N = None\n",
        "    num_regimes = None\n",
        "    masks_by_regime_index = None\n",
        "    for i, samp in enumerate(orig_data):\n",
        "        x = samp[0]\n",
        "        y = samp[1]\n",
        "        curr_dom_regime = np.argmax(y.squeeze())\n",
        "        if rpcmci_data is None:\n",
        "            assert rpcmci_labels is None\n",
        "            T_window_size = x.shape[0]\n",
        "            N = x.shape[1]\n",
        "            rpcmci_data = x\n",
        "            assert rpcmci_data.shape == (T_window_size, N)\n",
        "            num_regimes = y.shape[0]\n",
        "            rpcmci_labels = np.concatenate([y.T for _ in range(T_window_size)], axis=0)\n",
        "            assert rpcmci_labels.shape == (T_window_size, num_regimes)\n",
        "            masks_by_regime_index = {r:np.zeros(rpcmci_data.shape) for r in range(num_regimes)}\n",
        "        else:\n",
        "            rpcmci_data = np.concatenate((rpcmci_data, x), axis=0)\n",
        "            rpcmci_labels = np.concatenate([rpcmci_labels]+[y.T for _ in range(T_window_size)], axis=0)\n",
        "            for r in masks_by_regime_index.keys():\n",
        "                masks_by_regime_index[r] = np.concatenate([masks_by_regime_index[r], np.zeros(x.shape)], axis=0)\n",
        "        for r in masks_by_regime_index.keys():\n",
        "            assert masks_by_regime_index[r].shape == rpcmci_data.shape\n",
        "        masks_by_regime_index[curr_dom_regime][-1*T_window_size:,:] = masks_by_regime_index[curr_dom_regime][-1*T_window_size:,:] + 1\n",
        "    T = T_window_size*num_samps\n",
        "    assert rpcmci_data.shape == (T, N)\n",
        "    assert rpcmci_labels.shape == (T, num_regimes)\n",
        "    assert np.max([np.max(masks_by_regime_index[r]) for r in range(num_regimes)]) == 1\n",
        "    assert np.min([np.min(masks_by_regime_index[r]) for r in range(num_regimes)]) == 0\n",
        "    return rpcmci_data, rpcmci_labels, masks_by_regime_index, T_window_size, T, N, num_regimes\n",
        "\n",
        "\n",
        "# load data\n",
        "import pickle as pkl\n",
        "\n",
        "d4icHSNR_rep0_train_data = pkl.load(open(\"d4ic_hsnr_repeat0_train_subset_0.pkl\", \"rb\"))\n",
        "d4icHSNR_rep0_val_data = pkl.load(open(\"d4ic_hsnr_repeat0_val_subset_0.pkl\", \"rb\"))\n",
        "\n",
        "print(\"len(d4icHSNR_rep0_train_data) == \", len(d4icHSNR_rep0_train_data))\n",
        "print(len(d4icHSNR_rep0_train_data[0]))\n",
        "print(d4icHSNR_rep0_train_data[0][0].shape)\n",
        "print(d4icHSNR_rep0_train_data[0][1].shape)\n",
        "\n",
        "rpcmci_data, rpcmci_labels, masks_by_regime_index, T_window_size, T, N, num_regimes = prepare_data_for_rpcmci_modeling(d4icHSNR_rep0_train_data)\n",
        "print(\"rpcmci_data.shape == \", rpcmci_data.shape)\n",
        "print(\"rpcmci_labels.shape == \", rpcmci_labels.shape)\n",
        "print(\"masks_by_regime_index == \", masks_by_regime_index)\n",
        "print(\"T_window_size == \", T_window_size)\n",
        "print(\"T == \", T)\n",
        "print(\"N == \", N)\n",
        "print(\"num_regimes == \", num_regimes)\n",
        "\n",
        "var_names = [\"c\"+str(i) for i in range(N)]\n",
        "rpcmci_datatime = np.arange(T)\n",
        "\n",
        "dataframe_plotting_by_regime = dict()\n",
        "for r in range(num_regimes):\n",
        "    dataframe_plotting_by_regime[r] = pp.DataFrame(rpcmci_data, mask=masks_by_regime_index[r])\n",
        "    tp.plot_timeseries(dataframe_plotting_by_regime[r], figsize=(N,N), grey_masked_samples='data')\n",
        "    plt.xlabel(\"Regime \"+str(r)+\" Data (Grey)\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "06h4KjUMv45g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_standardized_off_diagonal_relation_predictions(A_tensor):\n",
        "    assert len(A_tensor.shape) == 3\n",
        "    assert A_tensor.shape[0] == A_tensor.shape[1]\n",
        "    standard_A = np.sum(np.abs(A_tensor), axis=2).T # standard convention is that columns drive rows\n",
        "    off_diag_mask = np.ones(standard_A.shape) - np.eye(standard_A.shape[0])\n",
        "    off_diag_standard_A = standard_A*off_diag_mask\n",
        "    return off_diag_standard_A\n",
        "\n",
        "# Case where causal regimes are known\n",
        "pcmci_by_regime = {r:PCMCI(dataframe=dataframe_plotting_by_regime[r], cond_ind_test=ParCorr(mask_type='y')) for r in range(num_regimes)}\n",
        "pcmci_results_by_regime = {r: pcmci_by_regime[r].run_pcmci(tau_min=1, tau_max=2, pc_alpha=0.2, alpha_level=0.01) for r in range(num_regimes)}\n",
        "for r in pcmci_results_by_regime.keys():\n",
        "    tp.plot_graph(\n",
        "        val_matrix=pcmci_results_by_regime[r]['val_matrix'],\n",
        "        graph=pcmci_results_by_regime[r]['graph'],\n",
        "        var_names=var_names,\n",
        "        node_aspect=0.5, node_size=0.5\n",
        "    )\n",
        "    plt.title(\"PCMCI Results for Regime \"+str(r))\n",
        "    plt.show()\n",
        "pcmci_standardizedRelationPreds_by_regime = {r:get_standardized_off_diagonal_relation_predictions(pcmci_results_by_regime[r]['val_matrix']) for r in range(num_regimes)}\n",
        "for r in pcmci_standardizedRelationPreds_by_regime.keys():\n",
        "    plt.imshow(pcmci_standardizedRelationPreds_by_regime[r])\n",
        "    plt.colorbar()\n",
        "    plt.title(\"PCMCI Standardized Inter-Variable Relation Preds for Regime \"+str(r))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "2nRgY-ph-Rpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, f1_score, precision_recall_curve\n",
        "\n",
        "# evaluating standardized predictions\n",
        "\n",
        "def get_d4ic_HSNR_rep0_true_standardized_graphs():\n",
        "    net1_adjacency_tensor = np.array([[[0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.]], [[1.], [0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.], [0.]], [[0.], [1.], [1.], [0.], [0.], [0.], [1.], [1.], [0.], [0.]], [[0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [1.], [1.], [0.], [0.], [1.], [1.]], [[0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]]]).squeeze()\n",
        "    net2_adjacency_tensor = np.array([[[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[1.], [0.], [0.], [0.], [0.], [1.], [0.], [1.], [0.], [0.]], [[1.], [0.], [0.], [1.], [0.], [0.], [1.], [0.], [0.], [1.]], [[1.], [0.], [1.], [0.], [0.], [0.], [1.], [0.], [0.], [1.]], [[1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.]], [[0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.]]]).squeeze()\n",
        "    net3_adjacency_tensor = np.array([[[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.]], [[1.], [0.], [0.], [1.], [0.], [0.], [1.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.]], [[0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [1.], [0.], [1.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]]]).squeeze()\n",
        "    net4_adjacency_tensor = np.array([[[0.], [0.], [0.], [1.], [1.], [0.], [1.], [0.], [0.], [0.]], [[1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [1.], [0.], [0.], [0.], [1.], [0.], [1.], [0.], [0.]], [[0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [1.], [0.], [1.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [1.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]]]).squeeze()\n",
        "    net5_adjacency_tensor = np.array([[[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[1.], [0.], [0.], [0.], [1.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [1.], [1.], [0.], [0.], [0.], [0.], [1.]], [[0.], [1.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [1.], [1.], [1.], [0.], [0.], [0.], [0.], [1.], [0.]], [[0.], [1.], [0.], [0.], [0.], [0.], [1.], [0.], [0.], [0.]], [[0.], [1.], [0.], [0.], [0.], [1.], [0.], [0.], [0.], [0.]], [[0.], [1.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]], [[0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.], [0.]]]).squeeze()\n",
        "    true_graphs_by_regime = {\n",
        "        0: net1_adjacency_tensor,\n",
        "        1: net2_adjacency_tensor,\n",
        "        2: net3_adjacency_tensor,\n",
        "        3: net4_adjacency_tensor,\n",
        "        4: net5_adjacency_tensor,\n",
        "    }\n",
        "    return true_graphs_by_regime\n",
        "\n",
        "def compute_optimal_f1(labels, pred_logits):\n",
        "    \"\"\"\n",
        "    See:\n",
        "     - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html\n",
        "     - https://stackoverflow.com/questions/70902917/how-to-calculate-precision-recall-and-f1-for-entity-prediction#:~:text=The%20F1%20score%20of%20a,a%20class%20in%20one%20metric.\n",
        "     - https://stackoverflow.com/questions/57060907/compute-maximum-f1-score-using-precision-recall-curve\n",
        "    \"\"\"\n",
        "    precision, recall, thresholds = precision_recall_curve(labels, pred_logits)\n",
        "    precision = precision[:-1] # see https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html\n",
        "    recall = recall[:-1] # see https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html\n",
        "    f1_scores_by_threshold = (2.0 * precision * recall) / (precision + recall)\n",
        "    for ind, f1 in enumerate(f1_scores_by_threshold):\n",
        "        if not np.isfinite(f1):\n",
        "            f1_scores_by_threshold[ind] = 0.\n",
        "    opt_threshold = np.argmax(f1_scores_by_threshold)\n",
        "    opt_f1 = np.max(f1_scores_by_threshold)\n",
        "    assert np.isfinite(opt_f1)\n",
        "    return opt_threshold, opt_f1\n",
        "\n",
        "\n",
        "true_graphs_by_regime = get_d4ic_HSNR_rep0_true_standardized_graphs()\n",
        "pcmci_optF1Scores_by_regime = dict()\n",
        "for r in range(num_regimes):\n",
        "    _, opt_f1 = compute_optimal_f1(true_graphs_by_regime[r].flatten(), pcmci_standardizedRelationPreds_by_regime[r].flatten())\n",
        "    pcmci_optF1Scores_by_regime[r] = opt_f1\n",
        "print(pcmci_optF1Scores_by_regime)\n",
        "print(\"mean_optF1Score for PCMCI on D4IC HSNR REPEAT0: \", np.mean([pcmci_optF1Scores_by_regime[r] for r in pcmci_optF1Scores_by_regime.keys()]))\n",
        "print(\"sem_optF1Score for PCMCI on D4IC HSNR REPEAT0: \", np.std([pcmci_optF1Scores_by_regime[r] for r in pcmci_optF1Scores_by_regime.keys()])/np.sqrt(len(pcmci_optF1Scores_by_regime.keys())))"
      ],
      "metadata": {
        "id": "ZaGLhke9FfiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computing Complexity Score of D4IC HSNR Networks 01/27/2025"
      ],
      "metadata": {
        "id": "vWInlnJCTFiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c = lambda x: ((x[1]) / (x[0]**2. - x[0]))**(-1)\n",
        "\n",
        "hsnr_fold0_net1_nE = 15\n",
        "hsnr_fold0_net2_nE = 15\n",
        "hsnr_fold0_net3_nE = 12\n",
        "hsnr_fold0_net4_nE = 13\n",
        "hsnr_fold0_net5_nE = 16\n",
        "hsnr_fold0_net1_nC = 10\n",
        "hsnr_fold0_net2_nC = 10\n",
        "hsnr_fold0_net3_nC = 10\n",
        "hsnr_fold0_net4_nC = 10\n",
        "hsnr_fold0_net5_nC = 10\n",
        "hsnr_fold0_net1_c = c((hsnr_fold0_net1_nC, hsnr_fold0_net1_nE))\n",
        "hsnr_fold0_net2_c = c((hsnr_fold0_net2_nC, hsnr_fold0_net2_nE))\n",
        "hsnr_fold0_net3_c = c((hsnr_fold0_net3_nC, hsnr_fold0_net3_nE))\n",
        "hsnr_fold0_net4_c = c((hsnr_fold0_net4_nC, hsnr_fold0_net4_nE))\n",
        "hsnr_fold0_net5_c = c((hsnr_fold0_net5_nC, hsnr_fold0_net5_nE))\n",
        "print(\"hsnr_fold0_net1_c == \", hsnr_fold0_net1_c)\n",
        "print(\"hsnr_fold0_net2_c == \", hsnr_fold0_net2_c)\n",
        "print(\"hsnr_fold0_net3_c == \", hsnr_fold0_net3_c)\n",
        "print(\"hsnr_fold0_net4_c == \", hsnr_fold0_net4_c)\n",
        "print(\"hsnr_fold0_net5_c == \", hsnr_fold0_net5_c, \"\\n\")\n",
        "\n",
        "hsnr_fold1_net1_nE = 15\n",
        "hsnr_fold1_net2_nE = 15\n",
        "hsnr_fold1_net3_nE = 12\n",
        "hsnr_fold1_net4_nE = 13\n",
        "hsnr_fold1_net5_nE = 16\n",
        "hsnr_fold1_net1_nC = 10\n",
        "hsnr_fold1_net2_nC = 10\n",
        "hsnr_fold1_net3_nC = 10\n",
        "hsnr_fold1_net4_nC = 10\n",
        "hsnr_fold1_net5_nC = 10\n",
        "hsnr_fold1_net1_c = c((hsnr_fold1_net1_nC, hsnr_fold1_net1_nE))\n",
        "hsnr_fold1_net2_c = c((hsnr_fold1_net2_nC, hsnr_fold1_net2_nE))\n",
        "hsnr_fold1_net3_c = c((hsnr_fold1_net3_nC, hsnr_fold1_net3_nE))\n",
        "hsnr_fold1_net4_c = c((hsnr_fold1_net4_nC, hsnr_fold1_net4_nE))\n",
        "hsnr_fold1_net5_c = c((hsnr_fold1_net5_nC, hsnr_fold1_net5_nE))\n",
        "print(\"hsnr_fold1_net1_c == \", hsnr_fold1_net1_c)\n",
        "print(\"hsnr_fold1_net2_c == \", hsnr_fold1_net2_c)\n",
        "print(\"hsnr_fold1_net3_c == \", hsnr_fold1_net3_c)\n",
        "print(\"hsnr_fold1_net4_c == \", hsnr_fold1_net4_c)\n",
        "print(\"hsnr_fold1_net5_c == \", hsnr_fold1_net5_c, \"\\n\")\n",
        "\n",
        "hsnr_fold2_net1_nE = 15\n",
        "hsnr_fold2_net2_nE = 15\n",
        "hsnr_fold2_net3_nE = 12\n",
        "hsnr_fold2_net4_nE = 13\n",
        "hsnr_fold2_net5_nE = 16\n",
        "hsnr_fold2_net1_nC = 10\n",
        "hsnr_fold2_net2_nC = 10\n",
        "hsnr_fold2_net3_nC = 10\n",
        "hsnr_fold2_net4_nC = 10\n",
        "hsnr_fold2_net5_nC = 10\n",
        "hsnr_fold2_net1_c = c((hsnr_fold2_net1_nC, hsnr_fold2_net1_nE))\n",
        "hsnr_fold2_net2_c = c((hsnr_fold2_net2_nC, hsnr_fold2_net2_nE))\n",
        "hsnr_fold2_net3_c = c((hsnr_fold2_net3_nC, hsnr_fold2_net3_nE))\n",
        "hsnr_fold2_net4_c = c((hsnr_fold2_net4_nC, hsnr_fold2_net4_nE))\n",
        "hsnr_fold2_net5_c = c((hsnr_fold2_net5_nC, hsnr_fold2_net5_nE))\n",
        "print(\"hsnr_fold2_net1_c == \", hsnr_fold2_net1_c)\n",
        "print(\"hsnr_fold2_net2_c == \", hsnr_fold2_net2_c)\n",
        "print(\"hsnr_fold2_net3_c == \", hsnr_fold2_net3_c)\n",
        "print(\"hsnr_fold2_net4_c == \", hsnr_fold2_net4_c)\n",
        "print(\"hsnr_fold2_net5_c == \", hsnr_fold2_net5_c, \"\\n\")\n",
        "\n",
        "hsnr_fold3_net1_nE = 15\n",
        "hsnr_fold3_net2_nE = 15\n",
        "hsnr_fold3_net3_nE = 12\n",
        "hsnr_fold3_net4_nE = 13\n",
        "hsnr_fold3_net5_nE = 16\n",
        "hsnr_fold3_net1_nC = 10\n",
        "hsnr_fold3_net2_nC = 10\n",
        "hsnr_fold3_net3_nC = 10\n",
        "hsnr_fold3_net4_nC = 10\n",
        "hsnr_fold3_net5_nC = 10\n",
        "hsnr_fold3_net1_c = c((hsnr_fold3_net1_nC, hsnr_fold3_net1_nE))\n",
        "hsnr_fold3_net2_c = c((hsnr_fold3_net2_nC, hsnr_fold3_net2_nE))\n",
        "hsnr_fold3_net3_c = c((hsnr_fold3_net3_nC, hsnr_fold3_net3_nE))\n",
        "hsnr_fold3_net4_c = c((hsnr_fold3_net4_nC, hsnr_fold3_net4_nE))\n",
        "hsnr_fold3_net5_c = c((hsnr_fold3_net5_nC, hsnr_fold3_net5_nE))\n",
        "print(\"hsnr_fold3_net1_c == \", hsnr_fold3_net1_c)\n",
        "print(\"hsnr_fold3_net2_c == \", hsnr_fold3_net2_c)\n",
        "print(\"hsnr_fold3_net3_c == \", hsnr_fold3_net3_c)\n",
        "print(\"hsnr_fold3_net4_c == \", hsnr_fold3_net4_c)\n",
        "print(\"hsnr_fold3_net5_c == \", hsnr_fold3_net5_c, \"\\n\")\n",
        "\n",
        "hsnr_fold4_net1_nE = 15\n",
        "hsnr_fold4_net2_nE = 15\n",
        "hsnr_fold4_net3_nE = 12\n",
        "hsnr_fold4_net4_nE = 13\n",
        "hsnr_fold4_net5_nE = 16\n",
        "hsnr_fold4_net1_nC = 10\n",
        "hsnr_fold4_net2_nC = 10\n",
        "hsnr_fold4_net3_nC = 10\n",
        "hsnr_fold4_net4_nC = 10\n",
        "hsnr_fold4_net5_nC = 10\n",
        "hsnr_fold4_net1_c = c((hsnr_fold4_net1_nC, hsnr_fold4_net1_nE))\n",
        "hsnr_fold4_net2_c = c((hsnr_fold4_net2_nC, hsnr_fold4_net2_nE))\n",
        "hsnr_fold4_net3_c = c((hsnr_fold4_net3_nC, hsnr_fold4_net3_nE))\n",
        "hsnr_fold4_net4_c = c((hsnr_fold4_net4_nC, hsnr_fold4_net4_nE))\n",
        "hsnr_fold4_net5_c = c((hsnr_fold4_net5_nC, hsnr_fold4_net5_nE))\n",
        "print(\"hsnr_fold4_net1_c == \", hsnr_fold4_net1_c)\n",
        "print(\"hsnr_fold4_net2_c == \", hsnr_fold4_net2_c)\n",
        "print(\"hsnr_fold4_net3_c == \", hsnr_fold4_net3_c)\n",
        "print(\"hsnr_fold4_net4_c == \", hsnr_fold4_net4_c)\n",
        "print(\"hsnr_fold4_net5_c == \", hsnr_fold4_net5_c, \"\\n\")"
      ],
      "metadata": {
        "id": "1ifu2_14TFXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing LSNR D4IC Results 01/27/2024"
      ],
      "metadata": {
        "id": "kh-j8awVpr9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# D4IC LSNR Summary (01/27/2025):\n",
        "\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "\n",
        "FONT_SMALL_SIZE = 18\n",
        "FONT_MEDIUM_SIZE = 20\n",
        "FONT_BIGGER_SIZE = 22\n",
        "\n",
        "plt.rc('font', size=FONT_SMALL_SIZE)          # controls default text sizes\n",
        "plt.rc('axes', titlesize=FONT_BIGGER_SIZE)     # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=FONT_MEDIUM_SIZE)    # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=FONT_SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=FONT_SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=FONT_SMALL_SIZE)    # legend fontsize\n",
        "plt.rc('figure', titlesize=FONT_BIGGER_SIZE)  # fontsize of the figure title\n",
        "\n",
        "\n",
        "def get_alg_name_alias_for_plot_axes(orig_name):\n",
        "    if orig_name == 'REDCLIFF-S (cMLP)':\n",
        "        return 'REDCLIFF-S\\n(cMLP)'\n",
        "    elif orig_name == 'REDCLIFF-S (cMLP)-vCosSim':\n",
        "        return 'REDCLIFF-S\\n(cMLP)'\n",
        "    elif orig_name == 'REDCLIFF-S (cMLP)-vSC':\n",
        "        return 'REDCLIFF-S\\n(cMLP)' + \" \" + \"*\"\n",
        "    elif orig_name == 'REDCLIFF-S (cMLP)' + \" \" + \"\\U000025C7\":\n",
        "        return 'REDCLIFF-S\\n(cMLP)' + \" \" + \"\\U000025C7\"\n",
        "    elif orig_name == 'DYNOTEARS' + \" \" + \"\\U000025C7\":\n",
        "        return 'DYNOTEARS' + \" \" + \"\\U000025C7\"\n",
        "    elif orig_name == 'NAVAR-P' + \" \" + \"\\U000025C7\":\n",
        "        return 'NAVAR-P' + \" \" + \"\\U000025C7\"\n",
        "    elif orig_name == 'NAVAR-R' + \" \" + \"\\U000025C7\":\n",
        "        return 'NAVAR-R' + \" \" + \"\\U000025C7\"\n",
        "    elif orig_name == 'cMLP':\n",
        "        return 'cMLP  '\n",
        "    elif orig_name == 'CLSTM':\n",
        "        return 'cLSTM '\n",
        "    elif orig_name == 'DCSFA-NMF':\n",
        "        return 'dCSFA-NMF'\n",
        "    return orig_name\n",
        "\n",
        "def get_alg_name_alias(orig_name):\n",
        "    if orig_name == 'REDCLIFF_S_CMLP':\n",
        "        return 'REDCLIFF-S (cMLP)'\n",
        "    elif orig_name == 'REDCLIFF_S_CMLP_WithSmoothing':\n",
        "        return 'REDCLIFF-S (cMLP)'\n",
        "    elif orig_name == 'CMLP':\n",
        "        return 'cMLP'\n",
        "    elif orig_name == 'CLSTM':\n",
        "        return 'cLSTM'\n",
        "    elif orig_name == 'DCSFA':\n",
        "        return 'dCSFA-NMF'\n",
        "    elif orig_name == 'DYNOTEARS_Vanilla':\n",
        "        return 'DYNOTEARS'\n",
        "    elif orig_name == 'NAVAR_CMLP':\n",
        "        return 'NAVAR-P'\n",
        "    elif orig_name == 'NAVAR_CLSTM':\n",
        "        return 'NAVAR-R'\n",
        "    return orig_name\n",
        "\n",
        "\n",
        "mean_colors = [\"darkorange\", \"darkred\", 'darkred', \"mediumvioletred\", \"darkslateblue\", 'darkslategrey', \"grey\", \"black\"]\n",
        "sem_colors = [\"orangered\", \"tomato\", 'tomato', \"lightcoral\", \"slategrey\", \"lightblue\", \"lightgrey\", \"darkgrey\"]\n",
        "alg_names = []\n",
        "alg_performance_means = []\n",
        "alg_performance_sems = []\n",
        "\n",
        "\n",
        "# read in bCgs1v1223_REDCvNEWcMLP LSNR results\n",
        "bsOH_lsnr_results = None\n",
        "with open(\"bCgs1v1223_REDCvNEWcMLP_full_comparrisson_summary.pkl\", \"rb\") as f:\n",
        "    bsOH_lsnr_results = pkl.load(f)\n",
        "\n",
        "print(bsOH_lsnr_results.keys())\n",
        "for i, alg_key in enumerate(bsOH_lsnr_results['dream4_insilicoCombo_size10_LSNR']['key_stats_estGC_normOffDiag_vs_trueGC_normOffDiag'].keys()):\n",
        "    if alg_key in ['REDCLIFF_S_CMLP','REDCLIFF_S_CMLP_WithSmoothing','CMLP']:\n",
        "        print(\"alg_key == \", alg_key)\n",
        "        if alg_key == 'CMLP':\n",
        "            alg_names.append(get_alg_name_alias(alg_key)+'-v2') # 'newer' CMLP, therefore dubbed v2\n",
        "        else:\n",
        "            assert alg_key == 'REDCLIFF_S_CMLP'\n",
        "            alg_names.append(get_alg_name_alias(alg_key)+'-vCosSim') # this REDCLIFF-S model (from bCgs1v1223_REDCvNEWcMLP) has a better/smaller cosSim penalty\n",
        "\n",
        "        alg_eval_stats = bsOH_lsnr_results['dream4_insilicoCombo_size10_LSNR']['key_stats_estGC_normOffDiag_vs_trueGC_normOffDiag'][alg_key]\n",
        "        for stat_key in alg_eval_stats.keys():\n",
        "            if 'f1' in stat_key and \"mean_across_factors\" in stat_key:\n",
        "                alg_performance_means.append(alg_eval_stats[stat_key])\n",
        "            elif 'f1' in stat_key and \"mean_std_err_across_factors\" in stat_key:\n",
        "                alg_performance_sems.append(alg_eval_stats[stat_key])\n",
        "\n",
        "# read in bCgs1v1223_REDCvOGcMLP LSNR results\n",
        "bsd4ic_lsnr_results = None\n",
        "with open(\"bCgs1v1223_REDCvOGcMLP_full_comparrisson_summary.pkl\", \"rb\") as f:\n",
        "    bsd4ic_lsnr_results = pkl.load(f)\n",
        "\n",
        "for i, alg_key in enumerate(bsd4ic_lsnr_results['dream4_insilicoCombo_size10_LSNR']['key_stats_estGC_normOffDiag_vs_trueGC_normOffDiag'].keys()):\n",
        "    print(\"alg_key == \", alg_key)\n",
        "    if alg_key != \"REDCLIFF_S_CMLP\":\n",
        "        if alg_key == \"CMLP\":\n",
        "            alg_names.append(get_alg_name_alias(alg_key)+'-v1') # 'older' CMLP, therefore dubbed v1\n",
        "        else:\n",
        "            alg_names.append(get_alg_name_alias(alg_key))\n",
        "        alg_eval_stats = bsd4ic_lsnr_results['dream4_insilicoCombo_size10_LSNR']['key_stats_estGC_normOffDiag_vs_trueGC_normOffDiag'][alg_key]\n",
        "        for stat_key in alg_eval_stats.keys():\n",
        "                if 'f1' in stat_key and \"mean_across_factors\" in stat_key:\n",
        "                    alg_performance_means.append(alg_eval_stats[stat_key])\n",
        "                elif 'f1' in stat_key and \"mean_std_err_across_factors\" in stat_key:\n",
        "                    alg_performance_sems.append(alg_eval_stats[stat_key])\n",
        "        assert len(alg_performance_means) == i+2\n",
        "        assert len(alg_performance_sems) == i+2\n",
        "\n",
        "\n",
        "# ORGANIZE LISTS INTO SENSIBLE ORDERING FOR VISUALIZATION\n",
        "alg_names = [alg_names[0]]+[alg_names[2]]+[alg_names[1]]+alg_names[3:]\n",
        "alg_performance_means = [alg_performance_means[0]]+[alg_performance_means[2]]+[alg_performance_means[1]]+alg_performance_means[3:]\n",
        "alg_performance_sems = [alg_performance_sems[0]]+[alg_performance_sems[2]]+[alg_performance_sems[1]]+alg_performance_sems[3:]\n",
        "\n",
        "\n",
        "# remainder of code drafted with help from ChatGPT\n",
        "# Create figure and axis\n",
        "fig = plt.figure(figsize=(9.5, 8))\n",
        "gs = gridspec.GridSpec(1, 1)\n",
        "ax1 = plt.subplot(gs[0])\n",
        "\n",
        "\n",
        "bar_width = 0.45\n",
        "index = np.arange(len(alg_names))\n",
        "\n",
        "# Horizontal bar plot with whiskers\n",
        "for a, (alg_name, mean_color, sem_color) in enumerate(zip(alg_names, mean_colors, sem_colors)):\n",
        "    curr_inds = None\n",
        "    curr_means = None\n",
        "    curr_sems = None\n",
        "\n",
        "    curr_inds = [ind for ind in index if ind % len(alg_names) == a]\n",
        "    curr_means = [alg_performance_means[ind] for ind in index if ind % len(alg_names) == a]\n",
        "    curr_sems = [alg_performance_sems[ind] for ind in index if ind % len(alg_names) == a]\n",
        "    for m in curr_means:\n",
        "        if not np.isfinite(m):\n",
        "            print(\"WARNING: m==\", m, \" when alg_name == \", alg_name)\n",
        "    for s in curr_sems:\n",
        "        if not np.isfinite(s):\n",
        "            print(\"WARNING: s==\", s, \" when alg_name == \", alg_name)\n",
        "    ax1.barh([ind - bar_width/2 for ind in curr_inds], curr_means, xerr=curr_sems, ecolor=sem_color, height=bar_width, color=mean_color, capsize=5, label=alg_name)\n",
        "\n",
        "ax1.set_yticks(index-.25)\n",
        "ax1.set_yticklabels([get_alg_name_alias_for_plot_axes(a) for a in alg_names], rotation=0)\n",
        "\n",
        "ax1.set_xlim(0.26, 0.35)\n",
        "\n",
        "# hide the spines between ax and ax2\n",
        "ax1.yaxis.tick_left()\n",
        "\n",
        "# Customize the grid: Add both major and minor grid lines\n",
        "ax1.grid(True, axis='x', which='major', linestyle=':', linewidth=0.75, color='grey')  # Major grid lines\n",
        "ax1.minorticks_on()  # Enable minor ticks\n",
        "ax1.grid(True, axis='x', which='minor', linestyle=':', linewidth=0.5, color='lightgray')  # Minor grid lines\n",
        "\n",
        "# Optional: Customize appearance\n",
        "ax1.invert_yaxis()  # Invert y-axis to display the first category at the top\n",
        "\n",
        "# Show plot\n",
        "ax1.set_title('D4IC LSNR Edge Prediction')\n",
        "ax1.set_xlabel('Avg. Optimal F1-Score '+r'$\\pm$'+' Std. Err. of the Mean')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "a68u4IIYpryX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing MSNR D4IC Results 01/27/2024"
      ],
      "metadata": {
        "id": "8GB1VQWKppt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# D4IC MSNR Summary (01/27/2025):\n",
        "\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "\n",
        "FONT_SMALL_SIZE = 18\n",
        "FONT_MEDIUM_SIZE = 20\n",
        "FONT_BIGGER_SIZE = 22\n",
        "\n",
        "plt.rc('font', size=FONT_SMALL_SIZE)          # controls default text sizes\n",
        "plt.rc('axes', titlesize=FONT_BIGGER_SIZE)     # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=FONT_MEDIUM_SIZE)    # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=FONT_SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=FONT_SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=FONT_SMALL_SIZE)    # legend fontsize\n",
        "plt.rc('figure', titlesize=FONT_BIGGER_SIZE)  # fontsize of the figure title\n",
        "\n",
        "\n",
        "def get_alg_name_alias_for_plot_axes(orig_name):\n",
        "    if orig_name == 'REDCLIFF-S (cMLP)':\n",
        "        return 'REDCLIFF-S\\n(cMLP)'\n",
        "    elif orig_name == 'REDCLIFF-S (cMLP)-vCosSim':\n",
        "        return 'REDCLIFF-S\\n(cMLP)'\n",
        "    elif orig_name == 'REDCLIFF-S (cMLP)-vSC':\n",
        "        return 'REDCLIFF-S\\n(cMLP)' + \" \" + \"*\"\n",
        "    elif orig_name == 'REDCLIFF-S (cMLP)' + \" \" + \"\\U000025C7\":\n",
        "        return 'REDCLIFF-S\\n(cMLP)' + \" \" + \"\\U000025C7\"\n",
        "    elif orig_name == 'DYNOTEARS' + \" \" + \"\\U000025C7\":\n",
        "        return 'DYNOTEARS' + \" \" + \"\\U000025C7\"\n",
        "    elif orig_name == 'NAVAR-P' + \" \" + \"\\U000025C7\":\n",
        "        return 'NAVAR-P' + \" \" + \"\\U000025C7\"\n",
        "    elif orig_name == 'NAVAR-R' + \" \" + \"\\U000025C7\":\n",
        "        return 'NAVAR-R' + \" \" + \"\\U000025C7\"\n",
        "    elif orig_name == 'cMLP':\n",
        "        return 'cMLP  '\n",
        "    elif orig_name == 'CLSTM':\n",
        "        return 'cLSTM '\n",
        "    elif orig_name == 'DCSFA-NMF':\n",
        "        return 'dCSFA-NMF'\n",
        "    return orig_name\n",
        "\n",
        "def get_alg_name_alias(orig_name):\n",
        "    if orig_name == 'REDCLIFF_S_CMLP':\n",
        "        return 'REDCLIFF-S (cMLP)'\n",
        "    elif orig_name == 'REDCLIFF_S_CMLP_WithSmoothing':\n",
        "        return 'REDCLIFF-S (cMLP)'\n",
        "    elif orig_name == 'CMLP':\n",
        "        return 'cMLP'\n",
        "    elif orig_name == 'CLSTM':\n",
        "        return 'cLSTM'\n",
        "    elif orig_name == 'DCSFA':\n",
        "        return 'dCSFA-NMF'\n",
        "    elif orig_name == 'DYNOTEARS_Vanilla':\n",
        "        return 'DYNOTEARS'\n",
        "    elif orig_name == 'NAVAR_CMLP':\n",
        "        return 'NAVAR-P'\n",
        "    elif orig_name == 'NAVAR_CLSTM':\n",
        "        return 'NAVAR-R'\n",
        "    return orig_name\n",
        "\n",
        "\n",
        "mean_colors = [\"darkorange\", \"darkred\", 'darkred', \"mediumvioletred\", \"darkslateblue\", \"indigo\", 'darkslategrey', \"grey\", \"black\"]\n",
        "sem_colors = [\"orangered\", \"tomato\", 'tomato', \"lightcoral\", \"slategrey\", \"mediumpurple\", \"lightblue\", \"lightgrey\", \"darkgrey\"]\n",
        "alg_names = []\n",
        "alg_performance_means = []\n",
        "alg_performance_sems = []\n",
        "\n",
        "\n",
        "# read in bCgs1v1223_REDCvNEWcMLP_v0120 MSNR results\n",
        "bsOH_msnr_results = None\n",
        "with open(\"bCgs1v1223_REDCvNEWcMLP_v0120_full_comparrisson_summary.pkl\", \"rb\") as f:\n",
        "    bsOH_msnr_results = pkl.load(f)\n",
        "\n",
        "print(bsOH_msnr_results.keys())\n",
        "for i, alg_key in enumerate(bsOH_msnr_results['dream4_insilicoCombo_size10_v01192024_RERUN10242024_MSNR']['key_stats_estGC_normOffDiag_vs_trueGC_normOffDiag'].keys()):\n",
        "    if alg_key in ['REDCLIFF_S_CMLP','REDCLIFF_S_CMLP_WithSmoothing','CMLP']:\n",
        "        print(\"alg_key == \", alg_key)\n",
        "        if alg_key == 'CMLP':\n",
        "            alg_names.append(get_alg_name_alias(alg_key)+'-v2') # 'newer' CMLP, therefore dubbed v2\n",
        "        else:\n",
        "            assert alg_key == 'REDCLIFF_S_CMLP'\n",
        "            alg_names.append(get_alg_name_alias(alg_key)+'-vCosSim') # this REDCLIFF-S model (from bCgs1v1223_REDCvNEWcMLP) has a better/smaller cosSim penalty\n",
        "\n",
        "        alg_eval_stats = bsOH_msnr_results['dream4_insilicoCombo_size10_MSNR']['key_stats_estGC_normOffDiag_vs_trueGC_normOffDiag'][alg_key]\n",
        "        for stat_key in alg_eval_stats.keys():\n",
        "            if 'f1' in stat_key and \"mean_across_factors\" in stat_key:\n",
        "                alg_performance_means.append(alg_eval_stats[stat_key])\n",
        "            elif 'f1' in stat_key and \"mean_std_err_across_factors\" in stat_key:\n",
        "                alg_performance_sems.append(alg_eval_stats[stat_key])\n",
        "\n",
        "# read in bCgs1v1223_REDCvOGcMLP MSNR results\n",
        "bsd4ic_msnr_results = None\n",
        "with open(\"bCgs1v1223_REDCvOGcMLP_full_comparrisson_summary.pkl\", \"rb\") as f:\n",
        "    bsd4ic_msnr_results = pkl.load(f)\n",
        "\n",
        "for i, alg_key in enumerate(bsd4ic_msnr_results['dream4_insilicoCombo_size10_MSNR']['key_stats_estGC_normOffDiag_vs_trueGC_normOffDiag'].keys()):\n",
        "    print(\"alg_key == \", alg_key)\n",
        "    if alg_key != \"REDCLIFF_S_CMLP\":\n",
        "        if alg_key == \"CMLP\":\n",
        "            alg_names.append(get_alg_name_alias(alg_key)+'-v1') # 'older' CMLP, therefore dubbed v1\n",
        "        else:\n",
        "            alg_names.append(get_alg_name_alias(alg_key))\n",
        "        alg_eval_stats = bsd4ic_msnr_results['dream4_insilicoCombo_size10_MSNR']['key_stats_estGC_normOffDiag_vs_trueGC_normOffDiag'][alg_key]\n",
        "        for stat_key in alg_eval_stats.keys():\n",
        "                if 'f1' in stat_key and \"mean_across_factors\" in stat_key:\n",
        "                    alg_performance_means.append(alg_eval_stats[stat_key])\n",
        "                elif 'f1' in stat_key and \"mean_std_err_across_factors\" in stat_key:\n",
        "                    alg_performance_sems.append(alg_eval_stats[stat_key])\n",
        "        assert len(alg_performance_means) == i+2\n",
        "        assert len(alg_performance_sems) == i+2\n",
        "\n",
        "\n",
        "# ORGANIZE LISTS INTO SENSIBLE ORDERING FOR VISUALIZATION\n",
        "alg_names = [alg_names[0]]+[alg_names[2]]+[alg_names[1]]+alg_names[3:]\n",
        "alg_performance_means = [alg_performance_means[0]]+[alg_performance_means[2]]+[alg_performance_means[1]]+alg_performance_means[3:]\n",
        "alg_performance_sems = [alg_performance_sems[0]]+[alg_performance_sems[2]]+[alg_performance_sems[1]]+alg_performance_sems[3:]\n",
        "\n",
        "\n",
        "# remainder of code drafted with help from ChatGPT\n",
        "# Create figure and axis\n",
        "fig = plt.figure(figsize=(9.5, 8))\n",
        "gs = gridspec.GridSpec(1, 1)\n",
        "ax1 = plt.subplot(gs[0])\n",
        "\n",
        "\n",
        "bar_width = 0.45\n",
        "index = np.arange(len(alg_names))\n",
        "\n",
        "# Horizontal bar plot with whiskers\n",
        "for a, (alg_name, mean_color, sem_color) in enumerate(zip(alg_names, mean_colors, sem_colors)):\n",
        "    curr_inds = None\n",
        "    curr_means = None\n",
        "    curr_sems = None\n",
        "\n",
        "    curr_inds = [ind for ind in index if ind % len(alg_names) == a]\n",
        "    curr_means = [alg_performance_means[ind] for ind in index if ind % len(alg_names) == a]\n",
        "    curr_sems = [alg_performance_sems[ind] for ind in index if ind % len(alg_names) == a]\n",
        "    for m in curr_means:\n",
        "        if not np.isfinite(m):\n",
        "            print(\"WARNING: m==\", m, \" when alg_name == \", alg_name)\n",
        "    for s in curr_sems:\n",
        "        if not np.isfinite(s):\n",
        "            print(\"WARNING: s==\", s, \" when alg_name == \", alg_name)\n",
        "    ax1.barh([ind - bar_width/2 for ind in curr_inds], curr_means, xerr=curr_sems, ecolor=sem_color, height=bar_width, color=mean_color, capsize=5, label=alg_name)\n",
        "\n",
        "ax1.set_yticks(index-.25)\n",
        "ax1.set_yticklabels([get_alg_name_alias_for_plot_axes(a) for a in alg_names], rotation=0)\n",
        "\n",
        "ax1.set_xlim(0.28, 0.38)\n",
        "\n",
        "# hide the spines between ax and ax2\n",
        "ax1.yaxis.tick_left()\n",
        "\n",
        "# Customize the grid: Add both major and minor grid lines\n",
        "ax1.grid(True, axis='x', which='major', linestyle=':', linewidth=0.75, color='grey')  # Major grid lines\n",
        "ax1.minorticks_on()  # Enable minor ticks\n",
        "ax1.grid(True, axis='x', which='minor', linestyle=':', linewidth=0.5, color='lightgray')  # Minor grid lines\n",
        "\n",
        "# Optional: Customize appearance\n",
        "ax1.invert_yaxis()  # Invert y-axis to display the first category at the top\n",
        "\n",
        "# Show plot\n",
        "ax1.set_title('D4IC MSNR Edge Prediction')\n",
        "ax1.set_xlabel('Avg. Optimal F1-Score '+r'$\\pm$'+' Std. Err. of the Mean')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ZHhDm5J2ppgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing HSNR D4IC Results 01/27/2024"
      ],
      "metadata": {
        "id": "NCXdgwmgmKG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# D4IC HSNR Summary (01/27/2025):\n",
        "\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "\n",
        "FONT_SMALL_SIZE = 18\n",
        "FONT_MEDIUM_SIZE = 20\n",
        "FONT_BIGGER_SIZE = 22\n",
        "\n",
        "plt.rc('font', size=FONT_SMALL_SIZE)          # controls default text sizes\n",
        "plt.rc('axes', titlesize=FONT_BIGGER_SIZE)     # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=FONT_MEDIUM_SIZE)    # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=FONT_SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=FONT_SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=FONT_SMALL_SIZE)    # legend fontsize\n",
        "plt.rc('figure', titlesize=FONT_BIGGER_SIZE)  # fontsize of the figure title\n",
        "\n",
        "\n",
        "def get_alg_name_alias_for_plot_axes(orig_name):\n",
        "    if orig_name == 'REDCLIFF-S (cMLP)':\n",
        "        return 'REDCLIFF-S\\n(cMLP)'\n",
        "    elif orig_name == 'REDCLIFF-S (cMLP)-vCosSim':\n",
        "        return 'REDCLIFF-S\\n(cMLP)'\n",
        "    elif orig_name == 'REDCLIFF-S (cMLP)-vSC':\n",
        "        return 'REDCLIFF-S\\n(cMLP)' + \" \" + \"*\"\n",
        "    elif orig_name == 'REDCLIFF-S (cMLP)' + \" \" + \"\\U000025C7\":\n",
        "        return 'REDCLIFF-S\\n(cMLP)' + \" \" + \"\\U000025C7\"\n",
        "    elif orig_name == 'DYNOTEARS' + \" \" + \"\\U000025C7\":\n",
        "        return 'DYNOTEARS' + \" \" + \"\\U000025C7\"\n",
        "    elif orig_name == 'NAVAR-P' + \" \" + \"\\U000025C7\":\n",
        "        return 'NAVAR-P' + \" \" + \"\\U000025C7\"\n",
        "    elif orig_name == 'NAVAR-R' + \" \" + \"\\U000025C7\":\n",
        "        return 'NAVAR-R' + \" \" + \"\\U000025C7\"\n",
        "    elif orig_name == 'cMLP':\n",
        "        return 'cMLP  '\n",
        "    elif orig_name == 'CLSTM':\n",
        "        return 'cLSTM '\n",
        "    elif orig_name == 'DCSFA-NMF':\n",
        "        return 'dCSFA-NMF'\n",
        "    return orig_name\n",
        "\n",
        "def get_alg_name_alias(orig_name):\n",
        "    if orig_name == 'REDCLIFF_S_CMLP':\n",
        "        return 'REDCLIFF-S (cMLP)'\n",
        "    elif orig_name == 'REDCLIFF_S_CMLP_WithSmoothing':\n",
        "        return 'REDCLIFF-S (cMLP)'\n",
        "    elif orig_name == 'CMLP':\n",
        "        return 'cMLP'\n",
        "    elif orig_name == 'CLSTM':\n",
        "        return 'cLSTM'\n",
        "    elif orig_name == 'DCSFA':\n",
        "        return 'dCSFA-NMF'\n",
        "    elif orig_name == 'DYNOTEARS_Vanilla':\n",
        "        return 'DYNOTEARS'\n",
        "    elif orig_name == 'NAVAR_CMLP':\n",
        "        return 'NAVAR-P'\n",
        "    elif orig_name == 'NAVAR_CLSTM':\n",
        "        return 'NAVAR-R'\n",
        "    return orig_name\n",
        "\n",
        "\n",
        "mean_colors = [\"darkorange\", \"darkred\", 'darkred', \"mediumvioletred\", \"darkslateblue\", \"indigo\", 'darkslategrey', \"grey\", \"black\"]\n",
        "sem_colors = [\"orangered\", \"tomato\", 'tomato', \"lightcoral\", \"slategrey\", \"mediumpurple\", \"lightblue\", \"lightgrey\", \"darkgrey\"]\n",
        "alg_names = []\n",
        "alg_performance_means = []\n",
        "alg_performance_sems = []\n",
        "\n",
        "\n",
        "# read in bCgs1v1223_REDCvNEWcMLP HSNR results\n",
        "bsOH_hsnr_results = None\n",
        "with open(\"bCgs1v1223_REDCvNEWcMLP_full_comparrisson_summary.pkl\", \"rb\") as f:\n",
        "    bsOH_hsnr_results = pkl.load(f)\n",
        "\n",
        "print(bsOH_hsnr_results.keys())\n",
        "for i, alg_key in enumerate(bsOH_hsnr_results['dream4_insilicoCombo_size10_HSNR']['key_stats_estGC_normOffDiag_vs_trueGC_normOffDiag'].keys()):\n",
        "    if alg_key in ['REDCLIFF_S_CMLP','REDCLIFF_S_CMLP_WithSmoothing','CMLP']:\n",
        "        print(\"alg_key == \", alg_key)\n",
        "        if alg_key == 'CMLP':\n",
        "            alg_names.append(get_alg_name_alias(alg_key)+'-v2') # 'newer' CMLP, therefore dubbed v2\n",
        "        else:\n",
        "            assert alg_key == 'REDCLIFF_S_CMLP'\n",
        "            alg_names.append(get_alg_name_alias(alg_key)+'-vCosSim') # this REDCLIFF-S model (from bCgs1v1223_REDCvNEWcMLP) has a better/smaller cosSim penalty\n",
        "\n",
        "        alg_eval_stats = bsOH_hsnr_results['dream4_insilicoCombo_size10_HSNR']['key_stats_estGC_normOffDiag_vs_trueGC_normOffDiag'][alg_key]\n",
        "        for stat_key in alg_eval_stats.keys():\n",
        "            if 'f1' in stat_key and \"mean_across_factors\" in stat_key:\n",
        "                alg_performance_means.append(alg_eval_stats[stat_key])\n",
        "            elif 'f1' in stat_key and \"mean_std_err_across_factors\" in stat_key:\n",
        "                alg_performance_sems.append(alg_eval_stats[stat_key])\n",
        "\n",
        "# read in bCgs1v1223_REDCvOGcMLP HSNR results\n",
        "bsd4ic_hsnr_results = None\n",
        "with open(\"bCgs1v1223_REDCvOGcMLP_full_comparrisson_summary.pkl\", \"rb\") as f:\n",
        "    bsd4ic_hsnr_results = pkl.load(f)\n",
        "\n",
        "for i, alg_key in enumerate(bsd4ic_hsnr_results['dream4_insilicoCombo_size10_HSNR']['key_stats_estGC_normOffDiag_vs_trueGC_normOffDiag'].keys()):\n",
        "    print(\"alg_key == \", alg_key)\n",
        "    if alg_key != \"REDCLIFF_S_CMLP\":\n",
        "        if alg_key == \"CMLP\":\n",
        "            alg_names.append(get_alg_name_alias(alg_key)+'-v1') # 'older' CMLP, therefore dubbed v1\n",
        "        else:\n",
        "            alg_names.append(get_alg_name_alias(alg_key))\n",
        "        alg_eval_stats = bsd4ic_hsnr_results['dream4_insilicoCombo_size10_HSNR']['key_stats_estGC_normOffDiag_vs_trueGC_normOffDiag'][alg_key]\n",
        "        for stat_key in alg_eval_stats.keys():\n",
        "                if 'f1' in stat_key and \"mean_across_factors\" in stat_key:\n",
        "                    alg_performance_means.append(alg_eval_stats[stat_key])\n",
        "                elif 'f1' in stat_key and \"mean_std_err_across_factors\" in stat_key:\n",
        "                    alg_performance_sems.append(alg_eval_stats[stat_key])\n",
        "        assert len(alg_performance_means) == i+2\n",
        "        assert len(alg_performance_sems) == i+2\n",
        "\n",
        "\n",
        "# ORGANIZE LISTS INTO SENSIBLE ORDERING FOR VISUALIZATION\n",
        "alg_names = [alg_names[0]]+[alg_names[2]]+[alg_names[1]]+alg_names[3:]\n",
        "alg_performance_means = [alg_performance_means[0]]+[alg_performance_means[2]]+[alg_performance_means[1]]+alg_performance_means[3:]\n",
        "alg_performance_sems = [alg_performance_sems[0]]+[alg_performance_sems[2]]+[alg_performance_sems[1]]+alg_performance_sems[3:]\n",
        "\n",
        "\n",
        "# remainder of code drafted with help from ChatGPT\n",
        "# Create figure and axis\n",
        "fig = plt.figure(figsize=(9.5, 8))\n",
        "gs = gridspec.GridSpec(1, 1)\n",
        "ax1 = plt.subplot(gs[0])\n",
        "\n",
        "\n",
        "bar_width = 0.45\n",
        "index = np.arange(len(alg_names))\n",
        "\n",
        "# Horizontal bar plot with whiskers\n",
        "for a, (alg_name, mean_color, sem_color) in enumerate(zip(alg_names, mean_colors, sem_colors)):\n",
        "    curr_inds = None\n",
        "    curr_means = None\n",
        "    curr_sems = None\n",
        "\n",
        "    curr_inds = [ind for ind in index if ind % len(alg_names) == a]\n",
        "    curr_means = [alg_performance_means[ind] for ind in index if ind % len(alg_names) == a]\n",
        "    curr_sems = [alg_performance_sems[ind] for ind in index if ind % len(alg_names) == a]\n",
        "    for m in curr_means:\n",
        "        if not np.isfinite(m):\n",
        "            print(\"WARNING: m==\", m, \" when alg_name == \", alg_name)\n",
        "    for s in curr_sems:\n",
        "        if not np.isfinite(s):\n",
        "            print(\"WARNING: s==\", s, \" when alg_name == \", alg_name)\n",
        "    ax1.barh([ind - bar_width/2 for ind in curr_inds], curr_means, xerr=curr_sems, ecolor=sem_color, height=bar_width, color=mean_color, capsize=5, label=alg_name)\n",
        "\n",
        "ax1.set_yticks(index-.25)\n",
        "ax1.set_yticklabels([get_alg_name_alias_for_plot_axes(a) for a in alg_names], rotation=0)\n",
        "\n",
        "ax1.set_xlim(0.28, 0.39)\n",
        "\n",
        "# hide the spines between ax and ax2\n",
        "ax1.yaxis.tick_left()\n",
        "\n",
        "# Customize the grid: Add both major and minor grid lines\n",
        "ax1.grid(True, axis='x', which='major', linestyle=':', linewidth=0.75, color='grey')  # Major grid lines\n",
        "ax1.minorticks_on()  # Enable minor ticks\n",
        "ax1.grid(True, axis='x', which='minor', linestyle=':', linewidth=0.5, color='lightgray')  # Minor grid lines\n",
        "\n",
        "# Optional: Customize appearance\n",
        "ax1.invert_yaxis()  # Invert y-axis to display the first category at the top\n",
        "\n",
        "# Show plot\n",
        "ax1.set_title('D4IC HSNR Edge Prediction')\n",
        "ax1.set_xlabel('Avg. Optimal F1-Score '+r'$\\pm$'+' Std. Err. of the Mean')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Yvwgl5UWmJ12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#    \n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "spYk1eU0mT71"
      }
    }
  ]
}